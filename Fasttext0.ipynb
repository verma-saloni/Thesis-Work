{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fasttext0.ipynb",
      "provenance": [],
      "mount_file_id": "1JAfWRZex7N1gP2HMjdWQZebCsMZRthYc",
      "authorship_tag": "ABX9TyMqtkdiatGmkXUubWBDBpaV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verma-saloni/Thesis-Work/blob/main/Fasttext0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "!pip install word2number\n",
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aByzVMdkzqAJ",
        "outputId": "25439cc3-63e2-4ec4-b691-7e114f10768c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.2)\n",
            "Collecting word2number\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=beff3aea39d80836f467cac9c7d0b1a0d2525996dd51696290e490707b2583f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number\n",
            "Successfully installed word2number-1.1\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.0.58-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 66.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85452 sha256=ac55d29d01d703d087d88315a9bf7a8bafba6aa7f47f095315e1fe5af53cd6e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.0.58 pyahocorasick-1.4.2 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wffusyCytsx",
        "outputId": "7f440b34-acc3-44fa-cbba-8bf6f7aa9be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import string\n",
        "string.punctuation\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import unidecode\n",
        "from word2number import w2n\n",
        "import contractions\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "# load spacy model, can be \"en_core_web_sm\" as well\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SusBhh-CzXYG",
        "outputId": "bb0b55f8-f886-4a9b-ce7e-b18b6bb1eca2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake = pd.read_csv('/content/drive/MyDrive/Thesis/gossipcop_fake.csv')\n",
        "df_real = pd.read_csv('/content/drive/MyDrive/Thesis/gossipcop_real.csv')\n",
        "df_fake['labelML']=0\n",
        "df_real['labelML']=1\n",
        "df= df_fake.head(50).append(df_real.head(50))\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "bwskIeYazYL6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjYdaIs51j87",
        "outputId": "c12550e4-8fb7-4c5c-df97-8a934201e91d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'news_url', 'title', 'tweet_ids', 'labelML'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2VUVYCL1q1i",
        "outputId": "72e163b1-05d8-4f3b-f84c-410f1acb9c01"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      id  ... labelML\n",
            "0   gossipcop-2493749932  ...       0\n",
            "1   gossipcop-4580247171  ...       0\n",
            "2    gossipcop-941805037  ...       0\n",
            "3   gossipcop-2547891536  ...       0\n",
            "4   gossipcop-5476631226  ...       0\n",
            "..                   ...  ...     ...\n",
            "95      gossipcop-955009  ...       1\n",
            "96      gossipcop-897603  ...       1\n",
            "97      gossipcop-908402  ...       1\n",
            "98      gossipcop-862967  ...       1\n",
            "99      gossipcop-886127  ...       1\n",
            "\n",
            "[100 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1= df.drop(['tweet_ids', 'news_url','id'], axis=1)"
      ],
      "metadata": {
        "id": "jwscw5FG1t8P"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP Preprocessing\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# NLP Preprocess - gensim.utils.simple_preprocess(doc, deacc=False, min_len=2, max_len=15)[source]\n",
        "# Convert a document into a list of tokens.\n",
        "# This lowercases, tokenizes, de-accents (optional). – the output are final tokens = unicode strings, that won’t be processed any further.\n",
        "\n",
        "df1.iloc[:, 0] = df1.iloc[:, 0].apply(lambda x: ' '.join(simple_preprocess(x)))"
      ],
      "metadata": {
        "id": "hdd1tdzS2HmB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prefixing each row of the category column with '__label__' 0;10 all rows. same for column. \n",
        "#---------df1.iloc[:, 0] = df1.iloc[1:, 0].apply(lambda x: '__label__' + x)\n",
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0VW4-_B3Ool",
        "outputId": "ddfee762-21cd-4ab8-a3f7-286d0b3679cb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                title  labelML\n",
            "0                                                 NaN        0\n",
            "1   __label__paris jackson cara delevingne enjoy n...        0\n",
            "2   __label__celebrities join tax march in protest...        0\n",
            "3   __label__cindy crawford daughter kaia gerber w...        0\n",
            "4     __label__full list of oscar nominations variety        0\n",
            "..                                                ...      ...\n",
            "95  __label__michael buble and wife luisana lopila...        1\n",
            "96  __label__selena gomez is going to keep her blo...        1\n",
            "97   __label__netflix new releases coming in february        1\n",
            "98  __label__halsey calls iggy azalea king moron a...        1\n",
            "99  __label__delilah opens up about son suicide an...        1\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h6wPx2906bxr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " #df = df.loc[:,\"title\"]\n",
        " # just for loc practice, ignore.\n"
      ],
      "metadata": {
        "id": "U0I2iZpj83sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prefixing each row of the category column with '__label__' 0;10 all rows. same for column. \n",
        "df1.iloc[:49, 0] = df1.iloc[1:, 0].apply(lambda x: '__label__0 ' + x)\n",
        "df1.iloc[50:, 0] = df1.iloc[1:, 0].apply(lambda x: '__label__1 ' + x)\n",
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6LGL-V67EHw",
        "outputId": "7d324bed-6e9d-40c0-f02f-7024efb59060"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                title  labelML\n",
            "0                                                 NaN        0\n",
            "1   __label__0 paris jackson cara delevingne enjoy...        0\n",
            "2   __label__0 celebrities join tax march in prote...        0\n",
            "3   __label__0 cindy crawford daughter kaia gerber...        0\n",
            "4   __label__0 full list of oscar nominations variety        0\n",
            "..                                                ...      ...\n",
            "95  __label__1 michael buble and wife luisana lopi...        1\n",
            "96  __label__1 selena gomez is going to keep her b...        1\n",
            "97  __label__1 netflix new releases coming in febr...        1\n",
            "98  __label__1 halsey calls iggy azalea king moron...        1\n",
            "99  __label__1 delilah opens up about son suicide ...        1\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.reset_index(drop=True, inplace=True)\n",
        "X, y = df1.iloc[:, 1:], df1['labelML']\n",
        "\n",
        "# Create the training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)\n",
        "\n",
        "# Instantiate the XGBClassifier: xg_cl\n",
        "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
        "\n",
        "# Fit the classifier to the training set\n",
        "xg_cl.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set: preds\n",
        "preds = xg_cl.predict(X_test)\n",
        "\n",
        "# Compute the accuracy: accuracy\n",
        "accuracy = float(np.sum(preds == y_test)) / y_test.shape[0]\n",
        "print(\"accuracy: %f\" % (accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRG_kuxYD8ld",
        "outputId": "9c2760ec-bd9c-4b90-e20d-286b5f366f22"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 1.000000\n"
          ]
        }
      ]
    }
  ]
}