{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SBERT_NN_Politifact.ipynb.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxhnBuwH/sXJaCHsNcFo02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d9145b2c74c4bd9b4b47b2b82c6e7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c52cdfd197964bc4acec9ee0ede3ff32",
              "IPY_MODEL_e28b5172c6714002ad4a581833d36f25"
            ],
            "layout": "IPY_MODEL_f61cf68e83434b21b1bc50d74d500425"
          }
        },
        "c52cdfd197964bc4acec9ee0ede3ff32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c56fd9396e84d97b08c53c06c9c5e54",
            "placeholder": "​",
            "style": "IPY_MODEL_83f1cd96f5cf4334bdc670b5c10e075e",
            "value": "0.622 MB of 0.622 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e28b5172c6714002ad4a581833d36f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f033fcb03454072bbb0e61a4e6e8fe1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1322a7ff338a4d3b8084b018b1718e0b",
            "value": 1
          }
        },
        "f61cf68e83434b21b1bc50d74d500425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c56fd9396e84d97b08c53c06c9c5e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f1cd96f5cf4334bdc670b5c10e075e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f033fcb03454072bbb0e61a4e6e8fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1322a7ff338a4d3b8084b018b1718e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0442043604d3420fbab729c19858bdf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f958e057bbfe445e8b92908bc7ce2b91",
              "IPY_MODEL_f768d4de70d248989aa1a15de4083aed"
            ],
            "layout": "IPY_MODEL_dd608d61e7c843e1b99b9b8ab0285c34"
          }
        },
        "f958e057bbfe445e8b92908bc7ce2b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b793df4c5404cdc85653d68fe9cb41a",
            "placeholder": "​",
            "style": "IPY_MODEL_8fc9a8ae4d454e758f7f764fe686d4c4",
            "value": "0.621 MB of 0.621 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "f768d4de70d248989aa1a15de4083aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39310d1ce6b44025a7e7cce81f91a8ba",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10b508d164f347db808a85335c1e0ad7",
            "value": 1
          }
        },
        "dd608d61e7c843e1b99b9b8ab0285c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b793df4c5404cdc85653d68fe9cb41a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc9a8ae4d454e758f7f764fe686d4c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39310d1ce6b44025a7e7cce81f91a8ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b508d164f347db808a85335c1e0ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verma-saloni/Thesis-Work/blob/main/07_10_22_SBERT_NN_Gossipcop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYuIJaDz9hAo",
        "outputId": "965a4d08-2775-4597-e787-a76e07976af5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 36.7 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 57.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 61.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 71.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.11.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 62.5 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.6.0-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers, pathtools\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=9fa7fdc4c6b765e37ece2ec3e2385ce3bc8c8d609feeeec354bc6b11db8b6b59\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=05637709c3fecf42e2a25e3b4b6fec10876efeff9625009816d7e5d717e4bc4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built sentence-transformers pathtools\n",
            "Installing collected packages: smmap, pyyaml, tokenizers, huggingface-hub, gitdb, transformers, shortuuid, setproctitle, sentry-sdk, sentencepiece, pathtools, GitPython, docker-pycreds, wandb, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 huggingface-hub-0.8.1 pathtools-0.1.2 pyyaml-6.0 sentence-transformers-2.2.2 sentencepiece-0.1.96 sentry-sdk-1.6.0 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 tokenizers-0.12.1 transformers-4.20.1 wandb-0.12.21\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "\n",
        "from sentence_transformers import SentenceTransformer \n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "yC3wiA2a9hlr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [accuracy_score, f1_score, precision_score, recall_score]\n",
        "\n",
        "def get_name(score_func):\n",
        "    return score_func.__name__.split(\"_\")[0]"
      ],
      "metadata": {
        "id": "WyFQBYC29hn3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "gTHgJzbM9wTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = Path(\"/content/drive/MyDrive/ResearchFND\")\n",
        "assert base_dir.exists()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9VMLVmH9hpt",
        "outputId": "2519b888-1166-4551-a12e-355e56637d36"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "converters = {\"retweets\":ast.literal_eval, \"tweets\":ast.literal_eval}\n",
        "df = pd.read_csv(base_dir/\"gossipcop_agg.csv\", index_col=0, converters=converters)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "DaaBmpTe9hsE",
        "outputId": "84126d50-1d2f-4039-8890-d96a2b21acfe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  \\\n",
              "title                                                     \n",
              "    Kendall   Kylie Jenner Jenner NOT Upset Ups...  NaN   \n",
              "    Kim Kardashian Dethroned Dethroned By Khloe...  NaN   \n",
              "    Kim Kardashian Did NOT Hot Staffer Hot Staf...  NaN   \n",
              "    The Voice The Voice Team NOT Surprised Surp...  NaN   \n",
              "   Drake NOT Angelina Jolie s Toy Boy Toy Boy  ...  NaN   \n",
              "\n",
              "                                                                                               tweets  \\\n",
              "title                                                                                                   \n",
              "    Kendall   Kylie Jenner Jenner NOT Upset Ups...                                                 []   \n",
              "    Kim Kardashian Dethroned Dethroned By Khloe...                                                 []   \n",
              "    Kim Kardashian Did NOT Hot Staffer Hot Staf...                                                 []   \n",
              "    The Voice The Voice Team NOT Surprised Surp...                                                 []   \n",
              "   Drake NOT Angelina Jolie s Toy Boy Toy Boy  ...  [{'id': 948630026496323585, 'text': 'Drake NOT...   \n",
              "\n",
              "                                                                                             retweets  \\\n",
              "title                                                                                                   \n",
              "    Kendall   Kylie Jenner Jenner NOT Upset Ups...  [995423424741888001, 995461685166202880, 99987...   \n",
              "    Kim Kardashian Dethroned Dethroned By Khloe...  [848843565027516416, 849030801970868224, 84884...   \n",
              "    Kim Kardashian Did NOT Hot Staffer Hot Staf...  [940685393112064001, 977921622672920576, 94031...   \n",
              "    The Voice The Voice Team NOT Surprised Surp...                                                 []   \n",
              "   Drake NOT Angelina Jolie s Toy Boy Toy Boy  ...  [948022124626808832, 948630026496323585, 94801...   \n",
              "\n",
              "                                                   label  url  \n",
              "title                                                          \n",
              "    Kendall   Kylie Jenner Jenner NOT Upset Ups...  fake  NaN  \n",
              "    Kim Kardashian Dethroned Dethroned By Khloe...  fake  NaN  \n",
              "    Kim Kardashian Did NOT Hot Staffer Hot Staf...  fake  NaN  \n",
              "    The Voice The Voice Team NOT Surprised Surp...  fake  NaN  \n",
              "   Drake NOT Angelina Jolie s Toy Boy Toy Boy  ...  fake  NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a190837-4178-4446-8ecf-1a9840c5b642\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tweets</th>\n",
              "      <th>retweets</th>\n",
              "      <th>label</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Kendall   Kylie Jenner Jenner NOT Upset Upset Over Caitlyn Engagement Engagement Despite Report</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[995423424741888001, 995461685166202880, 99987...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kim Kardashian Dethroned Dethroned By Khloe As Hot Hot Sister</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[848843565027516416, 849030801970868224, 84884...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kim Kardashian Did NOT Hot Staffer Hot Staffer To Save Marriage Save Marriage  Despite Claim</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[940685393112064001, 977921622672920576, 94031...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Voice The Voice Team NOT Surprised Surprised Adam Levine   Behati Prinsloo Pregnant Again Before Blake Shelton Gwen Stefani</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Drake NOT Angelina Jolie s Toy Boy Toy Boy  Despite Late And Wrong Report</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'id': 948630026496323585, 'text': 'Drake NOT...</td>\n",
              "      <td>[948022124626808832, 948630026496323585, 94801...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a190837-4178-4446-8ecf-1a9840c5b642')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a190837-4178-4446-8ecf-1a9840c5b642 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a190837-4178-4446-8ecf-1a9840c5b642');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles = df.title.tolist()\n",
        "texts = (df.title + \"\\n\" + df.text).tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "b9yss93d9hto",
        "outputId": "98271cd1-505d-4eba-9443-4f214230cd4f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-78adaac37987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'title'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzGBMn_c9hvs",
        "outputId": "7a9ce8d6-5920-4840-afcc-812da3af212f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "894"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Embeddings"
      ],
      "metadata": {
        "id": "OV9Se5KW-KB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_embedding_file = base_dir/\"gossipcop_sbert_title_embeddings.npy\"\n",
        "\n",
        "if title_embedding_file.exists():\n",
        "    title_embeddings = np.load(title_embedding_file)\n",
        "else:\n",
        "    model_id = \"all-mpnet-base-v2\"\n",
        "    model = SentenceTransformer(model_id)\n",
        "\n",
        "    title_embeddings = model.encode(titles, show_progress_bar=True)\n",
        "    np.save(title_embedding_file, title_embeddings)"
      ],
      "metadata": {
        "id": "Yq46fnNx9hxr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_embedding_file = base_dir/\"gossipcop_sbert_fulltext_embeddings.npy\"\n",
        "\n",
        "if text_embedding_file.exists():\n",
        "    text_embeddings = np.load(text_embedding_file)\n",
        "else:\n",
        "    model_id = \"all-mpnet-base-v2\"\n",
        "    model = SentenceTransformer(model_id)\n",
        "\n",
        "    text_embeddings = model.encode(texts, show_progress_bar=True)\n",
        "    np.save(text_embedding_file, text_embeddings)"
      ],
      "metadata": {
        "id": "lG6IXt6--Lbt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "eI5OflH9_Jdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "jtKKs-mo-Lfl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(d_h=64, p_in:float=0.2, p_out:float=0.2):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dropout(p_in), # input dropout\n",
        "        tf.keras.layers.Dense(d_h, activation='relu'),\n",
        "        tf.keras.layers.Dropout(p_out),  \n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
        "                  optimizer='adam',metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "9SrhHaN5-Lh2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title embeddings"
      ],
      "metadata": {
        "id": "ckZRVwlg_S06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = title_embeddings\n",
        "y = (df.label==\"real\").to_numpy().astype(int)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo-PzXty_TDa",
        "outputId": "c80aa117-ceb6-4d4c-91f5-ab40972cfd2c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19968, 768), (19968,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(shuffle=True, random_state=124)"
      ],
      "metadata": {
        "id": "6GLyRfa-_VXa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(fold_id, train_idx, test_idx, params):\n",
        "\n",
        "    # setup\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "    model = get_model()\n",
        "    # training\n",
        "    ckpt_filepath = f'ckpt/fold_{fold_id}'\n",
        "    save_model_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=ckpt_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "    history = model.fit(\n",
        "        X_train, y_train, validation_data = (X_test, y_test), \n",
        "        batch_size = params['bs'] , epochs=params['epochs'],\n",
        "        callbacks=[WandbCallback(), save_model_cb]\n",
        "    )\n",
        "    #evaluation\n",
        "    model.load_weights(ckpt_filepath)\n",
        "    logits = model.predict(X_test).squeeze()\n",
        "    y_pred = (logits > 0.).astype(int)\n",
        "    eval_results = {get_name(f):f(y_pred=y_pred, y_true=y_test) for f in metrics}\n",
        "    wandb.log(eval_results)\n",
        "    wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
        "                            y_true=y_test, preds=y_pred,\n",
        "                            class_names=[\"Fake\", \"Real\"])})\n",
        "    return history"
      ],
      "metadata": {
        "id": "ra4LtxJ3_VcF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"epochs\":200,\n",
        "    \"bs\":128,\n",
        "    # 'lr':1e-3\n",
        "}"
      ],
      "metadata": {
        "id": "05yAplbm_Vgm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROUP = f\"gossipcop-title-sbert-mlp\"\n",
        "\n",
        "for fold_id, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "    clear_output()\n",
        "    with wandb.init(entity=\"saloniteam\", project=\"nofolds\", group=GROUP, name=f\"{GROUP}-{fold_id}\") as run:\n",
        "        train(fold_id, train_idx, test_idx, params)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8d9145b2c74c4bd9b4b47b2b82c6e7e5",
            "c52cdfd197964bc4acec9ee0ede3ff32",
            "e28b5172c6714002ad4a581833d36f25",
            "f61cf68e83434b21b1bc50d74d500425",
            "2c56fd9396e84d97b08c53c06c9c5e54",
            "83f1cd96f5cf4334bdc670b5c10e075e",
            "0f033fcb03454072bbb0e61a4e6e8fe1",
            "1322a7ff338a4d3b8084b018b1718e0b"
          ]
        },
        "id": "HRBT3Mwt_csK",
        "outputId": "4b65f458-53df-4aa2-9775-652eda037c31"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220710_212235-aq9c1r9e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/saloniteam/nofolds/runs/aq9c1r9e\" target=\"_blank\">gossipcop-title-sbert-mlp-0</a></strong> to <a href=\"https://wandb.ai/saloniteam/nofolds\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to compute FLOPs for this model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "125/125 [==============================] - 5s 8ms/step - loss: 0.4767 - accuracy: 0.7480 - val_loss: 0.4163 - val_accuracy: 0.8032 - _timestamp: 1657488177.0000 - _runtime: 22.0000\n",
            "Epoch 2/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3943 - accuracy: 0.8195 - val_loss: 0.3956 - val_accuracy: 0.8172 - _timestamp: 1657488178.0000 - _runtime: 23.0000\n",
            "Epoch 3/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3786 - accuracy: 0.8277 - val_loss: 0.3862 - val_accuracy: 0.8167 - _timestamp: 1657488179.0000 - _runtime: 24.0000\n",
            "Epoch 4/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3723 - accuracy: 0.8304 - val_loss: 0.3818 - val_accuracy: 0.8247 - _timestamp: 1657488180.0000 - _runtime: 25.0000\n",
            "Epoch 5/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3655 - accuracy: 0.8346 - val_loss: 0.3784 - val_accuracy: 0.8280 - _timestamp: 1657488180.0000 - _runtime: 25.0000\n",
            "Epoch 6/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3615 - accuracy: 0.8352 - val_loss: 0.3743 - val_accuracy: 0.8275 - _timestamp: 1657488181.0000 - _runtime: 26.0000\n",
            "Epoch 7/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3567 - accuracy: 0.8363 - val_loss: 0.3741 - val_accuracy: 0.8358 - _timestamp: 1657488181.0000 - _runtime: 26.0000\n",
            "Epoch 8/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3502 - accuracy: 0.8427 - val_loss: 0.3677 - val_accuracy: 0.8310 - _timestamp: 1657488182.0000 - _runtime: 27.0000\n",
            "Epoch 9/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3458 - accuracy: 0.8450 - val_loss: 0.3660 - val_accuracy: 0.8330 - _timestamp: 1657488182.0000 - _runtime: 27.0000\n",
            "Epoch 10/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3436 - accuracy: 0.8464 - val_loss: 0.3663 - val_accuracy: 0.8350 - _timestamp: 1657488183.0000 - _runtime: 28.0000\n",
            "Epoch 11/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3384 - accuracy: 0.8492 - val_loss: 0.3635 - val_accuracy: 0.8305 - _timestamp: 1657488183.0000 - _runtime: 28.0000\n",
            "Epoch 12/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3358 - accuracy: 0.8498 - val_loss: 0.3621 - val_accuracy: 0.8325 - _timestamp: 1657488184.0000 - _runtime: 29.0000\n",
            "Epoch 13/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3312 - accuracy: 0.8561 - val_loss: 0.3615 - val_accuracy: 0.8390 - _timestamp: 1657488185.0000 - _runtime: 30.0000\n",
            "Epoch 14/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3259 - accuracy: 0.8566 - val_loss: 0.3602 - val_accuracy: 0.8335 - _timestamp: 1657488186.0000 - _runtime: 31.0000\n",
            "Epoch 15/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3253 - accuracy: 0.8583 - val_loss: 0.3590 - val_accuracy: 0.8375 - _timestamp: 1657488186.0000 - _runtime: 31.0000\n",
            "Epoch 16/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3205 - accuracy: 0.8611 - val_loss: 0.3562 - val_accuracy: 0.8408 - _timestamp: 1657488187.0000 - _runtime: 32.0000\n",
            "Epoch 17/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3192 - accuracy: 0.8613 - val_loss: 0.3564 - val_accuracy: 0.8400 - _timestamp: 1657488188.0000 - _runtime: 33.0000\n",
            "Epoch 18/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3106 - accuracy: 0.8672 - val_loss: 0.3548 - val_accuracy: 0.8410 - _timestamp: 1657488189.0000 - _runtime: 34.0000\n",
            "Epoch 19/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3111 - accuracy: 0.8670 - val_loss: 0.3544 - val_accuracy: 0.8373 - _timestamp: 1657488189.0000 - _runtime: 34.0000\n",
            "Epoch 20/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3088 - accuracy: 0.8641 - val_loss: 0.3563 - val_accuracy: 0.8440 - _timestamp: 1657488190.0000 - _runtime: 35.0000\n",
            "Epoch 21/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3038 - accuracy: 0.8702 - val_loss: 0.3533 - val_accuracy: 0.8395 - _timestamp: 1657488191.0000 - _runtime: 36.0000\n",
            "Epoch 22/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2998 - accuracy: 0.8719 - val_loss: 0.3537 - val_accuracy: 0.8418 - _timestamp: 1657488192.0000 - _runtime: 37.0000\n",
            "Epoch 23/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2985 - accuracy: 0.8709 - val_loss: 0.3498 - val_accuracy: 0.8383 - _timestamp: 1657488193.0000 - _runtime: 38.0000\n",
            "Epoch 24/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2956 - accuracy: 0.8738 - val_loss: 0.3518 - val_accuracy: 0.8420 - _timestamp: 1657488193.0000 - _runtime: 38.0000\n",
            "Epoch 25/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2932 - accuracy: 0.8783 - val_loss: 0.3511 - val_accuracy: 0.8400 - _timestamp: 1657488194.0000 - _runtime: 39.0000\n",
            "Epoch 26/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2924 - accuracy: 0.8767 - val_loss: 0.3497 - val_accuracy: 0.8433 - _timestamp: 1657488195.0000 - _runtime: 40.0000\n",
            "Epoch 27/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2858 - accuracy: 0.8792 - val_loss: 0.3526 - val_accuracy: 0.8440 - _timestamp: 1657488195.0000 - _runtime: 40.0000\n",
            "Epoch 28/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2846 - accuracy: 0.8797 - val_loss: 0.3512 - val_accuracy: 0.8395 - _timestamp: 1657488196.0000 - _runtime: 41.0000\n",
            "Epoch 29/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2827 - accuracy: 0.8777 - val_loss: 0.3530 - val_accuracy: 0.8378 - _timestamp: 1657488196.0000 - _runtime: 41.0000\n",
            "Epoch 30/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2781 - accuracy: 0.8844 - val_loss: 0.3552 - val_accuracy: 0.8460 - _timestamp: 1657488197.0000 - _runtime: 42.0000\n",
            "Epoch 31/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2751 - accuracy: 0.8838 - val_loss: 0.3518 - val_accuracy: 0.8438 - _timestamp: 1657488197.0000 - _runtime: 42.0000\n",
            "Epoch 32/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2761 - accuracy: 0.8828 - val_loss: 0.3537 - val_accuracy: 0.8435 - _timestamp: 1657488198.0000 - _runtime: 43.0000\n",
            "Epoch 33/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2729 - accuracy: 0.8857 - val_loss: 0.3538 - val_accuracy: 0.8430 - _timestamp: 1657488199.0000 - _runtime: 44.0000\n",
            "Epoch 34/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2701 - accuracy: 0.8880 - val_loss: 0.3535 - val_accuracy: 0.8418 - _timestamp: 1657488199.0000 - _runtime: 44.0000\n",
            "Epoch 35/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2643 - accuracy: 0.8899 - val_loss: 0.3538 - val_accuracy: 0.8395 - _timestamp: 1657488200.0000 - _runtime: 45.0000\n",
            "Epoch 36/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2679 - accuracy: 0.8858 - val_loss: 0.3547 - val_accuracy: 0.8420 - _timestamp: 1657488200.0000 - _runtime: 45.0000\n",
            "Epoch 37/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2626 - accuracy: 0.8915 - val_loss: 0.3592 - val_accuracy: 0.8440 - _timestamp: 1657488201.0000 - _runtime: 46.0000\n",
            "Epoch 38/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2587 - accuracy: 0.8908 - val_loss: 0.3545 - val_accuracy: 0.8388 - _timestamp: 1657488202.0000 - _runtime: 47.0000\n",
            "Epoch 39/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2555 - accuracy: 0.8923 - val_loss: 0.3550 - val_accuracy: 0.8370 - _timestamp: 1657488202.0000 - _runtime: 47.0000\n",
            "Epoch 40/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2532 - accuracy: 0.8951 - val_loss: 0.3563 - val_accuracy: 0.8428 - _timestamp: 1657488203.0000 - _runtime: 48.0000\n",
            "Epoch 41/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.8961 - val_loss: 0.3577 - val_accuracy: 0.8433 - _timestamp: 1657488203.0000 - _runtime: 48.0000\n",
            "Epoch 42/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2514 - accuracy: 0.8965 - val_loss: 0.3563 - val_accuracy: 0.8345 - _timestamp: 1657488204.0000 - _runtime: 49.0000\n",
            "Epoch 43/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2478 - accuracy: 0.8963 - val_loss: 0.3574 - val_accuracy: 0.8345 - _timestamp: 1657488204.0000 - _runtime: 49.0000\n",
            "Epoch 44/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2450 - accuracy: 0.8984 - val_loss: 0.3592 - val_accuracy: 0.8403 - _timestamp: 1657488205.0000 - _runtime: 50.0000\n",
            "Epoch 45/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.8998 - val_loss: 0.3582 - val_accuracy: 0.8395 - _timestamp: 1657488205.0000 - _runtime: 50.0000\n",
            "Epoch 46/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2414 - accuracy: 0.8993 - val_loss: 0.3631 - val_accuracy: 0.8435 - _timestamp: 1657488206.0000 - _runtime: 51.0000\n",
            "Epoch 47/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2415 - accuracy: 0.8998 - val_loss: 0.3611 - val_accuracy: 0.8390 - _timestamp: 1657488206.0000 - _runtime: 51.0000\n",
            "Epoch 48/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2396 - accuracy: 0.9010 - val_loss: 0.3586 - val_accuracy: 0.8325 - _timestamp: 1657488207.0000 - _runtime: 52.0000\n",
            "Epoch 49/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2340 - accuracy: 0.9044 - val_loss: 0.3616 - val_accuracy: 0.8327 - _timestamp: 1657488207.0000 - _runtime: 52.0000\n",
            "Epoch 50/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2362 - accuracy: 0.9030 - val_loss: 0.3641 - val_accuracy: 0.8385 - _timestamp: 1657488208.0000 - _runtime: 53.0000\n",
            "Epoch 51/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2304 - accuracy: 0.9053 - val_loss: 0.3648 - val_accuracy: 0.8292 - _timestamp: 1657488208.0000 - _runtime: 53.0000\n",
            "Epoch 52/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2285 - accuracy: 0.9057 - val_loss: 0.3658 - val_accuracy: 0.8388 - _timestamp: 1657488209.0000 - _runtime: 54.0000\n",
            "Epoch 53/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2269 - accuracy: 0.9057 - val_loss: 0.3640 - val_accuracy: 0.8390 - _timestamp: 1657488210.0000 - _runtime: 55.0000\n",
            "Epoch 54/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2284 - accuracy: 0.9074 - val_loss: 0.3649 - val_accuracy: 0.8375 - _timestamp: 1657488210.0000 - _runtime: 55.0000\n",
            "Epoch 55/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2260 - accuracy: 0.9050 - val_loss: 0.3703 - val_accuracy: 0.8390 - _timestamp: 1657488211.0000 - _runtime: 56.0000\n",
            "Epoch 56/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2216 - accuracy: 0.9086 - val_loss: 0.3678 - val_accuracy: 0.8360 - _timestamp: 1657488211.0000 - _runtime: 56.0000\n",
            "Epoch 57/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2209 - accuracy: 0.9077 - val_loss: 0.3712 - val_accuracy: 0.8388 - _timestamp: 1657488212.0000 - _runtime: 57.0000\n",
            "Epoch 58/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9086 - val_loss: 0.3711 - val_accuracy: 0.8322 - _timestamp: 1657488212.0000 - _runtime: 57.0000\n",
            "Epoch 59/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2204 - accuracy: 0.9097 - val_loss: 0.3708 - val_accuracy: 0.8348 - _timestamp: 1657488213.0000 - _runtime: 58.0000\n",
            "Epoch 60/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2162 - accuracy: 0.9115 - val_loss: 0.3728 - val_accuracy: 0.8390 - _timestamp: 1657488213.0000 - _runtime: 58.0000\n",
            "Epoch 61/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2146 - accuracy: 0.9113 - val_loss: 0.3715 - val_accuracy: 0.8350 - _timestamp: 1657488214.0000 - _runtime: 59.0000\n",
            "Epoch 62/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9121 - val_loss: 0.3734 - val_accuracy: 0.8363 - _timestamp: 1657488215.0000 - _runtime: 60.0000\n",
            "Epoch 63/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9130 - val_loss: 0.3728 - val_accuracy: 0.8325 - _timestamp: 1657488215.0000 - _runtime: 60.0000\n",
            "Epoch 64/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2062 - accuracy: 0.9170 - val_loss: 0.3778 - val_accuracy: 0.8360 - _timestamp: 1657488216.0000 - _runtime: 61.0000\n",
            "Epoch 65/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9166 - val_loss: 0.3753 - val_accuracy: 0.8365 - _timestamp: 1657488216.0000 - _runtime: 61.0000\n",
            "Epoch 66/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9161 - val_loss: 0.3772 - val_accuracy: 0.8350 - _timestamp: 1657488217.0000 - _runtime: 62.0000\n",
            "Epoch 67/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9189 - val_loss: 0.3756 - val_accuracy: 0.8272 - _timestamp: 1657488217.0000 - _runtime: 62.0000\n",
            "Epoch 68/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9156 - val_loss: 0.3761 - val_accuracy: 0.8317 - _timestamp: 1657488218.0000 - _runtime: 63.0000\n",
            "Epoch 69/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.9204 - val_loss: 0.3746 - val_accuracy: 0.8338 - _timestamp: 1657488218.0000 - _runtime: 63.0000\n",
            "Epoch 70/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1999 - accuracy: 0.9171 - val_loss: 0.3724 - val_accuracy: 0.8307 - _timestamp: 1657488219.0000 - _runtime: 64.0000\n",
            "Epoch 71/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1978 - accuracy: 0.9199 - val_loss: 0.3793 - val_accuracy: 0.8370 - _timestamp: 1657488219.0000 - _runtime: 64.0000\n",
            "Epoch 72/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1981 - accuracy: 0.9187 - val_loss: 0.3767 - val_accuracy: 0.8335 - _timestamp: 1657488220.0000 - _runtime: 65.0000\n",
            "Epoch 73/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1967 - accuracy: 0.9180 - val_loss: 0.3795 - val_accuracy: 0.8355 - _timestamp: 1657488220.0000 - _runtime: 65.0000\n",
            "Epoch 74/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1954 - accuracy: 0.9208 - val_loss: 0.3794 - val_accuracy: 0.8355 - _timestamp: 1657488221.0000 - _runtime: 66.0000\n",
            "Epoch 75/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1910 - accuracy: 0.9248 - val_loss: 0.3825 - val_accuracy: 0.8315 - _timestamp: 1657488222.0000 - _runtime: 67.0000\n",
            "Epoch 76/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1943 - accuracy: 0.9206 - val_loss: 0.3802 - val_accuracy: 0.8310 - _timestamp: 1657488222.0000 - _runtime: 67.0000\n",
            "Epoch 77/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1844 - accuracy: 0.9259 - val_loss: 0.3849 - val_accuracy: 0.8330 - _timestamp: 1657488223.0000 - _runtime: 68.0000\n",
            "Epoch 78/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.9250 - val_loss: 0.3830 - val_accuracy: 0.8325 - _timestamp: 1657488223.0000 - _runtime: 68.0000\n",
            "Epoch 79/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1868 - accuracy: 0.9238 - val_loss: 0.3892 - val_accuracy: 0.8338 - _timestamp: 1657488224.0000 - _runtime: 69.0000\n",
            "Epoch 80/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1843 - accuracy: 0.9259 - val_loss: 0.3916 - val_accuracy: 0.8373 - _timestamp: 1657488224.0000 - _runtime: 69.0000\n",
            "Epoch 81/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1848 - accuracy: 0.9284 - val_loss: 0.3863 - val_accuracy: 0.8365 - _timestamp: 1657488225.0000 - _runtime: 70.0000\n",
            "Epoch 82/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1823 - accuracy: 0.9293 - val_loss: 0.3907 - val_accuracy: 0.8365 - _timestamp: 1657488225.0000 - _runtime: 70.0000\n",
            "Epoch 83/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9291 - val_loss: 0.3908 - val_accuracy: 0.8355 - _timestamp: 1657488226.0000 - _runtime: 71.0000\n",
            "Epoch 84/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1838 - accuracy: 0.9273 - val_loss: 0.3911 - val_accuracy: 0.8302 - _timestamp: 1657488226.0000 - _runtime: 71.0000\n",
            "Epoch 85/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1825 - accuracy: 0.9256 - val_loss: 0.3895 - val_accuracy: 0.8270 - _timestamp: 1657488227.0000 - _runtime: 72.0000\n",
            "Epoch 86/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9284 - val_loss: 0.3970 - val_accuracy: 0.8300 - _timestamp: 1657488228.0000 - _runtime: 73.0000\n",
            "Epoch 87/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1793 - accuracy: 0.9274 - val_loss: 0.3915 - val_accuracy: 0.8307 - _timestamp: 1657488228.0000 - _runtime: 73.0000\n",
            "Epoch 88/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.9273 - val_loss: 0.4013 - val_accuracy: 0.8350 - _timestamp: 1657488229.0000 - _runtime: 74.0000\n",
            "Epoch 89/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1713 - accuracy: 0.9323 - val_loss: 0.3941 - val_accuracy: 0.8295 - _timestamp: 1657488229.0000 - _runtime: 74.0000\n",
            "Epoch 90/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.9331 - val_loss: 0.3949 - val_accuracy: 0.8307 - _timestamp: 1657488230.0000 - _runtime: 75.0000\n",
            "Epoch 91/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1774 - accuracy: 0.9260 - val_loss: 0.3949 - val_accuracy: 0.8365 - _timestamp: 1657488230.0000 - _runtime: 75.0000\n",
            "Epoch 92/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9307 - val_loss: 0.3934 - val_accuracy: 0.8310 - _timestamp: 1657488231.0000 - _runtime: 76.0000\n",
            "Epoch 93/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1752 - accuracy: 0.9289 - val_loss: 0.4012 - val_accuracy: 0.8282 - _timestamp: 1657488231.0000 - _runtime: 76.0000\n",
            "Epoch 94/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1690 - accuracy: 0.9304 - val_loss: 0.4015 - val_accuracy: 0.8332 - _timestamp: 1657488232.0000 - _runtime: 77.0000\n",
            "Epoch 95/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9320 - val_loss: 0.4070 - val_accuracy: 0.8245 - _timestamp: 1657488232.0000 - _runtime: 77.0000\n",
            "Epoch 96/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1671 - accuracy: 0.9313 - val_loss: 0.4016 - val_accuracy: 0.8255 - _timestamp: 1657488233.0000 - _runtime: 78.0000\n",
            "Epoch 97/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1670 - accuracy: 0.9335 - val_loss: 0.4012 - val_accuracy: 0.8307 - _timestamp: 1657488234.0000 - _runtime: 79.0000\n",
            "Epoch 98/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1665 - accuracy: 0.9326 - val_loss: 0.4040 - val_accuracy: 0.8262 - _timestamp: 1657488234.0000 - _runtime: 79.0000\n",
            "Epoch 99/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1613 - accuracy: 0.9351 - val_loss: 0.4067 - val_accuracy: 0.8338 - _timestamp: 1657488235.0000 - _runtime: 80.0000\n",
            "Epoch 100/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1649 - accuracy: 0.9331 - val_loss: 0.4061 - val_accuracy: 0.8312 - _timestamp: 1657488235.0000 - _runtime: 80.0000\n",
            "Epoch 101/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1648 - accuracy: 0.9343 - val_loss: 0.4061 - val_accuracy: 0.8327 - _timestamp: 1657488236.0000 - _runtime: 81.0000\n",
            "Epoch 102/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1620 - accuracy: 0.9356 - val_loss: 0.4109 - val_accuracy: 0.8345 - _timestamp: 1657488236.0000 - _runtime: 81.0000\n",
            "Epoch 103/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1622 - accuracy: 0.9355 - val_loss: 0.4104 - val_accuracy: 0.8330 - _timestamp: 1657488237.0000 - _runtime: 82.0000\n",
            "Epoch 104/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1604 - accuracy: 0.9350 - val_loss: 0.4132 - val_accuracy: 0.8302 - _timestamp: 1657488237.0000 - _runtime: 82.0000\n",
            "Epoch 105/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1566 - accuracy: 0.9363 - val_loss: 0.4155 - val_accuracy: 0.8358 - _timestamp: 1657488238.0000 - _runtime: 83.0000\n",
            "Epoch 106/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1574 - accuracy: 0.9356 - val_loss: 0.4139 - val_accuracy: 0.8327 - _timestamp: 1657488238.0000 - _runtime: 83.0000\n",
            "Epoch 107/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1564 - accuracy: 0.9361 - val_loss: 0.4151 - val_accuracy: 0.8322 - _timestamp: 1657488239.0000 - _runtime: 84.0000\n",
            "Epoch 108/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9385 - val_loss: 0.4187 - val_accuracy: 0.8312 - _timestamp: 1657488239.0000 - _runtime: 84.0000\n",
            "Epoch 109/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9381 - val_loss: 0.4176 - val_accuracy: 0.8272 - _timestamp: 1657488240.0000 - _runtime: 85.0000\n",
            "Epoch 110/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1484 - accuracy: 0.9409 - val_loss: 0.4263 - val_accuracy: 0.8315 - _timestamp: 1657488241.0000 - _runtime: 86.0000\n",
            "Epoch 111/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1524 - accuracy: 0.9363 - val_loss: 0.4164 - val_accuracy: 0.8310 - _timestamp: 1657488241.0000 - _runtime: 86.0000\n",
            "Epoch 112/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9375 - val_loss: 0.4176 - val_accuracy: 0.8315 - _timestamp: 1657488242.0000 - _runtime: 87.0000\n",
            "Epoch 113/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1540 - accuracy: 0.9392 - val_loss: 0.4206 - val_accuracy: 0.8215 - _timestamp: 1657488242.0000 - _runtime: 87.0000\n",
            "Epoch 114/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1526 - accuracy: 0.9369 - val_loss: 0.4212 - val_accuracy: 0.8307 - _timestamp: 1657488243.0000 - _runtime: 88.0000\n",
            "Epoch 115/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1502 - accuracy: 0.9397 - val_loss: 0.4197 - val_accuracy: 0.8330 - _timestamp: 1657488244.0000 - _runtime: 89.0000\n",
            "Epoch 116/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1512 - accuracy: 0.9390 - val_loss: 0.4260 - val_accuracy: 0.8332 - _timestamp: 1657488244.0000 - _runtime: 89.0000\n",
            "Epoch 117/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1507 - accuracy: 0.9377 - val_loss: 0.4240 - val_accuracy: 0.8348 - _timestamp: 1657488245.0000 - _runtime: 90.0000\n",
            "Epoch 118/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1531 - accuracy: 0.9374 - val_loss: 0.4253 - val_accuracy: 0.8262 - _timestamp: 1657488245.0000 - _runtime: 90.0000\n",
            "Epoch 119/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1464 - accuracy: 0.9407 - val_loss: 0.4227 - val_accuracy: 0.8290 - _timestamp: 1657488246.0000 - _runtime: 91.0000\n",
            "Epoch 120/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.9433 - val_loss: 0.4252 - val_accuracy: 0.8320 - _timestamp: 1657488246.0000 - _runtime: 91.0000\n",
            "Epoch 121/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1463 - accuracy: 0.9409 - val_loss: 0.4303 - val_accuracy: 0.8358 - _timestamp: 1657488247.0000 - _runtime: 92.0000\n",
            "Epoch 122/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9400 - val_loss: 0.4261 - val_accuracy: 0.8353 - _timestamp: 1657488247.0000 - _runtime: 92.0000\n",
            "Epoch 123/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.9410 - val_loss: 0.4259 - val_accuracy: 0.8292 - _timestamp: 1657488248.0000 - _runtime: 93.0000\n",
            "Epoch 124/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1417 - accuracy: 0.9439 - val_loss: 0.4332 - val_accuracy: 0.8322 - _timestamp: 1657488249.0000 - _runtime: 94.0000\n",
            "Epoch 125/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1445 - accuracy: 0.9412 - val_loss: 0.4330 - val_accuracy: 0.8350 - _timestamp: 1657488249.0000 - _runtime: 94.0000\n",
            "Epoch 126/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9443 - val_loss: 0.4347 - val_accuracy: 0.8300 - _timestamp: 1657488250.0000 - _runtime: 95.0000\n",
            "Epoch 127/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1441 - accuracy: 0.9420 - val_loss: 0.4338 - val_accuracy: 0.8307 - _timestamp: 1657488250.0000 - _runtime: 95.0000\n",
            "Epoch 128/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1415 - accuracy: 0.9423 - val_loss: 0.4361 - val_accuracy: 0.8315 - _timestamp: 1657488251.0000 - _runtime: 96.0000\n",
            "Epoch 129/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1416 - accuracy: 0.9412 - val_loss: 0.4384 - val_accuracy: 0.8317 - _timestamp: 1657488251.0000 - _runtime: 96.0000\n",
            "Epoch 130/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1393 - accuracy: 0.9426 - val_loss: 0.4370 - val_accuracy: 0.8310 - _timestamp: 1657488252.0000 - _runtime: 97.0000\n",
            "Epoch 131/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9408 - val_loss: 0.4291 - val_accuracy: 0.8332 - _timestamp: 1657488252.0000 - _runtime: 97.0000\n",
            "Epoch 132/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1411 - accuracy: 0.9407 - val_loss: 0.4389 - val_accuracy: 0.8310 - _timestamp: 1657488253.0000 - _runtime: 98.0000\n",
            "Epoch 133/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1367 - accuracy: 0.9450 - val_loss: 0.4423 - val_accuracy: 0.8320 - _timestamp: 1657488253.0000 - _runtime: 98.0000\n",
            "Epoch 134/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1374 - accuracy: 0.9455 - val_loss: 0.4423 - val_accuracy: 0.8305 - _timestamp: 1657488254.0000 - _runtime: 99.0000\n",
            "Epoch 135/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9438 - val_loss: 0.4402 - val_accuracy: 0.8322 - _timestamp: 1657488254.0000 - _runtime: 99.0000\n",
            "Epoch 136/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1343 - accuracy: 0.9456 - val_loss: 0.4443 - val_accuracy: 0.8348 - _timestamp: 1657488255.0000 - _runtime: 100.0000\n",
            "Epoch 137/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1387 - accuracy: 0.9437 - val_loss: 0.4402 - val_accuracy: 0.8265 - _timestamp: 1657488255.0000 - _runtime: 100.0000\n",
            "Epoch 138/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1343 - accuracy: 0.9467 - val_loss: 0.4449 - val_accuracy: 0.8257 - _timestamp: 1657488256.0000 - _runtime: 101.0000\n",
            "Epoch 139/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1338 - accuracy: 0.9464 - val_loss: 0.4492 - val_accuracy: 0.8327 - _timestamp: 1657488256.0000 - _runtime: 101.0000\n",
            "Epoch 140/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1326 - accuracy: 0.9469 - val_loss: 0.4466 - val_accuracy: 0.8322 - _timestamp: 1657488257.0000 - _runtime: 102.0000\n",
            "Epoch 141/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1340 - accuracy: 0.9475 - val_loss: 0.4484 - val_accuracy: 0.8287 - _timestamp: 1657488258.0000 - _runtime: 103.0000\n",
            "Epoch 142/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1329 - accuracy: 0.9466 - val_loss: 0.4493 - val_accuracy: 0.8255 - _timestamp: 1657488258.0000 - _runtime: 103.0000\n",
            "Epoch 143/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1378 - accuracy: 0.9437 - val_loss: 0.4421 - val_accuracy: 0.8305 - _timestamp: 1657488259.0000 - _runtime: 104.0000\n",
            "Epoch 144/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1285 - accuracy: 0.9496 - val_loss: 0.4530 - val_accuracy: 0.8295 - _timestamp: 1657488259.0000 - _runtime: 104.0000\n",
            "Epoch 145/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9480 - val_loss: 0.4563 - val_accuracy: 0.8290 - _timestamp: 1657488260.0000 - _runtime: 105.0000\n",
            "Epoch 146/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1304 - accuracy: 0.9480 - val_loss: 0.4511 - val_accuracy: 0.8285 - _timestamp: 1657488260.0000 - _runtime: 105.0000\n",
            "Epoch 147/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1292 - accuracy: 0.9478 - val_loss: 0.4503 - val_accuracy: 0.8215 - _timestamp: 1657488261.0000 - _runtime: 106.0000\n",
            "Epoch 148/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9480 - val_loss: 0.4490 - val_accuracy: 0.8265 - _timestamp: 1657488262.0000 - _runtime: 107.0000\n",
            "Epoch 149/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9497 - val_loss: 0.4502 - val_accuracy: 0.8322 - _timestamp: 1657488262.0000 - _runtime: 107.0000\n",
            "Epoch 150/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1343 - accuracy: 0.9448 - val_loss: 0.4519 - val_accuracy: 0.8202 - _timestamp: 1657488263.0000 - _runtime: 108.0000\n",
            "Epoch 151/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1315 - accuracy: 0.9475 - val_loss: 0.4580 - val_accuracy: 0.8322 - _timestamp: 1657488263.0000 - _runtime: 108.0000\n",
            "Epoch 152/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.9482 - val_loss: 0.4657 - val_accuracy: 0.8292 - _timestamp: 1657488264.0000 - _runtime: 109.0000\n",
            "Epoch 153/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1288 - accuracy: 0.9479 - val_loss: 0.4543 - val_accuracy: 0.8215 - _timestamp: 1657488264.0000 - _runtime: 109.0000\n",
            "Epoch 154/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1320 - accuracy: 0.9480 - val_loss: 0.4610 - val_accuracy: 0.8280 - _timestamp: 1657488265.0000 - _runtime: 110.0000\n",
            "Epoch 155/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1253 - accuracy: 0.9485 - val_loss: 0.4665 - val_accuracy: 0.8330 - _timestamp: 1657488266.0000 - _runtime: 111.0000\n",
            "Epoch 156/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1282 - accuracy: 0.9495 - val_loss: 0.4593 - val_accuracy: 0.8265 - _timestamp: 1657488266.0000 - _runtime: 111.0000\n",
            "Epoch 157/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1304 - accuracy: 0.9487 - val_loss: 0.4595 - val_accuracy: 0.8212 - _timestamp: 1657488267.0000 - _runtime: 112.0000\n",
            "Epoch 158/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1264 - accuracy: 0.9501 - val_loss: 0.4624 - val_accuracy: 0.8340 - _timestamp: 1657488267.0000 - _runtime: 112.0000\n",
            "Epoch 159/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1273 - accuracy: 0.9487 - val_loss: 0.4569 - val_accuracy: 0.8287 - _timestamp: 1657488268.0000 - _runtime: 113.0000\n",
            "Epoch 160/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1251 - accuracy: 0.9500 - val_loss: 0.4673 - val_accuracy: 0.8270 - _timestamp: 1657488268.0000 - _runtime: 113.0000\n",
            "Epoch 161/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9499 - val_loss: 0.4646 - val_accuracy: 0.8270 - _timestamp: 1657488269.0000 - _runtime: 114.0000\n",
            "Epoch 162/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9489 - val_loss: 0.4617 - val_accuracy: 0.8287 - _timestamp: 1657488269.0000 - _runtime: 114.0000\n",
            "Epoch 163/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9517 - val_loss: 0.4623 - val_accuracy: 0.8312 - _timestamp: 1657488270.0000 - _runtime: 115.0000\n",
            "Epoch 164/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1248 - accuracy: 0.9496 - val_loss: 0.4663 - val_accuracy: 0.8290 - _timestamp: 1657488270.0000 - _runtime: 115.0000\n",
            "Epoch 165/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9510 - val_loss: 0.4620 - val_accuracy: 0.8262 - _timestamp: 1657488271.0000 - _runtime: 116.0000\n",
            "Epoch 166/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.9500 - val_loss: 0.4704 - val_accuracy: 0.8305 - _timestamp: 1657488271.0000 - _runtime: 116.0000\n",
            "Epoch 167/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1234 - accuracy: 0.9499 - val_loss: 0.4659 - val_accuracy: 0.8247 - _timestamp: 1657488272.0000 - _runtime: 117.0000\n",
            "Epoch 168/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1177 - accuracy: 0.9529 - val_loss: 0.4685 - val_accuracy: 0.8250 - _timestamp: 1657488273.0000 - _runtime: 118.0000\n",
            "Epoch 169/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9525 - val_loss: 0.4679 - val_accuracy: 0.8292 - _timestamp: 1657488273.0000 - _runtime: 118.0000\n",
            "Epoch 170/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1231 - accuracy: 0.9494 - val_loss: 0.4711 - val_accuracy: 0.8295 - _timestamp: 1657488274.0000 - _runtime: 119.0000\n",
            "Epoch 171/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1209 - accuracy: 0.9511 - val_loss: 0.4704 - val_accuracy: 0.8302 - _timestamp: 1657488274.0000 - _runtime: 119.0000\n",
            "Epoch 172/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1137 - accuracy: 0.9547 - val_loss: 0.4722 - val_accuracy: 0.8287 - _timestamp: 1657488275.0000 - _runtime: 120.0000\n",
            "Epoch 173/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9512 - val_loss: 0.4717 - val_accuracy: 0.8262 - _timestamp: 1657488275.0000 - _runtime: 120.0000\n",
            "Epoch 174/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1158 - accuracy: 0.9536 - val_loss: 0.4814 - val_accuracy: 0.8260 - _timestamp: 1657488276.0000 - _runtime: 121.0000\n",
            "Epoch 175/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9507 - val_loss: 0.4753 - val_accuracy: 0.8302 - _timestamp: 1657488277.0000 - _runtime: 122.0000\n",
            "Epoch 176/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1151 - accuracy: 0.9553 - val_loss: 0.4766 - val_accuracy: 0.8282 - _timestamp: 1657488277.0000 - _runtime: 122.0000\n",
            "Epoch 177/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9529 - val_loss: 0.4753 - val_accuracy: 0.8250 - _timestamp: 1657488278.0000 - _runtime: 123.0000\n",
            "Epoch 178/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1158 - accuracy: 0.9526 - val_loss: 0.4775 - val_accuracy: 0.8277 - _timestamp: 1657488278.0000 - _runtime: 123.0000\n",
            "Epoch 179/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1163 - accuracy: 0.9535 - val_loss: 0.4815 - val_accuracy: 0.8285 - _timestamp: 1657488279.0000 - _runtime: 124.0000\n",
            "Epoch 180/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.9503 - val_loss: 0.4812 - val_accuracy: 0.8217 - _timestamp: 1657488279.0000 - _runtime: 124.0000\n",
            "Epoch 181/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1180 - accuracy: 0.9505 - val_loss: 0.4769 - val_accuracy: 0.8267 - _timestamp: 1657488280.0000 - _runtime: 125.0000\n",
            "Epoch 182/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1179 - accuracy: 0.9520 - val_loss: 0.4818 - val_accuracy: 0.8262 - _timestamp: 1657488280.0000 - _runtime: 125.0000\n",
            "Epoch 183/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1171 - accuracy: 0.9530 - val_loss: 0.4815 - val_accuracy: 0.8240 - _timestamp: 1657488281.0000 - _runtime: 126.0000\n",
            "Epoch 184/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9530 - val_loss: 0.4820 - val_accuracy: 0.8295 - _timestamp: 1657488282.0000 - _runtime: 127.0000\n",
            "Epoch 185/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1169 - accuracy: 0.9529 - val_loss: 0.4782 - val_accuracy: 0.8335 - _timestamp: 1657488282.0000 - _runtime: 127.0000\n",
            "Epoch 186/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9534 - val_loss: 0.4794 - val_accuracy: 0.8277 - _timestamp: 1657488283.0000 - _runtime: 128.0000\n",
            "Epoch 187/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9571 - val_loss: 0.4821 - val_accuracy: 0.8297 - _timestamp: 1657488283.0000 - _runtime: 128.0000\n",
            "Epoch 188/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9527 - val_loss: 0.4899 - val_accuracy: 0.8343 - _timestamp: 1657488284.0000 - _runtime: 129.0000\n",
            "Epoch 189/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9562 - val_loss: 0.4839 - val_accuracy: 0.8247 - _timestamp: 1657488284.0000 - _runtime: 129.0000\n",
            "Epoch 190/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9511 - val_loss: 0.4842 - val_accuracy: 0.8295 - _timestamp: 1657488285.0000 - _runtime: 130.0000\n",
            "Epoch 191/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9519 - val_loss: 0.4847 - val_accuracy: 0.8310 - _timestamp: 1657488285.0000 - _runtime: 130.0000\n",
            "Epoch 192/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1117 - accuracy: 0.9565 - val_loss: 0.4810 - val_accuracy: 0.8302 - _timestamp: 1657488286.0000 - _runtime: 131.0000\n",
            "Epoch 193/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1133 - accuracy: 0.9541 - val_loss: 0.4865 - val_accuracy: 0.8305 - _timestamp: 1657488287.0000 - _runtime: 132.0000\n",
            "Epoch 194/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1120 - accuracy: 0.9556 - val_loss: 0.4949 - val_accuracy: 0.8363 - _timestamp: 1657488287.0000 - _runtime: 132.0000\n",
            "Epoch 195/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9538 - val_loss: 0.4848 - val_accuracy: 0.8235 - _timestamp: 1657488288.0000 - _runtime: 133.0000\n",
            "Epoch 196/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1135 - accuracy: 0.9531 - val_loss: 0.4918 - val_accuracy: 0.8317 - _timestamp: 1657488288.0000 - _runtime: 133.0000\n",
            "Epoch 197/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1135 - accuracy: 0.9530 - val_loss: 0.4900 - val_accuracy: 0.8275 - _timestamp: 1657488289.0000 - _runtime: 134.0000\n",
            "Epoch 198/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9567 - val_loss: 0.4946 - val_accuracy: 0.8257 - _timestamp: 1657488289.0000 - _runtime: 134.0000\n",
            "Epoch 199/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9527 - val_loss: 0.4939 - val_accuracy: 0.8280 - _timestamp: 1657488290.0000 - _runtime: 135.0000\n",
            "Epoch 200/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9547 - val_loss: 0.4919 - val_accuracy: 0.8217 - _timestamp: 1657488290.0000 - _runtime: 135.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.591 MB of 0.591 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d9145b2c74c4bd9b4b47b2b82c6e7e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁</td></tr><tr><td>loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▇████▆█▇▆▆▅▅▅▆▆▅▃▆▅▅▃▆▅▅▃▄▃▄▅▄▃▃▄▄▆▆▂</td></tr><tr><td>val_loss</td><td>▃▂▂▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.84702</td></tr><tr><td>best_epoch</td><td>25</td></tr><tr><td>best_val_loss</td><td>0.34969</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>f1</td><td>0.90558</td></tr><tr><td>loss</td><td>0.11286</td></tr><tr><td>precision</td><td>0.86558</td></tr><tr><td>recall</td><td>0.94945</td></tr><tr><td>val_accuracy</td><td>0.82173</td></tr><tr><td>val_loss</td><td>0.49188</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">gossipcop-title-sbert-mlp-0</strong>: <a href=\"https://wandb.ai/saloniteam/nofolds/runs/aq9c1r9e\" target=\"_blank\">https://wandb.ai/saloniteam/nofolds/runs/aq9c1r9e</a><br/>Synced 5 W&B file(s), 2 media file(s), 1 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220710_212235-aq9c1r9e/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Embeddings"
      ],
      "metadata": {
        "id": "yoURIoYj_jd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = text_embeddings\n",
        "y = (df.label==\"real\").to_numpy().astype(int)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDIT3KyX_cu0",
        "outputId": "d29c543e-8120-4d71-c680-6cc7fdcf8c8d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19968, 768), (19968,))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(shuffle=True, random_state=124)"
      ],
      "metadata": {
        "id": "1NIo5zD7_cxT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROUP = f\"gossipcop-fulltext-sbert-mlp\"\n",
        "\n",
        "for fold_id, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "    clear_output()\n",
        "    with wandb.init(entity=\"saloniteam\", project=\"nofolds\", group=GROUP, name=f\"{GROUP}-{fold_id}\") as run:\n",
        "        train(fold_id, train_idx, test_idx, params)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0442043604d3420fbab729c19858bdf6",
            "f958e057bbfe445e8b92908bc7ce2b91",
            "f768d4de70d248989aa1a15de4083aed",
            "dd608d61e7c843e1b99b9b8ab0285c34",
            "2b793df4c5404cdc85653d68fe9cb41a",
            "8fc9a8ae4d454e758f7f764fe686d4c4",
            "39310d1ce6b44025a7e7cce81f91a8ba",
            "10b508d164f347db808a85335c1e0ad7"
          ]
        },
        "id": "pjNx8OYQ_nJZ",
        "outputId": "a3f7d73a-a8d5-4658-f7fb-a21672792989"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaloni\u001b[0m (\u001b[33msaloniteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220710_212522-1y3f8jkt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/saloniteam/nofolds/runs/1y3f8jkt\" target=\"_blank\">gossipcop-fulltext-sbert-mlp-0</a></strong> to <a href=\"https://wandb.ai/saloniteam/nofolds\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to compute FLOPs for this model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4739 - accuracy: 0.7473 - val_loss: 0.4088 - val_accuracy: 0.8197 - _timestamp: 1657488326.0000 - _runtime: 4.0000\n",
            "Epoch 2/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3866 - accuracy: 0.8247 - val_loss: 0.3890 - val_accuracy: 0.8192 - _timestamp: 1657488327.0000 - _runtime: 5.0000\n",
            "Epoch 3/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3726 - accuracy: 0.8355 - val_loss: 0.3820 - val_accuracy: 0.8340 - _timestamp: 1657488327.0000 - _runtime: 5.0000\n",
            "Epoch 4/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3643 - accuracy: 0.8374 - val_loss: 0.3774 - val_accuracy: 0.8340 - _timestamp: 1657488328.0000 - _runtime: 6.0000\n",
            "Epoch 5/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3589 - accuracy: 0.8401 - val_loss: 0.3732 - val_accuracy: 0.8403 - _timestamp: 1657488328.0000 - _runtime: 6.0000\n",
            "Epoch 6/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8427 - val_loss: 0.3687 - val_accuracy: 0.8385 - _timestamp: 1657488329.0000 - _runtime: 7.0000\n",
            "Epoch 7/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3455 - accuracy: 0.8460 - val_loss: 0.3670 - val_accuracy: 0.8425 - _timestamp: 1657488329.0000 - _runtime: 7.0000\n",
            "Epoch 8/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3403 - accuracy: 0.8476 - val_loss: 0.3649 - val_accuracy: 0.8430 - _timestamp: 1657488330.0000 - _runtime: 8.0000\n",
            "Epoch 9/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3363 - accuracy: 0.8522 - val_loss: 0.3597 - val_accuracy: 0.8415 - _timestamp: 1657488331.0000 - _runtime: 9.0000\n",
            "Epoch 10/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3317 - accuracy: 0.8546 - val_loss: 0.3566 - val_accuracy: 0.8390 - _timestamp: 1657488331.0000 - _runtime: 9.0000\n",
            "Epoch 11/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3294 - accuracy: 0.8547 - val_loss: 0.3546 - val_accuracy: 0.8400 - _timestamp: 1657488332.0000 - _runtime: 10.0000\n",
            "Epoch 12/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8555 - val_loss: 0.3541 - val_accuracy: 0.8415 - _timestamp: 1657488332.0000 - _runtime: 10.0000\n",
            "Epoch 13/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3216 - accuracy: 0.8602 - val_loss: 0.3533 - val_accuracy: 0.8483 - _timestamp: 1657488333.0000 - _runtime: 11.0000\n",
            "Epoch 14/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3182 - accuracy: 0.8604 - val_loss: 0.3542 - val_accuracy: 0.8498 - _timestamp: 1657488334.0000 - _runtime: 12.0000\n",
            "Epoch 15/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3149 - accuracy: 0.8615 - val_loss: 0.3494 - val_accuracy: 0.8473 - _timestamp: 1657488334.0000 - _runtime: 12.0000\n",
            "Epoch 16/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3161 - accuracy: 0.8618 - val_loss: 0.3499 - val_accuracy: 0.8503 - _timestamp: 1657488335.0000 - _runtime: 13.0000\n",
            "Epoch 17/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3110 - accuracy: 0.8659 - val_loss: 0.3481 - val_accuracy: 0.8543 - _timestamp: 1657488335.0000 - _runtime: 13.0000\n",
            "Epoch 18/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3058 - accuracy: 0.8670 - val_loss: 0.3475 - val_accuracy: 0.8510 - _timestamp: 1657488336.0000 - _runtime: 14.0000\n",
            "Epoch 19/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3030 - accuracy: 0.8704 - val_loss: 0.3470 - val_accuracy: 0.8503 - _timestamp: 1657488336.0000 - _runtime: 14.0000\n",
            "Epoch 20/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3007 - accuracy: 0.8716 - val_loss: 0.3469 - val_accuracy: 0.8515 - _timestamp: 1657488337.0000 - _runtime: 15.0000\n",
            "Epoch 21/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2993 - accuracy: 0.8696 - val_loss: 0.3448 - val_accuracy: 0.8495 - _timestamp: 1657488337.0000 - _runtime: 15.0000\n",
            "Epoch 22/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2964 - accuracy: 0.8729 - val_loss: 0.3491 - val_accuracy: 0.8555 - _timestamp: 1657488338.0000 - _runtime: 16.0000\n",
            "Epoch 23/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2913 - accuracy: 0.8744 - val_loss: 0.3467 - val_accuracy: 0.8543 - _timestamp: 1657488339.0000 - _runtime: 17.0000\n",
            "Epoch 24/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2894 - accuracy: 0.8745 - val_loss: 0.3467 - val_accuracy: 0.8515 - _timestamp: 1657488339.0000 - _runtime: 17.0000\n",
            "Epoch 25/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2885 - accuracy: 0.8777 - val_loss: 0.3438 - val_accuracy: 0.8500 - _timestamp: 1657488340.0000 - _runtime: 18.0000\n",
            "Epoch 26/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2843 - accuracy: 0.8809 - val_loss: 0.3433 - val_accuracy: 0.8478 - _timestamp: 1657488340.0000 - _runtime: 18.0000\n",
            "Epoch 27/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2826 - accuracy: 0.8790 - val_loss: 0.3445 - val_accuracy: 0.8535 - _timestamp: 1657488341.0000 - _runtime: 19.0000\n",
            "Epoch 28/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2804 - accuracy: 0.8816 - val_loss: 0.3471 - val_accuracy: 0.8540 - _timestamp: 1657488342.0000 - _runtime: 20.0000\n",
            "Epoch 29/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2781 - accuracy: 0.8827 - val_loss: 0.3433 - val_accuracy: 0.8503 - _timestamp: 1657488342.0000 - _runtime: 20.0000\n",
            "Epoch 30/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2758 - accuracy: 0.8821 - val_loss: 0.3446 - val_accuracy: 0.8538 - _timestamp: 1657488343.0000 - _runtime: 21.0000\n",
            "Epoch 31/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2730 - accuracy: 0.8863 - val_loss: 0.3426 - val_accuracy: 0.8520 - _timestamp: 1657488344.0000 - _runtime: 22.0000\n",
            "Epoch 32/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2670 - accuracy: 0.8864 - val_loss: 0.3436 - val_accuracy: 0.8513 - _timestamp: 1657488345.0000 - _runtime: 23.0000\n",
            "Epoch 33/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2700 - accuracy: 0.8846 - val_loss: 0.3431 - val_accuracy: 0.8510 - _timestamp: 1657488345.0000 - _runtime: 23.0000\n",
            "Epoch 34/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2669 - accuracy: 0.8859 - val_loss: 0.3449 - val_accuracy: 0.8525 - _timestamp: 1657488346.0000 - _runtime: 24.0000\n",
            "Epoch 35/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2638 - accuracy: 0.8894 - val_loss: 0.3515 - val_accuracy: 0.8558 - _timestamp: 1657488346.0000 - _runtime: 24.0000\n",
            "Epoch 36/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2599 - accuracy: 0.8909 - val_loss: 0.3464 - val_accuracy: 0.8503 - _timestamp: 1657488347.0000 - _runtime: 25.0000\n",
            "Epoch 37/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2601 - accuracy: 0.8918 - val_loss: 0.3457 - val_accuracy: 0.8473 - _timestamp: 1657488347.0000 - _runtime: 25.0000\n",
            "Epoch 38/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2603 - accuracy: 0.8880 - val_loss: 0.3443 - val_accuracy: 0.8505 - _timestamp: 1657488348.0000 - _runtime: 26.0000\n",
            "Epoch 39/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2567 - accuracy: 0.8925 - val_loss: 0.3429 - val_accuracy: 0.8465 - _timestamp: 1657488348.0000 - _runtime: 26.0000\n",
            "Epoch 40/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2559 - accuracy: 0.8947 - val_loss: 0.3464 - val_accuracy: 0.8538 - _timestamp: 1657488349.0000 - _runtime: 27.0000\n",
            "Epoch 41/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.8953 - val_loss: 0.3468 - val_accuracy: 0.8525 - _timestamp: 1657488349.0000 - _runtime: 27.0000\n",
            "Epoch 42/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2526 - accuracy: 0.8926 - val_loss: 0.3477 - val_accuracy: 0.8528 - _timestamp: 1657488350.0000 - _runtime: 28.0000\n",
            "Epoch 43/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2460 - accuracy: 0.8980 - val_loss: 0.3450 - val_accuracy: 0.8518 - _timestamp: 1657488350.0000 - _runtime: 28.0000\n",
            "Epoch 44/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2475 - accuracy: 0.8965 - val_loss: 0.3448 - val_accuracy: 0.8483 - _timestamp: 1657488351.0000 - _runtime: 29.0000\n",
            "Epoch 45/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2487 - accuracy: 0.8958 - val_loss: 0.3493 - val_accuracy: 0.8513 - _timestamp: 1657488352.0000 - _runtime: 30.0000\n",
            "Epoch 46/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2450 - accuracy: 0.8961 - val_loss: 0.3468 - val_accuracy: 0.8513 - _timestamp: 1657488352.0000 - _runtime: 30.0000\n",
            "Epoch 47/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2428 - accuracy: 0.8983 - val_loss: 0.3525 - val_accuracy: 0.8578 - _timestamp: 1657488353.0000 - _runtime: 31.0000\n",
            "Epoch 48/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2422 - accuracy: 0.8973 - val_loss: 0.3454 - val_accuracy: 0.8520 - _timestamp: 1657488353.0000 - _runtime: 31.0000\n",
            "Epoch 49/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2356 - accuracy: 0.9006 - val_loss: 0.3510 - val_accuracy: 0.8498 - _timestamp: 1657488354.0000 - _runtime: 32.0000\n",
            "Epoch 50/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2376 - accuracy: 0.9029 - val_loss: 0.3495 - val_accuracy: 0.8508 - _timestamp: 1657488354.0000 - _runtime: 32.0000\n",
            "Epoch 51/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2361 - accuracy: 0.9013 - val_loss: 0.3486 - val_accuracy: 0.8510 - _timestamp: 1657488355.0000 - _runtime: 33.0000\n",
            "Epoch 52/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2351 - accuracy: 0.9009 - val_loss: 0.3487 - val_accuracy: 0.8508 - _timestamp: 1657488356.0000 - _runtime: 34.0000\n",
            "Epoch 53/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2353 - accuracy: 0.9008 - val_loss: 0.3522 - val_accuracy: 0.8525 - _timestamp: 1657488356.0000 - _runtime: 34.0000\n",
            "Epoch 54/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2326 - accuracy: 0.9045 - val_loss: 0.3510 - val_accuracy: 0.8530 - _timestamp: 1657488357.0000 - _runtime: 35.0000\n",
            "Epoch 55/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2259 - accuracy: 0.9070 - val_loss: 0.3502 - val_accuracy: 0.8518 - _timestamp: 1657488357.0000 - _runtime: 35.0000\n",
            "Epoch 56/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2288 - accuracy: 0.9058 - val_loss: 0.3545 - val_accuracy: 0.8550 - _timestamp: 1657488358.0000 - _runtime: 36.0000\n",
            "Epoch 57/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2280 - accuracy: 0.9042 - val_loss: 0.3522 - val_accuracy: 0.8503 - _timestamp: 1657488358.0000 - _runtime: 36.0000\n",
            "Epoch 58/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2249 - accuracy: 0.9044 - val_loss: 0.3500 - val_accuracy: 0.8433 - _timestamp: 1657488359.0000 - _runtime: 37.0000\n",
            "Epoch 59/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2268 - accuracy: 0.9056 - val_loss: 0.3493 - val_accuracy: 0.8465 - _timestamp: 1657488359.0000 - _runtime: 37.0000\n",
            "Epoch 60/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2272 - accuracy: 0.9055 - val_loss: 0.3508 - val_accuracy: 0.8505 - _timestamp: 1657488360.0000 - _runtime: 38.0000\n",
            "Epoch 61/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9073 - val_loss: 0.3523 - val_accuracy: 0.8483 - _timestamp: 1657488360.0000 - _runtime: 38.0000\n",
            "Epoch 62/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2189 - accuracy: 0.9111 - val_loss: 0.3517 - val_accuracy: 0.8493 - _timestamp: 1657488361.0000 - _runtime: 39.0000\n",
            "Epoch 63/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2159 - accuracy: 0.9112 - val_loss: 0.3556 - val_accuracy: 0.8523 - _timestamp: 1657488362.0000 - _runtime: 40.0000\n",
            "Epoch 64/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2194 - accuracy: 0.9089 - val_loss: 0.3525 - val_accuracy: 0.8495 - _timestamp: 1657488362.0000 - _runtime: 40.0000\n",
            "Epoch 65/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2146 - accuracy: 0.9097 - val_loss: 0.3601 - val_accuracy: 0.8525 - _timestamp: 1657488363.0000 - _runtime: 41.0000\n",
            "Epoch 66/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2134 - accuracy: 0.9134 - val_loss: 0.3584 - val_accuracy: 0.8500 - _timestamp: 1657488363.0000 - _runtime: 41.0000\n",
            "Epoch 67/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9110 - val_loss: 0.3636 - val_accuracy: 0.8548 - _timestamp: 1657488364.0000 - _runtime: 42.0000\n",
            "Epoch 68/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2134 - accuracy: 0.9123 - val_loss: 0.3588 - val_accuracy: 0.8495 - _timestamp: 1657488364.0000 - _runtime: 42.0000\n",
            "Epoch 69/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9117 - val_loss: 0.3547 - val_accuracy: 0.8510 - _timestamp: 1657488365.0000 - _runtime: 43.0000\n",
            "Epoch 70/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9128 - val_loss: 0.3595 - val_accuracy: 0.8543 - _timestamp: 1657488366.0000 - _runtime: 44.0000\n",
            "Epoch 71/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9135 - val_loss: 0.3583 - val_accuracy: 0.8513 - _timestamp: 1657488366.0000 - _runtime: 44.0000\n",
            "Epoch 72/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2084 - accuracy: 0.9111 - val_loss: 0.3599 - val_accuracy: 0.8510 - _timestamp: 1657488367.0000 - _runtime: 45.0000\n",
            "Epoch 73/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9125 - val_loss: 0.3616 - val_accuracy: 0.8535 - _timestamp: 1657488367.0000 - _runtime: 45.0000\n",
            "Epoch 74/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2053 - accuracy: 0.9162 - val_loss: 0.3623 - val_accuracy: 0.8518 - _timestamp: 1657488368.0000 - _runtime: 46.0000\n",
            "Epoch 75/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9161 - val_loss: 0.3607 - val_accuracy: 0.8488 - _timestamp: 1657488368.0000 - _runtime: 46.0000\n",
            "Epoch 76/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1989 - accuracy: 0.9194 - val_loss: 0.3601 - val_accuracy: 0.8530 - _timestamp: 1657488369.0000 - _runtime: 47.0000\n",
            "Epoch 77/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2004 - accuracy: 0.9174 - val_loss: 0.3697 - val_accuracy: 0.8555 - _timestamp: 1657488369.0000 - _runtime: 47.0000\n",
            "Epoch 78/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9173 - val_loss: 0.3636 - val_accuracy: 0.8490 - _timestamp: 1657488370.0000 - _runtime: 48.0000\n",
            "Epoch 79/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2018 - accuracy: 0.9178 - val_loss: 0.3658 - val_accuracy: 0.8510 - _timestamp: 1657488370.0000 - _runtime: 48.0000\n",
            "Epoch 80/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1988 - accuracy: 0.9186 - val_loss: 0.3628 - val_accuracy: 0.8503 - _timestamp: 1657488371.0000 - _runtime: 49.0000\n",
            "Epoch 81/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1965 - accuracy: 0.9191 - val_loss: 0.3646 - val_accuracy: 0.8495 - _timestamp: 1657488371.0000 - _runtime: 49.0000\n",
            "Epoch 82/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1963 - accuracy: 0.9188 - val_loss: 0.3670 - val_accuracy: 0.8508 - _timestamp: 1657488372.0000 - _runtime: 50.0000\n",
            "Epoch 83/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1944 - accuracy: 0.9206 - val_loss: 0.3799 - val_accuracy: 0.8575 - _timestamp: 1657488373.0000 - _runtime: 51.0000\n",
            "Epoch 84/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9190 - val_loss: 0.3688 - val_accuracy: 0.8518 - _timestamp: 1657488373.0000 - _runtime: 51.0000\n",
            "Epoch 85/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1931 - accuracy: 0.9191 - val_loss: 0.3678 - val_accuracy: 0.8503 - _timestamp: 1657488374.0000 - _runtime: 52.0000\n",
            "Epoch 86/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1909 - accuracy: 0.9214 - val_loss: 0.3664 - val_accuracy: 0.8493 - _timestamp: 1657488374.0000 - _runtime: 52.0000\n",
            "Epoch 87/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1958 - accuracy: 0.9202 - val_loss: 0.3680 - val_accuracy: 0.8498 - _timestamp: 1657488375.0000 - _runtime: 53.0000\n",
            "Epoch 88/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1895 - accuracy: 0.9223 - val_loss: 0.3693 - val_accuracy: 0.8478 - _timestamp: 1657488375.0000 - _runtime: 53.0000\n",
            "Epoch 89/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1932 - accuracy: 0.9197 - val_loss: 0.3671 - val_accuracy: 0.8493 - _timestamp: 1657488376.0000 - _runtime: 54.0000\n",
            "Epoch 90/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1947 - accuracy: 0.9207 - val_loss: 0.3676 - val_accuracy: 0.8505 - _timestamp: 1657488377.0000 - _runtime: 55.0000\n",
            "Epoch 91/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1876 - accuracy: 0.9249 - val_loss: 0.3793 - val_accuracy: 0.8533 - _timestamp: 1657488377.0000 - _runtime: 55.0000\n",
            "Epoch 92/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1911 - accuracy: 0.9222 - val_loss: 0.3713 - val_accuracy: 0.8510 - _timestamp: 1657488378.0000 - _runtime: 56.0000\n",
            "Epoch 93/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9220 - val_loss: 0.3685 - val_accuracy: 0.8518 - _timestamp: 1657488378.0000 - _runtime: 56.0000\n",
            "Epoch 94/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1874 - accuracy: 0.9220 - val_loss: 0.3756 - val_accuracy: 0.8543 - _timestamp: 1657488379.0000 - _runtime: 57.0000\n",
            "Epoch 95/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1860 - accuracy: 0.9230 - val_loss: 0.3749 - val_accuracy: 0.8503 - _timestamp: 1657488379.0000 - _runtime: 57.0000\n",
            "Epoch 96/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1842 - accuracy: 0.9244 - val_loss: 0.3719 - val_accuracy: 0.8500 - _timestamp: 1657488380.0000 - _runtime: 58.0000\n",
            "Epoch 97/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1849 - accuracy: 0.9232 - val_loss: 0.3730 - val_accuracy: 0.8495 - _timestamp: 1657488380.0000 - _runtime: 58.0000\n",
            "Epoch 98/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1825 - accuracy: 0.9257 - val_loss: 0.3788 - val_accuracy: 0.8510 - _timestamp: 1657488381.0000 - _runtime: 59.0000\n",
            "Epoch 99/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1825 - accuracy: 0.9252 - val_loss: 0.3802 - val_accuracy: 0.8520 - _timestamp: 1657488381.0000 - _runtime: 59.0000\n",
            "Epoch 100/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1813 - accuracy: 0.9241 - val_loss: 0.3743 - val_accuracy: 0.8488 - _timestamp: 1657488382.0000 - _runtime: 60.0000\n",
            "Epoch 101/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1791 - accuracy: 0.9266 - val_loss: 0.3792 - val_accuracy: 0.8508 - _timestamp: 1657488383.0000 - _runtime: 61.0000\n",
            "Epoch 102/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9258 - val_loss: 0.3735 - val_accuracy: 0.8513 - _timestamp: 1657488383.0000 - _runtime: 61.0000\n",
            "Epoch 103/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1800 - accuracy: 0.9240 - val_loss: 0.3808 - val_accuracy: 0.8500 - _timestamp: 1657488384.0000 - _runtime: 62.0000\n",
            "Epoch 104/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1831 - accuracy: 0.9235 - val_loss: 0.3753 - val_accuracy: 0.8498 - _timestamp: 1657488384.0000 - _runtime: 62.0000\n",
            "Epoch 105/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1744 - accuracy: 0.9266 - val_loss: 0.3821 - val_accuracy: 0.8538 - _timestamp: 1657488385.0000 - _runtime: 63.0000\n",
            "Epoch 106/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1790 - accuracy: 0.9274 - val_loss: 0.3770 - val_accuracy: 0.8503 - _timestamp: 1657488385.0000 - _runtime: 63.0000\n",
            "Epoch 107/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1766 - accuracy: 0.9279 - val_loss: 0.3841 - val_accuracy: 0.8508 - _timestamp: 1657488386.0000 - _runtime: 64.0000\n",
            "Epoch 108/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1758 - accuracy: 0.9262 - val_loss: 0.3804 - val_accuracy: 0.8490 - _timestamp: 1657488386.0000 - _runtime: 64.0000\n",
            "Epoch 109/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.9293 - val_loss: 0.3840 - val_accuracy: 0.8478 - _timestamp: 1657488387.0000 - _runtime: 65.0000\n",
            "Epoch 110/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9300 - val_loss: 0.3848 - val_accuracy: 0.8498 - _timestamp: 1657488387.0000 - _runtime: 65.0000\n",
            "Epoch 111/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1729 - accuracy: 0.9276 - val_loss: 0.3847 - val_accuracy: 0.8498 - _timestamp: 1657488388.0000 - _runtime: 66.0000\n",
            "Epoch 112/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1786 - accuracy: 0.9262 - val_loss: 0.3821 - val_accuracy: 0.8528 - _timestamp: 1657488389.0000 - _runtime: 67.0000\n",
            "Epoch 113/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1731 - accuracy: 0.9284 - val_loss: 0.3907 - val_accuracy: 0.8533 - _timestamp: 1657488389.0000 - _runtime: 67.0000\n",
            "Epoch 114/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1721 - accuracy: 0.9298 - val_loss: 0.3834 - val_accuracy: 0.8485 - _timestamp: 1657488390.0000 - _runtime: 68.0000\n",
            "Epoch 115/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9311 - val_loss: 0.3862 - val_accuracy: 0.8488 - _timestamp: 1657488390.0000 - _runtime: 68.0000\n",
            "Epoch 116/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1679 - accuracy: 0.9311 - val_loss: 0.3859 - val_accuracy: 0.8480 - _timestamp: 1657488391.0000 - _runtime: 69.0000\n",
            "Epoch 117/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1704 - accuracy: 0.9291 - val_loss: 0.3894 - val_accuracy: 0.8510 - _timestamp: 1657488391.0000 - _runtime: 69.0000\n",
            "Epoch 118/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1637 - accuracy: 0.9341 - val_loss: 0.3943 - val_accuracy: 0.8498 - _timestamp: 1657488392.0000 - _runtime: 70.0000\n",
            "Epoch 119/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9309 - val_loss: 0.3856 - val_accuracy: 0.8505 - _timestamp: 1657488392.0000 - _runtime: 70.0000\n",
            "Epoch 120/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9316 - val_loss: 0.3857 - val_accuracy: 0.8498 - _timestamp: 1657488393.0000 - _runtime: 71.0000\n",
            "Epoch 121/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1674 - accuracy: 0.9304 - val_loss: 0.3885 - val_accuracy: 0.8503 - _timestamp: 1657488393.0000 - _runtime: 71.0000\n",
            "Epoch 122/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1654 - accuracy: 0.9336 - val_loss: 0.3899 - val_accuracy: 0.8565 - _timestamp: 1657488394.0000 - _runtime: 72.0000\n",
            "Epoch 123/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1594 - accuracy: 0.9361 - val_loss: 0.3936 - val_accuracy: 0.8483 - _timestamp: 1657488395.0000 - _runtime: 73.0000\n",
            "Epoch 124/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9303 - val_loss: 0.3878 - val_accuracy: 0.8475 - _timestamp: 1657488395.0000 - _runtime: 73.0000\n",
            "Epoch 125/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1606 - accuracy: 0.9340 - val_loss: 0.3940 - val_accuracy: 0.8508 - _timestamp: 1657488396.0000 - _runtime: 74.0000\n",
            "Epoch 126/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1672 - accuracy: 0.9313 - val_loss: 0.3864 - val_accuracy: 0.8475 - _timestamp: 1657488396.0000 - _runtime: 74.0000\n",
            "Epoch 127/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1617 - accuracy: 0.9356 - val_loss: 0.3940 - val_accuracy: 0.8523 - _timestamp: 1657488397.0000 - _runtime: 75.0000\n",
            "Epoch 128/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9358 - val_loss: 0.3929 - val_accuracy: 0.8540 - _timestamp: 1657488397.0000 - _runtime: 75.0000\n",
            "Epoch 129/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1594 - accuracy: 0.9351 - val_loss: 0.3964 - val_accuracy: 0.8540 - _timestamp: 1657488398.0000 - _runtime: 76.0000\n",
            "Epoch 130/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1595 - accuracy: 0.9349 - val_loss: 0.3926 - val_accuracy: 0.8498 - _timestamp: 1657488398.0000 - _runtime: 76.0000\n",
            "Epoch 131/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1615 - accuracy: 0.9333 - val_loss: 0.3945 - val_accuracy: 0.8518 - _timestamp: 1657488399.0000 - _runtime: 77.0000\n",
            "Epoch 132/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1543 - accuracy: 0.9373 - val_loss: 0.4034 - val_accuracy: 0.8580 - _timestamp: 1657488399.0000 - _runtime: 77.0000\n",
            "Epoch 133/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1606 - accuracy: 0.9339 - val_loss: 0.4066 - val_accuracy: 0.8583 - _timestamp: 1657488400.0000 - _runtime: 78.0000\n",
            "Epoch 134/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1556 - accuracy: 0.9378 - val_loss: 0.4028 - val_accuracy: 0.8550 - _timestamp: 1657488401.0000 - _runtime: 79.0000\n",
            "Epoch 135/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1567 - accuracy: 0.9352 - val_loss: 0.4078 - val_accuracy: 0.8520 - _timestamp: 1657488401.0000 - _runtime: 79.0000\n",
            "Epoch 136/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9395 - val_loss: 0.3964 - val_accuracy: 0.8500 - _timestamp: 1657488402.0000 - _runtime: 80.0000\n",
            "Epoch 137/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1561 - accuracy: 0.9365 - val_loss: 0.3977 - val_accuracy: 0.8545 - _timestamp: 1657488402.0000 - _runtime: 80.0000\n",
            "Epoch 138/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1514 - accuracy: 0.9395 - val_loss: 0.4040 - val_accuracy: 0.8568 - _timestamp: 1657488403.0000 - _runtime: 81.0000\n",
            "Epoch 139/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9370 - val_loss: 0.4019 - val_accuracy: 0.8568 - _timestamp: 1657488403.0000 - _runtime: 81.0000\n",
            "Epoch 140/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1558 - accuracy: 0.9370 - val_loss: 0.4032 - val_accuracy: 0.8575 - _timestamp: 1657488404.0000 - _runtime: 82.0000\n",
            "Epoch 141/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1598 - accuracy: 0.9328 - val_loss: 0.4071 - val_accuracy: 0.8550 - _timestamp: 1657488404.0000 - _runtime: 82.0000\n",
            "Epoch 142/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9366 - val_loss: 0.4009 - val_accuracy: 0.8470 - _timestamp: 1657488405.0000 - _runtime: 83.0000\n",
            "Epoch 143/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9373 - val_loss: 0.4113 - val_accuracy: 0.8530 - _timestamp: 1657488406.0000 - _runtime: 84.0000\n",
            "Epoch 144/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9377 - val_loss: 0.4099 - val_accuracy: 0.8560 - _timestamp: 1657488406.0000 - _runtime: 84.0000\n",
            "Epoch 145/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9385 - val_loss: 0.4068 - val_accuracy: 0.8555 - _timestamp: 1657488407.0000 - _runtime: 85.0000\n",
            "Epoch 146/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1554 - accuracy: 0.9355 - val_loss: 0.4049 - val_accuracy: 0.8523 - _timestamp: 1657488407.0000 - _runtime: 85.0000\n",
            "Epoch 147/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1527 - accuracy: 0.9372 - val_loss: 0.4071 - val_accuracy: 0.8490 - _timestamp: 1657488408.0000 - _runtime: 86.0000\n",
            "Epoch 148/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1469 - accuracy: 0.9406 - val_loss: 0.4075 - val_accuracy: 0.8475 - _timestamp: 1657488408.0000 - _runtime: 86.0000\n",
            "Epoch 149/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9374 - val_loss: 0.4114 - val_accuracy: 0.8543 - _timestamp: 1657488409.0000 - _runtime: 87.0000\n",
            "Epoch 150/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1476 - accuracy: 0.9390 - val_loss: 0.4227 - val_accuracy: 0.8550 - _timestamp: 1657488409.0000 - _runtime: 87.0000\n",
            "Epoch 151/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9407 - val_loss: 0.4111 - val_accuracy: 0.8473 - _timestamp: 1657488410.0000 - _runtime: 88.0000\n",
            "Epoch 152/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1479 - accuracy: 0.9392 - val_loss: 0.4076 - val_accuracy: 0.8500 - _timestamp: 1657488410.0000 - _runtime: 88.0000\n",
            "Epoch 153/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1482 - accuracy: 0.9413 - val_loss: 0.4044 - val_accuracy: 0.8463 - _timestamp: 1657488411.0000 - _runtime: 89.0000\n",
            "Epoch 154/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1481 - accuracy: 0.9405 - val_loss: 0.4119 - val_accuracy: 0.8525 - _timestamp: 1657488412.0000 - _runtime: 90.0000\n",
            "Epoch 155/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9420 - val_loss: 0.4117 - val_accuracy: 0.8520 - _timestamp: 1657488412.0000 - _runtime: 90.0000\n",
            "Epoch 156/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9383 - val_loss: 0.4051 - val_accuracy: 0.8513 - _timestamp: 1657488413.0000 - _runtime: 91.0000\n",
            "Epoch 157/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9412 - val_loss: 0.4087 - val_accuracy: 0.8478 - _timestamp: 1657488413.0000 - _runtime: 91.0000\n",
            "Epoch 158/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1408 - accuracy: 0.9432 - val_loss: 0.4138 - val_accuracy: 0.8523 - _timestamp: 1657488414.0000 - _runtime: 92.0000\n",
            "Epoch 159/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9381 - val_loss: 0.4093 - val_accuracy: 0.8490 - _timestamp: 1657488415.0000 - _runtime: 93.0000\n",
            "Epoch 160/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9419 - val_loss: 0.4120 - val_accuracy: 0.8510 - _timestamp: 1657488415.0000 - _runtime: 93.0000\n",
            "Epoch 161/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1441 - accuracy: 0.9400 - val_loss: 0.4070 - val_accuracy: 0.8490 - _timestamp: 1657488416.0000 - _runtime: 94.0000\n",
            "Epoch 162/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9392 - val_loss: 0.4105 - val_accuracy: 0.8518 - _timestamp: 1657488416.0000 - _runtime: 94.0000\n",
            "Epoch 163/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1466 - accuracy: 0.9403 - val_loss: 0.4166 - val_accuracy: 0.8515 - _timestamp: 1657488417.0000 - _runtime: 95.0000\n",
            "Epoch 164/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1400 - accuracy: 0.9432 - val_loss: 0.4189 - val_accuracy: 0.8510 - _timestamp: 1657488417.0000 - _runtime: 95.0000\n",
            "Epoch 165/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1429 - accuracy: 0.9411 - val_loss: 0.4127 - val_accuracy: 0.8448 - _timestamp: 1657488418.0000 - _runtime: 96.0000\n",
            "Epoch 166/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1410 - accuracy: 0.9430 - val_loss: 0.4165 - val_accuracy: 0.8493 - _timestamp: 1657488418.0000 - _runtime: 96.0000\n",
            "Epoch 167/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1398 - accuracy: 0.9433 - val_loss: 0.4172 - val_accuracy: 0.8523 - _timestamp: 1657488419.0000 - _runtime: 97.0000\n",
            "Epoch 168/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1426 - accuracy: 0.9410 - val_loss: 0.4172 - val_accuracy: 0.8518 - _timestamp: 1657488419.0000 - _runtime: 97.0000\n",
            "Epoch 169/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9423 - val_loss: 0.4166 - val_accuracy: 0.8510 - _timestamp: 1657488420.0000 - _runtime: 98.0000\n",
            "Epoch 170/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1416 - accuracy: 0.9415 - val_loss: 0.4169 - val_accuracy: 0.8503 - _timestamp: 1657488420.0000 - _runtime: 98.0000\n",
            "Epoch 171/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1391 - accuracy: 0.9427 - val_loss: 0.4189 - val_accuracy: 0.8548 - _timestamp: 1657488421.0000 - _runtime: 99.0000\n",
            "Epoch 172/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1388 - accuracy: 0.9417 - val_loss: 0.4276 - val_accuracy: 0.8548 - _timestamp: 1657488422.0000 - _runtime: 100.0000\n",
            "Epoch 173/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1352 - accuracy: 0.9448 - val_loss: 0.4264 - val_accuracy: 0.8545 - _timestamp: 1657488422.0000 - _runtime: 100.0000\n",
            "Epoch 174/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1421 - accuracy: 0.9422 - val_loss: 0.4183 - val_accuracy: 0.8480 - _timestamp: 1657488423.0000 - _runtime: 101.0000\n",
            "Epoch 175/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1350 - accuracy: 0.9456 - val_loss: 0.4237 - val_accuracy: 0.8525 - _timestamp: 1657488423.0000 - _runtime: 101.0000\n",
            "Epoch 176/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1401 - accuracy: 0.9432 - val_loss: 0.4328 - val_accuracy: 0.8520 - _timestamp: 1657488424.0000 - _runtime: 102.0000\n",
            "Epoch 177/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9428 - val_loss: 0.4209 - val_accuracy: 0.8505 - _timestamp: 1657488424.0000 - _runtime: 102.0000\n",
            "Epoch 178/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9455 - val_loss: 0.4261 - val_accuracy: 0.8498 - _timestamp: 1657488425.0000 - _runtime: 103.0000\n",
            "Epoch 179/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1388 - accuracy: 0.9442 - val_loss: 0.4191 - val_accuracy: 0.8480 - _timestamp: 1657488425.0000 - _runtime: 103.0000\n",
            "Epoch 180/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9425 - val_loss: 0.4219 - val_accuracy: 0.8510 - _timestamp: 1657488426.0000 - _runtime: 104.0000\n",
            "Epoch 181/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1372 - accuracy: 0.9440 - val_loss: 0.4244 - val_accuracy: 0.8500 - _timestamp: 1657488426.0000 - _runtime: 104.0000\n",
            "Epoch 182/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1338 - accuracy: 0.9452 - val_loss: 0.4292 - val_accuracy: 0.8515 - _timestamp: 1657488427.0000 - _runtime: 105.0000\n",
            "Epoch 183/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9428 - val_loss: 0.4253 - val_accuracy: 0.8513 - _timestamp: 1657488427.0000 - _runtime: 105.0000\n",
            "Epoch 184/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1373 - accuracy: 0.9448 - val_loss: 0.4242 - val_accuracy: 0.8463 - _timestamp: 1657488428.0000 - _runtime: 106.0000\n",
            "Epoch 185/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1324 - accuracy: 0.9460 - val_loss: 0.4317 - val_accuracy: 0.8545 - _timestamp: 1657488428.0000 - _runtime: 106.0000\n",
            "Epoch 186/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1346 - accuracy: 0.9450 - val_loss: 0.4178 - val_accuracy: 0.8448 - _timestamp: 1657488429.0000 - _runtime: 107.0000\n",
            "Epoch 187/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1361 - accuracy: 0.9445 - val_loss: 0.4208 - val_accuracy: 0.8515 - _timestamp: 1657488430.0000 - _runtime: 108.0000\n",
            "Epoch 188/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1354 - accuracy: 0.9437 - val_loss: 0.4237 - val_accuracy: 0.8475 - _timestamp: 1657488430.0000 - _runtime: 108.0000\n",
            "Epoch 189/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1335 - accuracy: 0.9450 - val_loss: 0.4260 - val_accuracy: 0.8473 - _timestamp: 1657488431.0000 - _runtime: 109.0000\n",
            "Epoch 190/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9455 - val_loss: 0.4263 - val_accuracy: 0.8498 - _timestamp: 1657488431.0000 - _runtime: 109.0000\n",
            "Epoch 191/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1305 - accuracy: 0.9457 - val_loss: 0.4416 - val_accuracy: 0.8495 - _timestamp: 1657488432.0000 - _runtime: 110.0000\n",
            "Epoch 192/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1391 - accuracy: 0.9425 - val_loss: 0.4293 - val_accuracy: 0.8483 - _timestamp: 1657488432.0000 - _runtime: 110.0000\n",
            "Epoch 193/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1383 - accuracy: 0.9440 - val_loss: 0.4410 - val_accuracy: 0.8508 - _timestamp: 1657488433.0000 - _runtime: 111.0000\n",
            "Epoch 194/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1309 - accuracy: 0.9476 - val_loss: 0.4348 - val_accuracy: 0.8505 - _timestamp: 1657488434.0000 - _runtime: 112.0000\n",
            "Epoch 195/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.9455 - val_loss: 0.4307 - val_accuracy: 0.8515 - _timestamp: 1657488434.0000 - _runtime: 112.0000\n",
            "Epoch 196/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9465 - val_loss: 0.4404 - val_accuracy: 0.8550 - _timestamp: 1657488435.0000 - _runtime: 113.0000\n",
            "Epoch 197/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1316 - accuracy: 0.9469 - val_loss: 0.4351 - val_accuracy: 0.8525 - _timestamp: 1657488435.0000 - _runtime: 113.0000\n",
            "Epoch 198/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1331 - accuracy: 0.9457 - val_loss: 0.4297 - val_accuracy: 0.8510 - _timestamp: 1657488436.0000 - _runtime: 114.0000\n",
            "Epoch 199/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1328 - accuracy: 0.9460 - val_loss: 0.4275 - val_accuracy: 0.8488 - _timestamp: 1657488436.0000 - _runtime: 114.0000\n",
            "Epoch 200/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9480 - val_loss: 0.4292 - val_accuracy: 0.8465 - _timestamp: 1657488437.0000 - _runtime: 115.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.591 MB of 0.591 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.999737…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0442043604d3420fbab729c19858bdf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁</td></tr><tr><td>loss</td><td>█▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅▇█▆▇▇▇▇▇█▇▇▇▇▇▆▇▇▇▇▇▇█▇███▆▇▇▇▇▆▇▆▆▇▆</td></tr><tr><td>val_loss</td><td>▅▃▂▂▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85653</td></tr><tr><td>best_epoch</td><td>30</td></tr><tr><td>best_val_loss</td><td>0.3426</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>f1</td><td>0.91079</td></tr><tr><td>loss</td><td>0.13062</td></tr><tr><td>precision</td><td>0.87654</td></tr><tr><td>recall</td><td>0.94783</td></tr><tr><td>val_accuracy</td><td>0.84652</td></tr><tr><td>val_loss</td><td>0.42919</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">gossipcop-fulltext-sbert-mlp-0</strong>: <a href=\"https://wandb.ai/saloniteam/nofolds/runs/1y3f8jkt\" target=\"_blank\">https://wandb.ai/saloniteam/nofolds/runs/1y3f8jkt</a><br/>Synced 5 W&B file(s), 2 media file(s), 1 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220710_212522-1y3f8jkt/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-mef-FcU_nL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}