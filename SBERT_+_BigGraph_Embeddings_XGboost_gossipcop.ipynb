{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verma-saloni/Thesis-Work/blob/main/SBERT_%2B_BigGraph_Embeddings_XGboost_gossipcop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "!pip install -U xgboost sentence-transformers wandb"
      ],
      "metadata": {
        "id": "aByzVMdkzqAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8b7ba0-fc97-41e3-ef9a-7c7c242fa360"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 255.9 MB 44 kB/s \n",
            "\u001b[?25hCollecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.13.4-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 60.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 67.8 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 72.6 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 67.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 74.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 69.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 66.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 69.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 74.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 74.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers, pathtools\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=25752d3a5830ee9df5a9466258607cafa75b88f46e5c8b2a323fc25f3e3e26b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=2c628a29b42531be7bc66648fd45b02d88161049a556f13ad5260372dc31f14c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built sentence-transformers pathtools\n",
            "Installing collected packages: smmap, tokenizers, huggingface-hub, gitdb, transformers, shortuuid, setproctitle, sentry-sdk, sentencepiece, pathtools, GitPython, docker-pycreds, xgboost, wandb, sentence-transformers\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 huggingface-hub-0.10.1 pathtools-0.1.2 sentence-transformers-2.2.2 sentencepiece-0.1.97 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 tokenizers-0.13.1 transformers-4.23.1 wandb-0.13.4 xgboost-1.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook for SBERt+Biggraph embeddings, for Gossipcop dataset. Logged results on Wandb (saloniteam project)"
      ],
      "metadata": {
        "id": "XpfK1y8X_Tkh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8wffusyCytsx"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "\n",
        "from sentence_transformers import SentenceTransformer \n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import xgboost as xgb\n",
        "\n",
        "import wandb\n",
        "from wandb.xgboost import WandbCallback\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [accuracy_score, f1_score, precision_score, recall_score]\n",
        "\n",
        "def get_name(score_func):\n",
        "    return score_func.__name__.split(\"_\")[0]"
      ],
      "metadata": {
        "id": "oUUMZeWMuZXE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "R_4mZElNIVb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_dir = Path(\"/content/drive/MyDrive/ResearchFND\")\n",
        "assert base_dir.exists()"
      ],
      "metadata": {
        "id": "UxNEaltli8H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f60f1f02-df23-4ea3-c567-013e48898f19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_id = 'gossipcop'"
      ],
      "metadata": {
        "id": "p1sDxnH0xX1S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "converters = {\"retweets\":ast.literal_eval, \"tweets\":ast.literal_eval}\n",
        "df = pd.read_csv(base_dir/f\"{dataset_id}_agg.csv\", converters=converters)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2YYgYvwB7nkO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9dd2b1e1-8664-4d7f-9d57-fcc14e95b7b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title text  \\\n",
              "0      Kendall   Kylie Jenner Jenner NOT Upset Up...  NaN   \n",
              "1      Kim Kardashian Dethroned Dethroned By Khlo...  NaN   \n",
              "2      Kim Kardashian Did NOT Hot Staffer Hot Sta...  NaN   \n",
              "3      The Voice The Voice Team NOT Surprised Sur...  NaN   \n",
              "4     Drake NOT Angelina Jolie s Toy Boy Toy Boy ...  NaN   \n",
              "\n",
              "                                              tweets  \\\n",
              "0                                                 []   \n",
              "1                                                 []   \n",
              "2                                                 []   \n",
              "3                                                 []   \n",
              "4  [{'id': 948630026496323585, 'text': 'Drake NOT...   \n",
              "\n",
              "                                            retweets label  url  num_retweets  \\\n",
              "0  [995423424741888001, 995461685166202880, 99987...  fake  NaN             3   \n",
              "1  [848843565027516416, 849030801970868224, 84884...  fake  NaN             3   \n",
              "2  [940685393112064001, 977921622672920576, 94031...  fake  NaN             8   \n",
              "3                                                 []  fake  NaN             0   \n",
              "4  [948022124626808832, 948630026496323585, 94801...  fake  NaN            18   \n",
              "\n",
              "   log_num_retweets  num_tweets  log_num_tweets  \n",
              "0          1.386294           0        0.000000  \n",
              "1          1.386294           0        0.000000  \n",
              "2          2.197225           0        0.000000  \n",
              "3          0.000000           0        0.000000  \n",
              "4          2.944439           7        2.079442  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-946df3a8-afb5-472f-a789-aa8a3ae4fc05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>tweets</th>\n",
              "      <th>retweets</th>\n",
              "      <th>label</th>\n",
              "      <th>url</th>\n",
              "      <th>num_retweets</th>\n",
              "      <th>log_num_retweets</th>\n",
              "      <th>num_tweets</th>\n",
              "      <th>log_num_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kendall   Kylie Jenner Jenner NOT Upset Up...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[995423424741888001, 995461685166202880, 99987...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kim Kardashian Dethroned Dethroned By Khlo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[848843565027516416, 849030801970868224, 84884...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kim Kardashian Did NOT Hot Staffer Hot Sta...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[940685393112064001, 977921622672920576, 94031...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Voice The Voice Team NOT Surprised Sur...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Drake NOT Angelina Jolie s Toy Boy Toy Boy ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'id': 948630026496323585, 'text': 'Drake NOT...</td>\n",
              "      <td>[948022124626808832, 948630026496323585, 94801...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>2.944439</td>\n",
              "      <td>7</td>\n",
              "      <td>2.079442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-946df3a8-afb5-472f-a789-aa8a3ae4fc05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-946df3a8-afb5-472f-a789-aa8a3ae4fc05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-946df3a8-afb5-472f-a789-aa8a3ae4fc05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.title.isna().sum(), (df.title == \"\").sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2PltrGzNia4",
        "outputId": "105912c8-31f6-42e3-a337-06909806b856"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles = df.title.tolist()\n",
        "texts = (df.title + \" \" + df.text).tolist()"
      ],
      "metadata": {
        "id": "9BG1btWEm0b_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfZSpiXU8IHY",
        "outputId": "53619fee-8171-4864-ec64-fd44ca97d191"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19968"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare emebeddings"
      ],
      "metadata": {
        "id": "CnksS6trIRdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_embedding_file = base_dir/f\"{dataset_id}_sbert_title_embeddings.npy\"\n",
        "\n",
        "if title_embedding_file.exists():\n",
        "    title_embeddings = np.load(title_embedding_file)\n",
        "else:\n",
        "    model_id = \"all-mpnet-base-v2\"\n",
        "    model = SentenceTransformer(model_id)\n",
        "    titles = df.title.tolist()\n",
        "    title_embeddings = model.encode(titles, show_progress_bar=True)\n",
        "    np.save(title_embedding_file, title_embeddings)"
      ],
      "metadata": {
        "id": "fwwbRvyOpCcl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_embedding_file = base_dir/f\"{dataset_id}_sbert_fulltext_embeddings.npy\"\n",
        "\n",
        "if text_embedding_file.exists():\n",
        "    text_embeddings = np.load(text_embedding_file)\n",
        "else:\n",
        "    model_id = \"all-mpnet-base-v2\"\n",
        "    model = SentenceTransformer(model_id)\n",
        "    texts = (df.title + \"\\n\" + df.text).tolist()\n",
        "    text_embeddings = model.encode(texts, show_progress_bar=True)\n",
        "    np.save(text_embedding_file, text_embeddings)"
      ],
      "metadata": {
        "id": "Ey0dv12fpCcn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edim = 128\n",
        "bg_embeddings = np.load(base_dir/f'{dataset_id}_pt_biggraph_article_embeddings_{edim}.npy')\n",
        "idx = np.load(base_dir/f\"{dataset_id}_pt_biggraph_article_idx_{edim}.npy\")"
      ],
      "metadata": {
        "id": "uQjE8biJFfW8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_embeddings = np.zeros((text_embeddings.shape[0], edim))\n",
        "graph_embeddings[idx] = bg_embeddings"
      ],
      "metadata": {
        "id": "NWS6KO7UpUX3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate([\n",
        "    text_embeddings, \n",
        "    df.num_retweets.to_numpy()[..., None], \n",
        "    df.num_tweets.to_numpy()[..., None],\n",
        "    graph_embeddings], axis=1)\n",
        "y = (df.label==\"real\").to_numpy().astype(int)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eface49a-4f70-41ac-ef21-ac1c8af23847",
        "id": "CHZ56FHKxQd3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19968, 898), (19968,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(shuffle=True, random_state=124)"
      ],
      "metadata": {
        "id": "Ec5ppDaQK16F"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traing XGB"
      ],
      "metadata": {
        "id": "pOEREu_Yz5YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_idx, test_idx, params):\n",
        "\n",
        "    # training\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "    watchlist = [(dtrain,'train'), (dtest,'eval')]\n",
        "    clf = xgb.train(params, dtrain, num_boost_round=params['num_boost_round'], early_stopping_rounds=None, evals=watchlist, callbacks=[WandbCallback()])\n",
        "    #evaluation\n",
        "    probs = clf.predict(dtest)\n",
        "    y_pred = (probs > 0.5).astype(int)\n",
        "    eval_results = {get_name(f):f(y_pred=y_pred, y_true=y_test) for f in metrics}\n",
        "    wandb.log(eval_results)\n",
        "    wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
        "                            y_true=y_test, preds=y_pred,\n",
        "                            class_names=[\"Fake\", \"Real\"])})"
      ],
      "metadata": {
        "id": "5oSeII1QLot_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"objective\":'binary:logistic',\n",
        "    \"seed\":124,\n",
        "    \"num_boost_round\":200\n",
        "}"
      ],
      "metadata": {
        "id": "5IvqyG9jPVQw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WANDB_ENTITY = 'saloniteam'\n",
        "WANDB_PROJECT = 'nofolds'\n",
        "GROUP = \"gossipcop-sbert-mpnet-v2-biggraph128-xgb\"\n",
        "\n",
        "for fold_id, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "    clear_output()\n",
        "    with wandb.init(entity=WANDB_ENTITY, project=WANDB_PROJECT, group=GROUP, name=f\"{GROUP}-fold-{fold_id}\", tags=['xgb', 'sbert', 'biggraph']) as run:\n",
        "        train(train_idx, test_idx, params)\n",
        "    break"
      ],
      "metadata": {
        "id": "UoH1hD_3-rt8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1157d19-8763-4867-9375-3e3ec847b91f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221018_121004-jnqkhrvl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/saloniteam/nofolds/runs/jnqkhrvl\" target=\"_blank\">gossipcop-sbert-mpnet-v2-biggraph128-xgb-fold-0</a></strong> to <a href=\"https://wandb.ai/saloniteam/nofolds\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:10:06] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"num_boost_round\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[0]\ttrain-logloss:0.53893\teval-logloss:0.55267\n",
            "[1]\ttrain-logloss:0.44819\teval-logloss:0.47325\n",
            "[2]\ttrain-logloss:0.38859\teval-logloss:0.42444\n",
            "[3]\ttrain-logloss:0.34590\teval-logloss:0.39308\n",
            "[4]\ttrain-logloss:0.31374\teval-logloss:0.36986\n",
            "[5]\ttrain-logloss:0.28707\teval-logloss:0.35301\n",
            "[6]\ttrain-logloss:0.26881\teval-logloss:0.34220\n",
            "[7]\ttrain-logloss:0.25077\teval-logloss:0.33604\n",
            "[8]\ttrain-logloss:0.23792\teval-logloss:0.33084\n",
            "[9]\ttrain-logloss:0.22448\teval-logloss:0.32632\n",
            "[10]\ttrain-logloss:0.21605\teval-logloss:0.32081\n",
            "[11]\ttrain-logloss:0.20413\teval-logloss:0.31601\n",
            "[12]\ttrain-logloss:0.19312\teval-logloss:0.31348\n",
            "[13]\ttrain-logloss:0.18783\teval-logloss:0.31075\n",
            "[14]\ttrain-logloss:0.17895\teval-logloss:0.30842\n",
            "[15]\ttrain-logloss:0.17418\teval-logloss:0.30604\n",
            "[16]\ttrain-logloss:0.16805\teval-logloss:0.30530\n",
            "[17]\ttrain-logloss:0.15866\teval-logloss:0.30294\n",
            "[18]\ttrain-logloss:0.15225\teval-logloss:0.30235\n",
            "[19]\ttrain-logloss:0.14868\teval-logloss:0.30104\n",
            "[20]\ttrain-logloss:0.14564\teval-logloss:0.29903\n",
            "[21]\ttrain-logloss:0.14009\teval-logloss:0.29871\n",
            "[22]\ttrain-logloss:0.13413\teval-logloss:0.29757\n",
            "[23]\ttrain-logloss:0.13081\teval-logloss:0.29597\n",
            "[24]\ttrain-logloss:0.12853\teval-logloss:0.29592\n",
            "[25]\ttrain-logloss:0.12260\teval-logloss:0.29648\n",
            "[26]\ttrain-logloss:0.11949\teval-logloss:0.29598\n",
            "[27]\ttrain-logloss:0.11504\teval-logloss:0.29550\n",
            "[28]\ttrain-logloss:0.11024\teval-logloss:0.29516\n",
            "[29]\ttrain-logloss:0.10700\teval-logloss:0.29400\n",
            "[30]\ttrain-logloss:0.10422\teval-logloss:0.29320\n",
            "[31]\ttrain-logloss:0.10190\teval-logloss:0.29363\n",
            "[32]\ttrain-logloss:0.10000\teval-logloss:0.29290\n",
            "[33]\ttrain-logloss:0.09787\teval-logloss:0.29293\n",
            "[34]\ttrain-logloss:0.09628\teval-logloss:0.29159\n",
            "[35]\ttrain-logloss:0.09437\teval-logloss:0.29216\n",
            "[36]\ttrain-logloss:0.09141\teval-logloss:0.29318\n",
            "[37]\ttrain-logloss:0.09027\teval-logloss:0.29284\n",
            "[38]\ttrain-logloss:0.08633\teval-logloss:0.29151\n",
            "[39]\ttrain-logloss:0.08426\teval-logloss:0.29150\n",
            "[40]\ttrain-logloss:0.08162\teval-logloss:0.29198\n",
            "[41]\ttrain-logloss:0.08018\teval-logloss:0.29120\n",
            "[42]\ttrain-logloss:0.07822\teval-logloss:0.29125\n",
            "[43]\ttrain-logloss:0.07652\teval-logloss:0.29167\n",
            "[44]\ttrain-logloss:0.07455\teval-logloss:0.29149\n",
            "[45]\ttrain-logloss:0.07305\teval-logloss:0.29104\n",
            "[46]\ttrain-logloss:0.07058\teval-logloss:0.29226\n",
            "[47]\ttrain-logloss:0.06918\teval-logloss:0.29218\n",
            "[48]\ttrain-logloss:0.06812\teval-logloss:0.29212\n",
            "[49]\ttrain-logloss:0.06613\teval-logloss:0.29218\n",
            "[50]\ttrain-logloss:0.06443\teval-logloss:0.29257\n",
            "[51]\ttrain-logloss:0.06255\teval-logloss:0.29302\n",
            "[52]\ttrain-logloss:0.06153\teval-logloss:0.29212\n",
            "[53]\ttrain-logloss:0.05948\teval-logloss:0.29300\n",
            "[54]\ttrain-logloss:0.05751\teval-logloss:0.29214\n",
            "[55]\ttrain-logloss:0.05536\teval-logloss:0.29254\n",
            "[56]\ttrain-logloss:0.05395\teval-logloss:0.29218\n",
            "[57]\ttrain-logloss:0.05283\teval-logloss:0.29291\n",
            "[58]\ttrain-logloss:0.05210\teval-logloss:0.29293\n",
            "[59]\ttrain-logloss:0.05033\teval-logloss:0.29416\n",
            "[60]\ttrain-logloss:0.04862\teval-logloss:0.29297\n",
            "[61]\ttrain-logloss:0.04764\teval-logloss:0.29319\n",
            "[62]\ttrain-logloss:0.04641\teval-logloss:0.29325\n",
            "[63]\ttrain-logloss:0.04513\teval-logloss:0.29438\n",
            "[64]\ttrain-logloss:0.04392\teval-logloss:0.29421\n",
            "[65]\ttrain-logloss:0.04225\teval-logloss:0.29525\n",
            "[66]\ttrain-logloss:0.04184\teval-logloss:0.29544\n",
            "[67]\ttrain-logloss:0.04070\teval-logloss:0.29548\n",
            "[68]\ttrain-logloss:0.03935\teval-logloss:0.29627\n",
            "[69]\ttrain-logloss:0.03832\teval-logloss:0.29616\n",
            "[70]\ttrain-logloss:0.03737\teval-logloss:0.29634\n",
            "[71]\ttrain-logloss:0.03645\teval-logloss:0.29613\n",
            "[72]\ttrain-logloss:0.03583\teval-logloss:0.29631\n",
            "[73]\ttrain-logloss:0.03465\teval-logloss:0.29683\n",
            "[74]\ttrain-logloss:0.03410\teval-logloss:0.29780\n",
            "[75]\ttrain-logloss:0.03277\teval-logloss:0.29893\n",
            "[76]\ttrain-logloss:0.03177\teval-logloss:0.29998\n",
            "[77]\ttrain-logloss:0.03054\teval-logloss:0.30116\n",
            "[78]\ttrain-logloss:0.02942\teval-logloss:0.30128\n",
            "[79]\ttrain-logloss:0.02856\teval-logloss:0.30133\n",
            "[80]\ttrain-logloss:0.02792\teval-logloss:0.30166\n",
            "[81]\ttrain-logloss:0.02751\teval-logloss:0.30154\n",
            "[82]\ttrain-logloss:0.02722\teval-logloss:0.30229\n",
            "[83]\ttrain-logloss:0.02663\teval-logloss:0.30229\n",
            "[84]\ttrain-logloss:0.02584\teval-logloss:0.30357\n",
            "[85]\ttrain-logloss:0.02559\teval-logloss:0.30373\n",
            "[86]\ttrain-logloss:0.02521\teval-logloss:0.30485\n",
            "[87]\ttrain-logloss:0.02503\teval-logloss:0.30512\n",
            "[88]\ttrain-logloss:0.02442\teval-logloss:0.30517\n",
            "[89]\ttrain-logloss:0.02420\teval-logloss:0.30501\n",
            "[90]\ttrain-logloss:0.02344\teval-logloss:0.30586\n",
            "[91]\ttrain-logloss:0.02281\teval-logloss:0.30713\n",
            "[92]\ttrain-logloss:0.02222\teval-logloss:0.30817\n",
            "[93]\ttrain-logloss:0.02200\teval-logloss:0.30816\n",
            "[94]\ttrain-logloss:0.02141\teval-logloss:0.30851\n",
            "[95]\ttrain-logloss:0.02112\teval-logloss:0.30961\n",
            "[96]\ttrain-logloss:0.02068\teval-logloss:0.30969\n",
            "[97]\ttrain-logloss:0.02008\teval-logloss:0.31047\n",
            "[98]\ttrain-logloss:0.01959\teval-logloss:0.31097\n",
            "[99]\ttrain-logloss:0.01923\teval-logloss:0.31105\n",
            "[100]\ttrain-logloss:0.01875\teval-logloss:0.31131\n",
            "[101]\ttrain-logloss:0.01857\teval-logloss:0.31175\n",
            "[102]\ttrain-logloss:0.01832\teval-logloss:0.31236\n",
            "[103]\ttrain-logloss:0.01790\teval-logloss:0.31280\n",
            "[104]\ttrain-logloss:0.01731\teval-logloss:0.31332\n",
            "[105]\ttrain-logloss:0.01671\teval-logloss:0.31415\n",
            "[106]\ttrain-logloss:0.01646\teval-logloss:0.31461\n",
            "[107]\ttrain-logloss:0.01609\teval-logloss:0.31525\n",
            "[108]\ttrain-logloss:0.01568\teval-logloss:0.31621\n",
            "[109]\ttrain-logloss:0.01530\teval-logloss:0.31765\n",
            "[110]\ttrain-logloss:0.01476\teval-logloss:0.31929\n",
            "[111]\ttrain-logloss:0.01462\teval-logloss:0.31929\n",
            "[112]\ttrain-logloss:0.01442\teval-logloss:0.31974\n",
            "[113]\ttrain-logloss:0.01412\teval-logloss:0.31914\n",
            "[114]\ttrain-logloss:0.01378\teval-logloss:0.31965\n",
            "[115]\ttrain-logloss:0.01358\teval-logloss:0.31975\n",
            "[116]\ttrain-logloss:0.01348\teval-logloss:0.31970\n",
            "[117]\ttrain-logloss:0.01319\teval-logloss:0.32009\n",
            "[118]\ttrain-logloss:0.01307\teval-logloss:0.31956\n",
            "[119]\ttrain-logloss:0.01281\teval-logloss:0.32041\n",
            "[120]\ttrain-logloss:0.01259\teval-logloss:0.32049\n",
            "[121]\ttrain-logloss:0.01222\teval-logloss:0.32135\n",
            "[122]\ttrain-logloss:0.01198\teval-logloss:0.32168\n",
            "[123]\ttrain-logloss:0.01172\teval-logloss:0.32256\n",
            "[124]\ttrain-logloss:0.01145\teval-logloss:0.32314\n",
            "[125]\ttrain-logloss:0.01124\teval-logloss:0.32365\n",
            "[126]\ttrain-logloss:0.01099\teval-logloss:0.32428\n",
            "[127]\ttrain-logloss:0.01078\teval-logloss:0.32429\n",
            "[128]\ttrain-logloss:0.01053\teval-logloss:0.32495\n",
            "[129]\ttrain-logloss:0.01027\teval-logloss:0.32627\n",
            "[130]\ttrain-logloss:0.01015\teval-logloss:0.32685\n",
            "[131]\ttrain-logloss:0.00991\teval-logloss:0.32710\n",
            "[132]\ttrain-logloss:0.00982\teval-logloss:0.32717\n",
            "[133]\ttrain-logloss:0.00968\teval-logloss:0.32746\n",
            "[134]\ttrain-logloss:0.00952\teval-logloss:0.32765\n",
            "[135]\ttrain-logloss:0.00928\teval-logloss:0.32783\n",
            "[136]\ttrain-logloss:0.00911\teval-logloss:0.32881\n",
            "[137]\ttrain-logloss:0.00901\teval-logloss:0.32883\n",
            "[138]\ttrain-logloss:0.00894\teval-logloss:0.32887\n",
            "[139]\ttrain-logloss:0.00883\teval-logloss:0.32953\n",
            "[140]\ttrain-logloss:0.00864\teval-logloss:0.33048\n",
            "[141]\ttrain-logloss:0.00855\teval-logloss:0.33055\n",
            "[142]\ttrain-logloss:0.00833\teval-logloss:0.33154\n",
            "[143]\ttrain-logloss:0.00818\teval-logloss:0.33244\n",
            "[144]\ttrain-logloss:0.00802\teval-logloss:0.33272\n",
            "[145]\ttrain-logloss:0.00790\teval-logloss:0.33265\n",
            "[146]\ttrain-logloss:0.00784\teval-logloss:0.33365\n",
            "[147]\ttrain-logloss:0.00775\teval-logloss:0.33437\n",
            "[148]\ttrain-logloss:0.00759\teval-logloss:0.33457\n",
            "[149]\ttrain-logloss:0.00752\teval-logloss:0.33531\n",
            "[150]\ttrain-logloss:0.00740\teval-logloss:0.33562\n",
            "[151]\ttrain-logloss:0.00730\teval-logloss:0.33606\n",
            "[152]\ttrain-logloss:0.00721\teval-logloss:0.33624\n",
            "[153]\ttrain-logloss:0.00709\teval-logloss:0.33691\n",
            "[154]\ttrain-logloss:0.00698\teval-logloss:0.33733\n",
            "[155]\ttrain-logloss:0.00685\teval-logloss:0.33778\n",
            "[156]\ttrain-logloss:0.00678\teval-logloss:0.33805\n",
            "[157]\ttrain-logloss:0.00666\teval-logloss:0.33828\n",
            "[158]\ttrain-logloss:0.00655\teval-logloss:0.33837\n",
            "[159]\ttrain-logloss:0.00645\teval-logloss:0.33855\n",
            "[160]\ttrain-logloss:0.00635\teval-logloss:0.33921\n",
            "[161]\ttrain-logloss:0.00628\teval-logloss:0.33942\n",
            "[162]\ttrain-logloss:0.00620\teval-logloss:0.34008\n",
            "[163]\ttrain-logloss:0.00609\teval-logloss:0.34016\n",
            "[164]\ttrain-logloss:0.00599\teval-logloss:0.34091\n",
            "[165]\ttrain-logloss:0.00592\teval-logloss:0.34114\n",
            "[166]\ttrain-logloss:0.00588\teval-logloss:0.34129\n",
            "[167]\ttrain-logloss:0.00579\teval-logloss:0.34195\n",
            "[168]\ttrain-logloss:0.00570\teval-logloss:0.34275\n",
            "[169]\ttrain-logloss:0.00562\teval-logloss:0.34271\n",
            "[170]\ttrain-logloss:0.00557\teval-logloss:0.34275\n",
            "[171]\ttrain-logloss:0.00552\teval-logloss:0.34330\n",
            "[172]\ttrain-logloss:0.00540\teval-logloss:0.34366\n",
            "[173]\ttrain-logloss:0.00528\teval-logloss:0.34470\n",
            "[174]\ttrain-logloss:0.00520\teval-logloss:0.34538\n",
            "[175]\ttrain-logloss:0.00509\teval-logloss:0.34675\n",
            "[176]\ttrain-logloss:0.00505\teval-logloss:0.34719\n",
            "[177]\ttrain-logloss:0.00502\teval-logloss:0.34764\n",
            "[178]\ttrain-logloss:0.00493\teval-logloss:0.34811\n",
            "[179]\ttrain-logloss:0.00488\teval-logloss:0.34846\n",
            "[180]\ttrain-logloss:0.00481\teval-logloss:0.34832\n",
            "[181]\ttrain-logloss:0.00475\teval-logloss:0.34903\n",
            "[182]\ttrain-logloss:0.00467\teval-logloss:0.34979\n",
            "[183]\ttrain-logloss:0.00458\teval-logloss:0.35020\n",
            "[184]\ttrain-logloss:0.00453\teval-logloss:0.34995\n",
            "[185]\ttrain-logloss:0.00446\teval-logloss:0.35059\n",
            "[186]\ttrain-logloss:0.00440\teval-logloss:0.35145\n",
            "[187]\ttrain-logloss:0.00436\teval-logloss:0.35166\n",
            "[188]\ttrain-logloss:0.00430\teval-logloss:0.35251\n",
            "[189]\ttrain-logloss:0.00425\teval-logloss:0.35274\n",
            "[190]\ttrain-logloss:0.00418\teval-logloss:0.35281\n",
            "[191]\ttrain-logloss:0.00413\teval-logloss:0.35233\n",
            "[192]\ttrain-logloss:0.00408\teval-logloss:0.35246\n",
            "[193]\ttrain-logloss:0.00402\teval-logloss:0.35309\n",
            "[194]\ttrain-logloss:0.00395\teval-logloss:0.35374\n",
            "[195]\ttrain-logloss:0.00389\teval-logloss:0.35440\n",
            "[196]\ttrain-logloss:0.00383\teval-logloss:0.35522\n",
            "[197]\ttrain-logloss:0.00381\teval-logloss:0.35541\n",
            "[198]\ttrain-logloss:0.00376\teval-logloss:0.35576\n",
            "[199]\ttrain-logloss:0.00373\teval-logloss:0.35615\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval-logloss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▄</td></tr><tr><td>f1</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>train-logloss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.89234</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>f1</td><td>0.93247</td></tr><tr><td>precision</td><td>0.90463</td></tr><tr><td>recall</td><td>0.96209</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">gossipcop-sbert-mpnet-v2-biggraph128-xgb-fold-0</strong>: <a href=\"https://wandb.ai/saloniteam/nofolds/runs/jnqkhrvl\" target=\"_blank\">https://wandb.ai/saloniteam/nofolds/runs/jnqkhrvl</a><br/>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221018_121004-jnqkhrvl/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNEc6tfHpccu"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}