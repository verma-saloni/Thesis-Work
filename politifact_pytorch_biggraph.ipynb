{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "politifact_pytorch_biggraph.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verma-saloni/Thesis-Work/blob/main/politifact_pytorch_biggraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the necessary libraries for the Pytorch BigGraph embeddings. "
      ],
      "metadata": {
        "id": "JtbwP7PzgpQR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpTeMbYZwmf7"
      },
      "outputs": [],
      "source": [
        "!pip -qq install jsonlines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -qb working https://github.com/verma-saloni/PyTorch-BigGraph"
      ],
      "metadata": {
        "id": "Vne7O50jOJRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb63657-c002-4b25-96ea-67f5cb22c3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PyTorch-BigGraph' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PyTorch-BigGraph/\n",
        "!pip -qq install .\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "fKc3Ix04OThj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6d1660-0bdc-4f41-be2e-36ea5693fe65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyTorch-BigGraph\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Building wheel for torchbiggraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "from pathlib import Path\n",
        "base_dir = Path(\"/gdrive/MyDrive/ResearchFND\")\n",
        "assert base_dir.exists()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxNEaltli8H_",
        "outputId": "dc42a0a5-8487-43ed-9282-8efd78bd904c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data prep"
      ],
      "metadata": {
        "id": "NHdG78wwVumY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import os\n",
        "import json\n",
        "import jsonlines\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import IPython.display as ipd"
      ],
      "metadata": {
        "id": "7tPiW_FBWO8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the input file for the dataset. \n"
      ],
      "metadata": {
        "id": "i-vVZW8Rheye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(base_dir/'politifact_agg.csv', index_col=0)\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "0BsiweMKV3Kt",
        "outputId": "c382e1f1-d2c4-422e-e460-af40bc9d4add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title text tweets  \\\n",
              "0   Actress Emma Stone ‘For the first time in his...  NaN     []   \n",
              "1   Breaking President Trump makes English the of...  NaN     []   \n",
              "\n",
              "                                            retweets label  url tweet_ids  \\\n",
              "0  ['1020554564334964741', '1020817527046197248',...  fake  NaN        []   \n",
              "1                                                 []  fake  NaN        []   \n",
              "\n",
              "   num_retweets  log_num_retweets  num_tweets  log_num_tweets  \n",
              "0          2911          7.976595           0             0.0  \n",
              "1             0          0.000000           0             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b00de4c-b275-4e9f-b5df-332cf5210ff0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>tweets</th>\n",
              "      <th>retweets</th>\n",
              "      <th>label</th>\n",
              "      <th>url</th>\n",
              "      <th>tweet_ids</th>\n",
              "      <th>num_retweets</th>\n",
              "      <th>log_num_retweets</th>\n",
              "      <th>num_tweets</th>\n",
              "      <th>log_num_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Actress Emma Stone ‘For the first time in his...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['1020554564334964741', '1020817527046197248',...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>2911</td>\n",
              "      <td>7.976595</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Breaking President Trump makes English the of...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b00de4c-b275-4e9f-b5df-332cf5210ff0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b00de4c-b275-4e9f-b5df-332cf5210ff0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b00de4c-b275-4e9f-b5df-332cf5210ff0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(base_dir/'t2u.json') as f:\n",
        "    t2u = json.load(f)\n",
        "\n",
        "with open(base_dir/'users_info.json') as f:\n",
        "    users_info = json.load(f)"
      ],
      "metadata": {
        "id": "-6bwXASDJdFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweets'] = df.tweets.map(ast.literal_eval)\n",
        "users_tweeted = df.tweets.map(lambda x: [int(e['user_id']) for e in x])"
      ],
      "metadata": {
        "id": "cruZFCpNWRLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['retweets'] = df.retweets.map(ast.literal_eval)\n",
        "users_retweeted = df.retweets.map(lambda x: [t2u[str(e)] for e in x if (str(e) in t2u) ])"
      ],
      "metadata": {
        "id": "gJpLhbzEMbaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(users_tweeted), sum(users_tweeted.map(len) > 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exnDy-5ud_uJ",
        "outputId": "d58d823c-b9fe-4731-9c0c-cc0a4dcb4a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(894, 149)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(users_retweeted), sum(users_retweeted.map(len) > 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihN_iQVMN4Lu",
        "outputId": "b5dd44ff-f7b4-4199-ffa6-42f2585a64ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(894, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "follow_src = []\n",
        "follow_dst = []\n",
        "with jsonlines.open(base_dir/\"followers.jsonl\") as reader:\n",
        "    for line in reader:\n",
        "        v = line[\"user_id\"]\n",
        "        for u in line[\"followers\"]:\n",
        "            follow_src.append(u)\n",
        "            follow_dst.append(v)"
      ],
      "metadata": {
        "id": "h3XOCaEwoMvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open(base_dir/\"following.jsonl\") as reader:\n",
        "    for line in reader:\n",
        "        u = line[\"user_id\"]\n",
        "        for v in line[\"following\"]:\n",
        "            follow_src.append(u)\n",
        "            follow_dst.append(v)"
      ],
      "metadata": {
        "id": "sWJFoJ_4oMvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"retweet\" users\n",
        "for u, info in users_info.items():\n",
        "    u = int(u)\n",
        "    for v in info['followers']:\n",
        "        follow_src.append(v)\n",
        "        follow_dst.append(u)\n",
        "    for v in info['friends']:\n",
        "        follow_src.append(u)\n",
        "        follow_dst.append(v)"
      ],
      "metadata": {
        "id": "Wj-m05WwJ75g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_src = []\n",
        "tweet_dst = []\n",
        "\n",
        "for v, l in users_tweeted.iteritems():\n",
        "    if not len(l):dd\n",
        "        continue\n",
        "    for u in l:\n",
        "        tweet_src.append(u)\n",
        "        tweet_dst.append(v)"
      ],
      "metadata": {
        "id": "DWM9MEXDpiyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for v, l in users_retweeted.iteritems():\n",
        "    if not len(l):\n",
        "        continue\n",
        "    for u in l:\n",
        "        tweet_src.append(u)\n",
        "        tweet_dst.append(v)"
      ],
      "metadata": {
        "id": "7NWVWayzQdGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('edges.txt', 'w') as f:\n",
        "    for src, dst in zip(follow_src, follow_dst):\n",
        "        f.write(f\"{src}\\t{dst}\\tfollows\\n\")\n",
        "    for src, dst in zip(tweet_src, tweet_dst):\n",
        "        f.write(f\"{src}\\t{dst}\\ttwitted\\n\")"
      ],
      "metadata": {
        "id": "OkIxZJL5UuD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 edges.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHqWee-K9jDA",
        "outputId": "062212f0-55a5-4cb2-d53e-8edd3dd91795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "983553159057498114\t961251714857828357\tfollows\n",
            "988529911873921024\t961251714857828357\tfollows\n",
            "961635897929359360\t961251714857828357\tfollows\n",
            "159717173\t961251714857828357\tfollows\n",
            "4737344780\t961251714857828357\tfollows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp edges.txt $base_dir/"
      ],
      "metadata": {
        "id": "wF1RCfArK1bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "A9DZtJEvKUrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzq9nvhQRYYc",
        "outputId": "8cacaed6-5502-4db3-8e9b-2e9f751a997b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import attr\n",
        "import pkg_resources\n",
        "from torchbiggraph.config import add_to_sys_path, ConfigFileLoader\n",
        "from torchbiggraph.converters.importers import convert_input_data, TSVEdgelistReader\n",
        "from torchbiggraph.converters.utils import download_url, extract_gzip, extract_tar\n",
        "from torchbiggraph.eval import do_eval\n",
        "from torchbiggraph.train import train\n",
        "from torchbiggraph.util import (\n",
        "    set_logging_verbosity,\n",
        "    setup_logging,\n",
        "    SubprocessInitializer,\n",
        ")"
      ],
      "metadata": {
        "id": "2AfA9wOUQFzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a new edges txt file in the library, which will show the connections between different Twitter users with their Twitter IDs. \n"
      ],
      "metadata": {
        "id": "khl7P2MyCKf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path('./data')\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "fpath = base_dir/'edges.txt'"
      ],
      "metadata": {
        "id": "EhJ-IR1D2_Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting into train and validation files, 80-20 split, random splits and then starts to follow a path. "
      ],
      "metadata": {
        "id": "QU676V-SCXvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def split_edges(input_file, pct=0.8, train_file='data/train_edges.txt', valid_file='data/valid_edges.txt'):\n",
        "\n",
        "    with open(input_file) as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    follow_edges, tweet_edges = [], []\n",
        "    for line in lines:\n",
        "        if line.strip().endswith('follows'):\n",
        "            follow_edges.append(line)\n",
        "        else:\n",
        "            tweet_edges.append(line)\n",
        "\n",
        "    random.shuffle(follow_edges)\n",
        "    random.shuffle(tweet_edges)\n",
        "    follow_split, tweet_split = int(pct*len(follow_edges)), int(pct*len(tweet_edges))\n",
        "    train_edges = follow_edges[:follow_split] + tweet_edges[:tweet_split]\n",
        "    valid_edges = follow_edges[follow_split:] + tweet_edges[tweet_split:]\n",
        "\n",
        "    with open(train_file, 'w') as f:\n",
        "        f.writelines(train_edges)\n",
        "\n",
        "    with open(valid_file, 'w') as f:\n",
        "        f.writelines(valid_edges)"
      ],
      "metadata": {
        "id": "6IufRqmI_3yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_edges(fpath)"
      ],
      "metadata": {
        "id": "m8CRfFnyAPob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = ConfigFileLoader()\n",
        "config = loader.load_config('PyTorch-BigGraph/torchbiggraph/examples/configs/politifact_config.py', [])\n",
        "set_logging_verbosity(0)\n",
        "subprocess_init = SubprocessInitializer()\n",
        "#subprocess_init.register(setup_logging, 1). # commented so it will remove some unnecessary outputs for the next cells..for the github gist it was set to 1, in case it was needed later for analysis of connections\n",
        "subprocess_init.register(setup_logging, 0)\n",
        "subprocess_init.register(add_to_sys_path, loader.config_dir.name)\n",
        "input_edge_paths = [data_dir/'train_edges.txt', data_dir/'valid_edges.txt']\n",
        "output_train_path, output_test_path = config.edge_paths"
      ],
      "metadata": {
        "id": "arg_IAqn9SPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the input data to entities, relations and paths through which they are connected. \n"
      ],
      "metadata": {
        "id": "dw6PjgCvDlFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convert_input_data(\n",
        "    config.entities,\n",
        "    config.relations,\n",
        "    config.entity_path,\n",
        "    config.edge_paths,\n",
        "    input_edge_paths,\n",
        "    TSVEdgelistReader(lhs_col=0, rhs_col=1, rel_col=2),\n",
        "    dynamic_relations=config.dynamic_relations,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTXJLODH-RQx",
        "outputId": "6f3b584e-783b-4634-f5dc-4b27d5114fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-08-29 20:59:08.219271] Using the 2 relation types given in the config\n",
            "[2022-08-29 20:59:08.220512] Searching for the entities in the edge files...\n",
            "[2022-08-29 20:59:09.947028] Entity type user:\n",
            "[2022-08-29 20:59:09.948612] - Found 678041 entities\n",
            "[2022-08-29 20:59:09.952914] - Removing the ones with fewer than 1 occurrences...\n",
            "[2022-08-29 20:59:10.209704] - Left with 678041 entities\n",
            "[2022-08-29 20:59:10.211149] - Shuffling them...\n",
            "[2022-08-29 20:59:10.974042] Entity type article:\n",
            "[2022-08-29 20:59:10.975583] - Found 171 entities\n",
            "[2022-08-29 20:59:10.982600] - Removing the ones with fewer than 1 occurrences...\n",
            "[2022-08-29 20:59:10.983378] - Left with 171 entities\n",
            "[2022-08-29 20:59:10.987287] - Shuffling them...\n",
            "[2022-08-29 20:59:10.994703] Preparing counts and dictionaries for entities and relation types:\n",
            "[2022-08-29 20:59:10.997772] - Writing count of entity type user and partition 0\n",
            "[2022-08-29 20:59:11.466186] - Writing count of entity type article and partition 0\n",
            "[2022-08-29 20:59:11.468626] Preparing edge path data/train_partitioned, out of the edges found in data/train_edges.txt\n",
            "[2022-08-29 20:59:11.470599] - Edges will be partitioned in 1 x 1 buckets.\n",
            "[2022-08-29 20:59:12.253593] - Processed 100000 edges so far...\n",
            "[2022-08-29 20:59:13.351941] - Processed 200000 edges so far...\n",
            "[2022-08-29 20:59:14.228456] - Processed 300000 edges so far...\n",
            "[2022-08-29 20:59:15.270885] - Processed 400000 edges so far...\n",
            "[2022-08-29 20:59:16.208410] - Processed 500000 edges so far...\n",
            "[2022-08-29 20:59:17.218925] - Processed 600000 edges so far...\n",
            "[2022-08-29 20:59:17.707551] - Processed 606538 edges in total\n",
            "[2022-08-29 20:59:17.711833] Preparing edge path data/test_partitioned, out of the edges found in data/valid_edges.txt\n",
            "[2022-08-29 20:59:17.714612] - Edges will be partitioned in 1 x 1 buckets.\n",
            "[2022-08-29 20:59:18.475816] - Processed 100000 edges so far...\n",
            "[2022-08-29 20:59:19.508239] - Processed 151636 edges in total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = attr.evolve(config, edge_paths=[output_train_path])\n",
        "train(train_config, subprocess_init=subprocess_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMLAogkkFQKW",
        "outputId": "cd1022d2-40c2-4998-eb63-1a5a40b793ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:torchbiggraph:Loading entity counts...\n",
            "INFO:torchbiggraph:Creating workers...\n",
            "INFO:torchbiggraph:Initializing global model...\n",
            "INFO:torchbiggraph:Starting epoch 1 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  454.197 , pos_rank:  994.281 , mrr:  0.0036958 , r1:  0.000379213 , r10:  0.00431973 , r50:  0.0232309 , auc:  0.502654 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  23.3764 , reg:  0 , violators_lhs:  44.4033 , violators_rhs:  45.0389 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  437.533 , pos_rank:  832.764 , mrr:  0.0381277 , r1:  0.0242696 , r10:  0.0675658 , r50:  0.119914 , auc:  0.585719 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.90 s ( 0.073 M/sec ); Eval 2*30326 edges in 3.50 s ( 0.017 M/sec ); io: 0.56 s for 361,801,456 bytes ( 641.55 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 1 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 2 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  437.461 , pos_rank:  832.526 , mrr:  0.0381749 , r1:  0.0243356 , r10:  0.0674833 , r50:  0.120128 , auc:  0.584581 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  4.19091 , reg:  0 , violators_lhs:  9.86682 , violators_rhs:  6.38047 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  517.364 , pos_rank:  864.329 , mrr:  0.0401669 , r1:  0.0261492 , r10:  0.0708963 , r50:  0.122486 , auc:  0.561845 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.66 s ( 0.075 M/sec ); Eval 2*30326 edges in 2.09 s ( 0.029 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3138.35 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 2 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 3 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  517.935 , pos_rank:  864.706 , mrr:  0.0398576 , r1:  0.025704 , r10:  0.0711765 , r50:  0.122403 , auc:  0.557756 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.4827 , reg:  0 , violators_lhs:  9.4471 , violators_rhs:  5.15194 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  527.011 , pos_rank:  869.993 , mrr:  0.0396279 , r1:  0.0254897 , r10:  0.0714733 , r50:  0.122782 , auc:  0.557179 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 8.84 s ( 0.065 M/sec ); Eval 2*30326 edges in 2.08 s ( 0.029 M/sec ); io: 0.11 s for 361,801,456 bytes ( 3193.90 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 3 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 4 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  526.793 , pos_rank:  869.888 , mrr:  0.0395852 , r1:  0.0256381 , r10:  0.0710282 , r50:  0.122634 , auc:  0.552711 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.3234 , reg:  0 , violators_lhs:  9.44406 , violators_rhs:  4.9333 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  526.37 , pos_rank:  874.729 , mrr:  0.0388927 , r1:  0.0245004 , r10:  0.0709952 , r50:  0.122156 , auc:  0.551474 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 8.02 s ( 0.072 M/sec ); Eval 2*30326 edges in 2.15 s ( 0.028 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3125.73 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 4 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 5 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  526.939 , pos_rank:  875.284 , mrr:  0.0393665 , r1:  0.0252589 , r10:  0.0711601 , r50:  0.122106 , auc:  0.548622 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.25866 , reg:  0 , violators_lhs:  9.44768 , violators_rhs:  4.85608 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  527.839 , pos_rank:  877.679 , mrr:  0.0412121 , r1:  0.0274187 , r10:  0.0726769 , r50:  0.122568 , auc:  0.548111 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.74 s ( 0.074 M/sec ); Eval 2*30326 edges in 2.08 s ( 0.029 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3005.38 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 5 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 6 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  527.764 , pos_rank:  877.186 , mrr:  0.0409597 , r1:  0.0270395 , r10:  0.0722812 , r50:  0.122271 , auc:  0.551573 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.21589 , reg:  0 , violators_lhs:  9.44232 , violators_rhs:  4.76862 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  527.913 , pos_rank:  878.478 , mrr:  0.0403781 , r1:  0.0263635 , r10:  0.0715722 , r50:  0.121859 , auc:  0.551886 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.72 s ( 0.075 M/sec ); Eval 2*30326 edges in 2.07 s ( 0.029 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3112.08 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 6 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 7 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  528.235 , pos_rank:  878.308 , mrr:  0.0405862 , r1:  0.0266438 , r10:  0.0721493 , r50:  0.122172 , auc:  0.549809 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.19053 , reg:  0 , violators_lhs:  9.45187 , violators_rhs:  4.71425 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  528.246 , pos_rank:  878.152 , mrr:  0.0402303 , r1:  0.0260503 , r10:  0.0728253 , r50:  0.122189 , auc:  0.545621 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.63 s ( 0.076 M/sec ); Eval 2*30326 edges in 2.17 s ( 0.028 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3043.03 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 7 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 8 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  529.315 , pos_rank:  878.63 , mrr:  0.0404319 , r1:  0.026413 , r10:  0.0730231 , r50:  0.122156 , auc:  0.544945 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.16311 , reg:  0 , violators_lhs:  9.42902 , violators_rhs:  4.67256 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  529.665 , pos_rank:  879.874 , mrr:  0.0408407 , r1:  0.0268252 , r10:  0.0727593 , r50:  0.122172 , auc:  0.550518 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.94 s ( 0.073 M/sec ); Eval 2*30326 edges in 2.83 s ( 0.021 M/sec ); io: 0.12 s for 361,801,456 bytes ( 2945.75 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 8 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 9 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  530.204 , pos_rank:  879.972 , mrr:  0.0404815 , r1:  0.0260832 , r10:  0.0729902 , r50:  0.122502 , auc:  0.551787 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.1493 , reg:  0 , violators_lhs:  9.43663 , violators_rhs:  4.66504 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  530.085 , pos_rank:  879.076 , mrr:  0.0406628 , r1:  0.0266933 , r10:  0.0723636 , r50:  0.122502 , auc:  0.54943 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.38 s ( 0.078 M/sec ); Eval 2*30326 edges in 2.03 s ( 0.03 M/sec ); io: 0.11 s for 361,801,456 bytes ( 3243.83 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 9 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 10 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  530.173 , pos_rank:  879.44 , mrr:  0.0407324 , r1:  0.0268087 , r10:  0.0723636 , r50:  0.12237 , auc:  0.549825 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.12988 , reg:  0 , violators_lhs:  9.41443 , violators_rhs:  4.60708 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  530.867 , pos_rank:  880.135 , mrr:  0.0409652 , r1:  0.0271384 , r10:  0.0720998 , r50:  0.122255 , auc:  0.552941 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.43 s ( 0.078 M/sec ); Eval 2*30326 edges in 2.01 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3080.71 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 10 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 11 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  530.694 , pos_rank:  879.685 , mrr:  0.0409075 , r1:  0.0269571 , r10:  0.071836 , r50:  0.122057 , auc:  0.551655 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.11626 , reg:  0 , violators_lhs:  9.40193 , violators_rhs:  4.56508 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  531.478 , pos_rank:  879.41 , mrr:  0.040872 , r1:  0.0268087 , r10:  0.073254 , r50:  0.122931 , auc:  0.546132 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.38 s ( 0.078 M/sec ); Eval 2*30326 edges in 2.01 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3088.35 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 11 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 12 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  531.675 , pos_rank:  879.666 , mrr:  0.0405074 , r1:  0.0262481 , r10:  0.0728418 , r50:  0.123013 , auc:  0.54849 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.10661 , reg:  0 , violators_lhs:  9.4107 , violators_rhs:  4.56609 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  532.106 , pos_rank:  880.508 , mrr:  0.040345 , r1:  0.0263305 , r10:  0.0724296 , r50:  0.122618 , auc:  0.549759 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.35 s ( 0.078 M/sec ); Eval 2*30326 edges in 2.04 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3104.49 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 12 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 13 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  532.641 , pos_rank:  880.736 , mrr:  0.0399354 , r1:  0.0254072 , r10:  0.0726769 , r50:  0.122766 , auc:  0.546841 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.09403 , reg:  0 , violators_lhs:  9.38478 , violators_rhs:  4.53374 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  532.419 , pos_rank:  881.926 , mrr:  0.0412128 , r1:  0.0272538 , r10:  0.0724791 , r50:  0.123096 , auc:  0.55309 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.29 s ( 0.079 M/sec ); Eval 2*30326 edges in 2.05 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3105.18 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 13 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 14 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  533.673 , pos_rank:  881.567 , mrr:  0.0412701 , r1:  0.0273528 , r10:  0.0730891 , r50:  0.123294 , auc:  0.547517 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.08868 , reg:  0 , violators_lhs:  9.40624 , violators_rhs:  4.51091 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  534.01 , pos_rank:  880.793 , mrr:  0.0410015 , r1:  0.027023 , r10:  0.0730231 , r50:  0.122766 , auc:  0.546181 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.29 s ( 0.079 M/sec ); Eval 2*30326 edges in 2.03 s ( 0.03 M/sec ); io: 0.11 s for 361,801,456 bytes ( 3152.22 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 14 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 15 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  532.557 , pos_rank:  880.596 , mrr:  0.0408098 , r1:  0.0266933 , r10:  0.0736167 , r50:  0.122898 , auc:  0.546247 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.07593 , reg:  0 , violators_lhs:  9.37683 , violators_rhs:  4.50653 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  533.042 , pos_rank:  880.261 , mrr:  0.0407315 , r1:  0.0268746 , r10:  0.0728253 , r50:  0.122799 , auc:  0.552463 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.21 s ( 0.08 M/sec ); Eval 2*30326 edges in 1.99 s ( 0.03 M/sec ); io: 0.11 s for 361,801,456 bytes ( 3284.16 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 15 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 16 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  533.637 , pos_rank:  880.3 , mrr:  0.0401252 , r1:  0.0256875 , r10:  0.0730561 , r50:  0.122832 , auc:  0.552117 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.06852 , reg:  0 , violators_lhs:  9.38005 , violators_rhs:  4.4821 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  534.12 , pos_rank:  880.934 , mrr:  0.0411119 , r1:  0.0271384 , r10:  0.073155 , r50:  0.123195 , auc:  0.552348 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.25 s ( 0.08 M/sec ); Eval 2*30326 edges in 2.00 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3141.29 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 16 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 17 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  534.029 , pos_rank:  880.885 , mrr:  0.0411068 , r1:  0.027089 , r10:  0.0733694 , r50:  0.123178 , auc:  0.546033 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.06272 , reg:  0 , violators_lhs:  9.38125 , violators_rhs:  4.46575 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  534.302 , pos_rank:  880.349 , mrr:  0.0416756 , r1:  0.0275341 , r10:  0.0734353 , r50:  0.124085 , auc:  0.545324 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.25 s ( 0.079 M/sec ); Eval 2*30326 edges in 2.64 s ( 0.023 M/sec ); io: 0.11 s for 361,801,456 bytes ( 3217.07 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 17 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 18 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  534.142 , pos_rank:  880.446 , mrr:  0.0418419 , r1:  0.0277155 , r10:  0.073897 , r50:  0.124283 , auc:  0.548341 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.05764 , reg:  0 , violators_lhs:  9.38059 , violators_rhs:  4.44234 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  534.83 , pos_rank:  881.513 , mrr:  0.0406295 , r1:  0.0267592 , r10:  0.072611 , r50:  0.122634 , auc:  0.547632 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.24 s ( 0.08 M/sec ); Eval 2*30326 edges in 2.14 s ( 0.028 M/sec ); io: 0.13 s for 361,801,456 bytes ( 2797.06 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 18 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 19 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  534.167 , pos_rank:  880.859 , mrr:  0.0407371 , r1:  0.0267922 , r10:  0.0733199 , r50:  0.122782 , auc:  0.549512 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.04948 , reg:  0 , violators_lhs:  9.36041 , violators_rhs:  4.42942 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  535.167 , pos_rank:  881.767 , mrr:  0.041923 , r1:  0.0279793 , r10:  0.0736497 , r50:  0.123046 , auc:  0.547764 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.22 s ( 0.08 M/sec ); Eval 2*30326 edges in 2.03 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3049.06 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 19 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 20 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  534.839 , pos_rank:  881.679 , mrr:  0.0419075 , r1:  0.0278804 , r10:  0.0737816 , r50:  0.123228 , auc:  0.547962 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.04364 , reg:  0 , violators_lhs:  9.35477 , violators_rhs:  4.41797 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  534.378 , pos_rank:  880.325 , mrr:  0.0414941 , r1:  0.0275506 , r10:  0.0734518 , r50:  0.123541 , auc:  0.547665 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.39 s ( 0.078 M/sec ); Eval 2*30326 edges in 2.07 s ( 0.029 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3125.14 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 20 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 21 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  534.561 , pos_rank:  880.975 , mrr:  0.0414712 , r1:  0.0274517 , r10:  0.0733364 , r50:  0.12331 , auc:  0.548061 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.03914 , reg:  0 , violators_lhs:  9.35615 , violators_rhs:  4.39494 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  535.124 , pos_rank:  880.93 , mrr:  0.0415621 , r1:  0.0277485 , r10:  0.0735507 , r50:  0.123063 , auc:  0.548391 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.21 s ( 0.08 M/sec ); Eval 2*30326 edges in 2.08 s ( 0.029 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3055.77 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 21 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 22 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  535.99 , pos_rank:  881.474 , mrr:  0.0416591 , r1:  0.0279628 , r10:  0.0731386 , r50:  0.123079 , auc:  0.549561 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.03241 , reg:  0 , violators_lhs:  9.34357 , violators_rhs:  4.39373 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  535.196 , pos_rank:  881.138 , mrr:  0.0406865 , r1:  0.0266438 , r10:  0.072611 , r50:  0.122651 , auc:  0.549017 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.22 s ( 0.08 M/sec ); Eval 2*30326 edges in 2.05 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3143.17 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 22 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 23 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  535.325 , pos_rank:  881.274 , mrr:  0.0405652 , r1:  0.0265614 , r10:  0.0729407 , r50:  0.122931 , auc:  0.546973 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.0314 , reg:  0 , violators_lhs:  9.35864 , violators_rhs:  4.38268 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  535.666 , pos_rank:  881.735 , mrr:  0.041166 , r1:  0.0272538 , r10:  0.0730396 , r50:  0.123359 , auc:  0.547913 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.44 s ( 0.077 M/sec ); Eval 2*30326 edges in 2.07 s ( 0.029 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3072.72 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 23 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 24 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  535.367 , pos_rank:  881.627 , mrr:  0.041259 , r1:  0.0274517 , r10:  0.0731056 , r50:  0.123178 , auc:  0.547418 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.02369 , reg:  0 , violators_lhs:  9.33388 , violators_rhs:  4.36981 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  534.963 , pos_rank:  880.394 , mrr:  0.0417464 , r1:  0.0279133 , r10:  0.0732045 , r50:  0.123162 , auc:  0.547781 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.42 s ( 0.078 M/sec ); Eval 2*30326 edges in 2.02 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3050.42 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 24 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 25 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  536.219 , pos_rank:  880.751 , mrr:  0.0418603 , r1:  0.0281277 , r10:  0.0734024 , r50:  0.122931 , auc:  0.552035 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.02013 , reg:  0 , violators_lhs:  9.33608 , violators_rhs:  4.34934 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  534.444 , pos_rank:  880.409 , mrr:  0.0423296 , r1:  0.0287212 , r10:  0.073188 , r50:  0.123327 , auc:  0.547665 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.42 s ( 0.078 M/sec ); Eval 2*30326 edges in 2.03 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3081.21 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 25 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 26 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  535.343 , pos_rank:  881.021 , mrr:  0.0422835 , r1:  0.0284245 , r10:  0.0736826 , r50:  0.123541 , auc:  0.550188 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.01536 , reg:  0 , violators_lhs:  9.33011 , violators_rhs:  4.36459 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  535.981 , pos_rank:  881.004 , mrr:  0.042679 , r1:  0.0288861 , r10:  0.0736332 , r50:  0.123722 , auc:  0.549281 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.48 s ( 0.077 M/sec ); Eval 2*30326 edges in 2.02 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 2946.33 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 26 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 27 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  535.268 , pos_rank:  880.825 , mrr:  0.0426513 , r1:  0.0287872 , r10:  0.07393 , r50:  0.123541 , auc:  0.553601 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.01266 , reg:  0 , violators_lhs:  9.33116 , violators_rhs:  4.35496 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  535.067 , pos_rank:  881.516 , mrr:  0.0418337 , r1:  0.0281442 , r10:  0.0728748 , r50:  0.122964 , auc:  0.548061 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 8.85 s ( 0.065 M/sec ); Eval 2*30326 edges in 2.04 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3054.79 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 27 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 28 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  535.39 , pos_rank:  881.03 , mrr:  0.0418323 , r1:  0.0281442 , r10:  0.0730891 , r50:  0.122881 , auc:  0.547138 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.00692 , reg:  0 , violators_lhs:  9.3149 , violators_rhs:  4.32875 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  534.555 , pos_rank:  879.716 , mrr:  0.0413751 , r1:  0.0276331 , r10:  0.0727923 , r50:  0.123178 , auc:  0.552018 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.30 s ( 0.079 M/sec ); Eval 2*30326 edges in 2.04 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 2935.49 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 28 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 29 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  535.278 , pos_rank:  880.808 , mrr:  0.040342 , r1:  0.0256216 , r10:  0.0724791 , r50:  0.123063 , auc:  0.548638 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.00498 , reg:  0 , violators_lhs:  9.32182 , violators_rhs:  4.32408 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  535.531 , pos_rank:  880.462 , mrr:  0.0418005 , r1:  0.0279463 , r10:  0.0737486 , r50:  0.123706 , auc:  0.546759 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.25 s ( 0.08 M/sec ); Eval 2*30326 edges in 1.96 s ( 0.031 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3107.69 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 29 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Starting epoch 30 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Edge path: data/train_partitioned\n",
            "INFO:torchbiggraph:still in queue: 0\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings None ( 0 , 0 )\n",
            "INFO:torchbiggraph:Loading partitioned embeddings from checkpoint\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats before training: loss:  536.812 , pos_rank:  881.11 , mrr:  0.0414722 , r1:  0.0274352 , r10:  0.0733199 , r50:  0.123475 , auc:  0.547336 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): Training stats: loss:  3.00228 , reg:  0 , violators_lhs:  9.32563 , violators_rhs:  4.32622 , count:  576212\n",
            "INFO:torchbiggraph:( 0 , 0 ): Stats after training: loss:  535.656 , pos_rank:  880.958 , mrr:  0.0417162 , r1:  0.0278309 , r10:  0.0728253 , r50:  0.122964 , auc:  0.548787 , count:  30326\n",
            "INFO:torchbiggraph:( 0 , 0 ): bucket 1 / 1 : Trained 576212 edges in 7.22 s ( 0.08 M/sec ); Eval 2*30326 edges in 2.05 s ( 0.03 M/sec ); io: 0.12 s for 361,801,456 bytes ( 3079.05 MB/sec )\n",
            "INFO:torchbiggraph:Swapping partitioned embeddings ( 0 , 0 ) None\n",
            "INFO:torchbiggraph:Saving partitioned embeddings to checkpoint\n",
            "INFO:torchbiggraph:Finished epoch 30 / 30, edge path 1 / 1, edge chunk 1 / 1\n",
            "INFO:torchbiggraph:Writing the metadata\n",
            "INFO:torchbiggraph:Writing the training stats\n",
            "INFO:torchbiggraph:Writing the checkpoint\n",
            "INFO:torchbiggraph:Switching to the new checkpoint version\n",
            "INFO:torchbiggraph:Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_config = attr.evolve(config, edge_paths=[output_test_path])\n",
        "do_eval(eval_config, subprocess_init=subprocess_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTI_xjLuFeVd",
        "outputId": "ad44ed22-c922-4bc4-a77e-fefa5e654111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:torchbiggraph:Starting edge path 1 / 1 (data/test_partitioned)\n",
            "INFO:torchbiggraph:( 0 , 0 ): Processed 151636 edges in 2 s (0.074M/sec); load time: 0.32 s\n",
            "INFO:torchbiggraph:Stats for edge path 1 / 1, bucket ( 0 , 0 ): loss:  27.5652 , pos_rank:  46.4381 , mrr:  0.111293 , r1:  0.0639756 , r10:  0.16411 , r50:  0.552768 , auc:  0.537062 , count:  151636\n",
            "INFO:torchbiggraph:\n",
            "INFO:torchbiggraph:Stats for edge path 1 / 1: loss:  27.5652 , pos_rank:  46.4381 , mrr:  0.111293 , r1:  0.0639756 , r10:  0.16411 , r50:  0.552768 , auc:  0.537062 , count:  151636\n",
            "INFO:torchbiggraph:\n",
            "INFO:torchbiggraph:\n",
            "INFO:torchbiggraph:Stats: loss:  27.5652 , pos_rank:  46.4381 , mrr:  0.111293 , r1:  0.0639756 , r10:  0.16411 , r50:  0.552768 , auc:  0.537062 , count:  151636\n",
            "INFO:torchbiggraph:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!torchbiggraph_export_to_tsv \\\n",
        "    'PyTorch-BigGraph/torchbiggraph/examples/configs/politifact_config.py' \\\n",
        "    --entities-output entity_embeddings.tsv \\\n",
        "    --relation-types-output relation_types_parameters.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHjXkt89LR5C",
        "outputId": "3bcea243-cd3e-4850-8f4d-a56be0190a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading relation types and entities...\n",
            "Initializing model...\n",
            "Loading model check point...\n",
            "Writing entity embeddings...\n",
            "Reading embeddings for entity type user partition 0 from checkpoint...\n",
            "Writing embeddings for entity type user partition 0 to output file...\n",
            "- Processed 5000/678041 entities so far...\n",
            "- Processed 10000/678041 entities so far...\n",
            "- Processed 15000/678041 entities so far...\n",
            "- Processed 20000/678041 entities so far...\n",
            "- Processed 25000/678041 entities so far...\n",
            "- Processed 30000/678041 entities so far...\n",
            "- Processed 35000/678041 entities so far...\n",
            "- Processed 40000/678041 entities so far...\n",
            "- Processed 45000/678041 entities so far...\n",
            "- Processed 50000/678041 entities so far...\n",
            "- Processed 55000/678041 entities so far...\n",
            "- Processed 60000/678041 entities so far...\n",
            "- Processed 65000/678041 entities so far...\n",
            "- Processed 70000/678041 entities so far...\n",
            "- Processed 75000/678041 entities so far...\n",
            "- Processed 80000/678041 entities so far...\n",
            "- Processed 85000/678041 entities so far...\n",
            "- Processed 90000/678041 entities so far...\n",
            "- Processed 95000/678041 entities so far...\n",
            "- Processed 100000/678041 entities so far...\n",
            "- Processed 105000/678041 entities so far...\n",
            "- Processed 110000/678041 entities so far...\n",
            "- Processed 115000/678041 entities so far...\n",
            "- Processed 120000/678041 entities so far...\n",
            "- Processed 125000/678041 entities so far...\n",
            "- Processed 130000/678041 entities so far...\n",
            "- Processed 135000/678041 entities so far...\n",
            "- Processed 140000/678041 entities so far...\n",
            "- Processed 145000/678041 entities so far...\n",
            "- Processed 150000/678041 entities so far...\n",
            "- Processed 155000/678041 entities so far...\n",
            "- Processed 160000/678041 entities so far...\n",
            "- Processed 165000/678041 entities so far...\n",
            "- Processed 170000/678041 entities so far...\n",
            "- Processed 175000/678041 entities so far...\n",
            "- Processed 180000/678041 entities so far...\n",
            "- Processed 185000/678041 entities so far...\n",
            "- Processed 190000/678041 entities so far...\n",
            "- Processed 195000/678041 entities so far...\n",
            "- Processed 200000/678041 entities so far...\n",
            "- Processed 205000/678041 entities so far...\n",
            "- Processed 210000/678041 entities so far...\n",
            "- Processed 215000/678041 entities so far...\n",
            "- Processed 220000/678041 entities so far...\n",
            "- Processed 225000/678041 entities so far...\n",
            "- Processed 230000/678041 entities so far...\n",
            "- Processed 235000/678041 entities so far...\n",
            "- Processed 240000/678041 entities so far...\n",
            "- Processed 245000/678041 entities so far...\n",
            "- Processed 250000/678041 entities so far...\n",
            "- Processed 255000/678041 entities so far...\n",
            "- Processed 260000/678041 entities so far...\n",
            "- Processed 265000/678041 entities so far...\n",
            "- Processed 270000/678041 entities so far...\n",
            "- Processed 275000/678041 entities so far...\n",
            "- Processed 280000/678041 entities so far...\n",
            "- Processed 285000/678041 entities so far...\n",
            "- Processed 290000/678041 entities so far...\n",
            "- Processed 295000/678041 entities so far...\n",
            "- Processed 300000/678041 entities so far...\n",
            "- Processed 305000/678041 entities so far...\n",
            "- Processed 310000/678041 entities so far...\n",
            "- Processed 315000/678041 entities so far...\n",
            "- Processed 320000/678041 entities so far...\n",
            "- Processed 325000/678041 entities so far...\n",
            "- Processed 330000/678041 entities so far...\n",
            "- Processed 335000/678041 entities so far...\n",
            "- Processed 340000/678041 entities so far...\n",
            "- Processed 345000/678041 entities so far...\n",
            "- Processed 350000/678041 entities so far...\n",
            "- Processed 355000/678041 entities so far...\n",
            "- Processed 360000/678041 entities so far...\n",
            "- Processed 365000/678041 entities so far...\n",
            "- Processed 370000/678041 entities so far...\n",
            "- Processed 375000/678041 entities so far...\n",
            "- Processed 380000/678041 entities so far...\n",
            "- Processed 385000/678041 entities so far...\n",
            "- Processed 390000/678041 entities so far...\n",
            "- Processed 395000/678041 entities so far...\n",
            "- Processed 400000/678041 entities so far...\n",
            "- Processed 405000/678041 entities so far...\n",
            "- Processed 410000/678041 entities so far...\n",
            "- Processed 415000/678041 entities so far...\n",
            "- Processed 420000/678041 entities so far...\n",
            "- Processed 425000/678041 entities so far...\n",
            "- Processed 430000/678041 entities so far...\n",
            "- Processed 435000/678041 entities so far...\n",
            "- Processed 440000/678041 entities so far...\n",
            "- Processed 445000/678041 entities so far...\n",
            "- Processed 450000/678041 entities so far...\n",
            "- Processed 455000/678041 entities so far...\n",
            "- Processed 460000/678041 entities so far...\n",
            "- Processed 465000/678041 entities so far...\n",
            "- Processed 470000/678041 entities so far...\n",
            "- Processed 475000/678041 entities so far...\n",
            "- Processed 480000/678041 entities so far...\n",
            "- Processed 485000/678041 entities so far...\n",
            "- Processed 490000/678041 entities so far...\n",
            "- Processed 495000/678041 entities so far...\n",
            "- Processed 500000/678041 entities so far...\n",
            "- Processed 505000/678041 entities so far...\n",
            "- Processed 510000/678041 entities so far...\n",
            "- Processed 515000/678041 entities so far...\n",
            "- Processed 520000/678041 entities so far...\n",
            "- Processed 525000/678041 entities so far...\n",
            "- Processed 530000/678041 entities so far...\n",
            "- Processed 535000/678041 entities so far...\n",
            "- Processed 540000/678041 entities so far...\n",
            "- Processed 545000/678041 entities so far...\n",
            "- Processed 550000/678041 entities so far...\n",
            "- Processed 555000/678041 entities so far...\n",
            "- Processed 560000/678041 entities so far...\n",
            "- Processed 565000/678041 entities so far...\n",
            "- Processed 570000/678041 entities so far...\n",
            "- Processed 575000/678041 entities so far...\n",
            "- Processed 580000/678041 entities so far...\n",
            "- Processed 585000/678041 entities so far...\n",
            "- Processed 590000/678041 entities so far...\n",
            "- Processed 595000/678041 entities so far...\n",
            "- Processed 600000/678041 entities so far...\n",
            "- Processed 605000/678041 entities so far...\n",
            "- Processed 610000/678041 entities so far...\n",
            "- Processed 615000/678041 entities so far...\n",
            "- Processed 620000/678041 entities so far...\n",
            "- Processed 625000/678041 entities so far...\n",
            "- Processed 630000/678041 entities so far...\n",
            "- Processed 635000/678041 entities so far...\n",
            "- Processed 640000/678041 entities so far...\n",
            "- Processed 645000/678041 entities so far...\n",
            "- Processed 650000/678041 entities so far...\n",
            "- Processed 655000/678041 entities so far...\n",
            "- Processed 660000/678041 entities so far...\n",
            "- Processed 665000/678041 entities so far...\n",
            "- Processed 670000/678041 entities so far...\n",
            "- Processed 675000/678041 entities so far...\n",
            "- Processed all 678041 entities\n",
            "Reading embeddings for entity type article partition 0 from checkpoint...\n",
            "Writing embeddings for entity type article partition 0 to output file...\n",
            "- Processed all 171 entities\n",
            "Done exporting entity data to entity_embeddings.tsv\n",
            "Writing relation type parameters...\n",
            "Done exporting relation type data to relation_types_parameters.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gitsource for PBG: https://github.com/facebookresearch/PyTorch-BigGraph#training: all explanations here. "
      ],
      "metadata": {
        "id": "88BrXT_sL0uB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}