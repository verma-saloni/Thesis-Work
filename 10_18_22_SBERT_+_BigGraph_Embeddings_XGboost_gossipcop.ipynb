{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verma-saloni/Thesis-Work/blob/main/10_18_22_SBERT_%2B_BigGraph_Embeddings_XGboost_gossipcop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "!pip install -U xgboost sentence-transformers wandb"
      ],
      "metadata": {
        "id": "aByzVMdkzqAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eee496d-eeed-41ad-dd02-50090f796b28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.97)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.23.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.29)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook for SBERt+Biggraph embeddings, for Gossipcop dataset. Logged results on Wandb (saloniteam project)"
      ],
      "metadata": {
        "id": "XpfK1y8X_Tkh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8wffusyCytsx"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "\n",
        "from sentence_transformers import SentenceTransformer \n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import xgboost as xgb\n",
        "\n",
        "import wandb\n",
        "from wandb.xgboost import WandbCallback\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [accuracy_score, f1_score, precision_score, recall_score]\n",
        "\n",
        "def get_name(score_func):\n",
        "    return score_func.__name__.split(\"_\")[0]"
      ],
      "metadata": {
        "id": "oUUMZeWMuZXE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "R_4mZElNIVb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_dir = Path(\"/content/drive/MyDrive/ResearchFND\")\n",
        "assert base_dir.exists()"
      ],
      "metadata": {
        "id": "UxNEaltli8H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa98a55f-6f67-4f11-e1c8-0a26b91e464a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_id = 'gossipcop'"
      ],
      "metadata": {
        "id": "p1sDxnH0xX1S"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "converters = {\"retweets\":ast.literal_eval, \"tweets\":ast.literal_eval}\n",
        "df = pd.read_csv(base_dir/f\"{dataset_id}_agg.csv\", converters=converters)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2YYgYvwB7nkO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "63c01b63-39c5-4835-d465-e5c28725d839"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title text  \\\n",
              "0      Kendall   Kylie Jenner Jenner NOT Upset Up...  NaN   \n",
              "1      Kim Kardashian Dethroned Dethroned By Khlo...  NaN   \n",
              "2      Kim Kardashian Did NOT Hot Staffer Hot Sta...  NaN   \n",
              "3      The Voice The Voice Team NOT Surprised Sur...  NaN   \n",
              "4     Drake NOT Angelina Jolie s Toy Boy Toy Boy ...  NaN   \n",
              "\n",
              "                                              tweets  \\\n",
              "0                                                 []   \n",
              "1                                                 []   \n",
              "2                                                 []   \n",
              "3                                                 []   \n",
              "4  [{'id': 948630026496323585, 'text': 'Drake NOT...   \n",
              "\n",
              "                                            retweets label  url  num_retweets  \\\n",
              "0  [995423424741888001, 995461685166202880, 99987...  fake  NaN             3   \n",
              "1  [848843565027516416, 849030801970868224, 84884...  fake  NaN             3   \n",
              "2  [940685393112064001, 977921622672920576, 94031...  fake  NaN             8   \n",
              "3                                                 []  fake  NaN             0   \n",
              "4  [948022124626808832, 948630026496323585, 94801...  fake  NaN            18   \n",
              "\n",
              "   log_num_retweets  num_tweets  log_num_tweets  \n",
              "0          1.386294           0        0.000000  \n",
              "1          1.386294           0        0.000000  \n",
              "2          2.197225           0        0.000000  \n",
              "3          0.000000           0        0.000000  \n",
              "4          2.944439           7        2.079442  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebfc1658-3520-401f-acd5-26db153a6913\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>tweets</th>\n",
              "      <th>retweets</th>\n",
              "      <th>label</th>\n",
              "      <th>url</th>\n",
              "      <th>num_retweets</th>\n",
              "      <th>log_num_retweets</th>\n",
              "      <th>num_tweets</th>\n",
              "      <th>log_num_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kendall   Kylie Jenner Jenner NOT Upset Up...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[995423424741888001, 995461685166202880, 99987...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kim Kardashian Dethroned Dethroned By Khlo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[848843565027516416, 849030801970868224, 84884...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kim Kardashian Did NOT Hot Staffer Hot Sta...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[940685393112064001, 977921622672920576, 94031...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Voice The Voice Team NOT Surprised Sur...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Drake NOT Angelina Jolie s Toy Boy Toy Boy ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'id': 948630026496323585, 'text': 'Drake NOT...</td>\n",
              "      <td>[948022124626808832, 948630026496323585, 94801...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>2.944439</td>\n",
              "      <td>7</td>\n",
              "      <td>2.079442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebfc1658-3520-401f-acd5-26db153a6913')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebfc1658-3520-401f-acd5-26db153a6913 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebfc1658-3520-401f-acd5-26db153a6913');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.title.isna().sum(), (df.title == \"\").sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2PltrGzNia4",
        "outputId": "0349fa42-cd84-49f5-d512-6a60817b8397"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles = df.title.tolist()\n",
        "texts = (df.title + \" \" + df.text).tolist()"
      ],
      "metadata": {
        "id": "9BG1btWEm0b_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfZSpiXU8IHY",
        "outputId": "cbb77171-f876-4b65-b16c-2bdbf940e1b6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19968"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare emebeddings"
      ],
      "metadata": {
        "id": "CnksS6trIRdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_embedding_file = base_dir/f\"{dataset_id}_sbert_title_embeddings.npy\"\n",
        "\n",
        "if title_embedding_file.exists():\n",
        "    title_embeddings = np.load(title_embedding_file)\n",
        "else:\n",
        "    model_id = \"all-mpnet-base-v2\"\n",
        "    model = SentenceTransformer(model_id)\n",
        "    titles = df.title.tolist()\n",
        "    title_embeddings = model.encode(titles, show_progress_bar=True)\n",
        "    np.save(title_embedding_file, title_embeddings)"
      ],
      "metadata": {
        "id": "fwwbRvyOpCcl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_embedding_file = base_dir/f\"{dataset_id}_sbert_fulltext_embeddings.npy\"\n",
        "\n",
        "if text_embedding_file.exists():\n",
        "    text_embeddings = np.load(text_embedding_file)\n",
        "else:\n",
        "    model_id = \"all-mpnet-base-v2\"\n",
        "    model = SentenceTransformer(model_id)\n",
        "    texts = (df.title + \"\\n\" + df.text).tolist()\n",
        "    text_embeddings = model.encode(texts, show_progress_bar=True)\n",
        "    np.save(text_embedding_file, text_embeddings)"
      ],
      "metadata": {
        "id": "Ey0dv12fpCcn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edim = 128\n",
        "bg_embeddings = np.load(base_dir/f'{dataset_id}_pt_biggraph_article_embeddings_{edim}.npy')\n",
        "idx = np.load(base_dir/f\"{dataset_id}_pt_biggraph_article_idx_{edim}.npy\")"
      ],
      "metadata": {
        "id": "uQjE8biJFfW8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_embeddings = np.zeros((text_embeddings.shape[0], edim))\n",
        "graph_embeddings[idx] = bg_embeddings"
      ],
      "metadata": {
        "id": "NWS6KO7UpUX3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate([\n",
        "    text_embeddings, \n",
        "    df.num_retweets.to_numpy()[..., None], \n",
        "    df.num_tweets.to_numpy()[..., None],\n",
        "    graph_embeddings], axis=1)\n",
        "y = (df.label==\"real\").to_numpy().astype(int)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9484f08-9e12-4a60-a741-686eeace13e8",
        "id": "CHZ56FHKxQd3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19968, 898), (19968,))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(shuffle=True, random_state=124)"
      ],
      "metadata": {
        "id": "Ec5ppDaQK16F"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traing XGB"
      ],
      "metadata": {
        "id": "pOEREu_Yz5YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_idx, test_idx, params):\n",
        "\n",
        "    # training\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "    watchlist = [(dtrain,'train'), (dtest,'eval')]\n",
        "    clf = xgb.train(params, dtrain, num_boost_round=params['num_boost_round'], early_stopping_rounds=None, evals=watchlist, callbacks=[WandbCallback()])\n",
        "    #evaluation\n",
        "    probs = clf.predict(dtest)\n",
        "    y_pred = (probs > 0.5).astype(int)\n",
        "    eval_results = {get_name(f):f(y_pred=y_pred, y_true=y_test) for f in metrics}\n",
        "    wandb.log(eval_results)\n",
        "    wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
        "                            y_true=y_test, preds=y_pred,\n",
        "                            class_names=[\"Fake\", \"Real\"])})"
      ],
      "metadata": {
        "id": "5oSeII1QLot_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"objective\":'binary:logistic',\n",
        "    \"seed\":124,\n",
        "    \"num_boost_round\":400\n",
        "}"
      ],
      "metadata": {
        "id": "5IvqyG9jPVQw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WANDB_ENTITY = 'saloniteam'\n",
        "WANDB_PROJECT = 'nofolds'\n",
        "GROUP = \"gossipcop-sbert-mpnet-v2-biggraph128-xgbE400\"\n",
        "\n",
        "for fold_id, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "    clear_output()\n",
        "    with wandb.init(entity=WANDB_ENTITY, project=WANDB_PROJECT, group=GROUP, name=f\"{GROUP}-fold-{fold_id}\", tags=['xgb', 'sbert', 'biggraph']) as run:\n",
        "        train(train_idx, test_idx, params)\n",
        "    break"
      ],
      "metadata": {
        "id": "UoH1hD_3-rt8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d573faa-8de6-4b5d-a2ca-026acd295096"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaloni\u001b[0m (\u001b[33msaloniteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221018_133332-ps1yufcd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/saloniteam/nofolds/runs/ps1yufcd\" target=\"_blank\">gossipcop-sbert-mpnet-v2-biggraph128-xgbE400-fold-0</a></strong> to <a href=\"https://wandb.ai/saloniteam/nofolds\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:33:33] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"num_boost_round\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[0]\ttrain-logloss:0.53893\teval-logloss:0.55267\n",
            "[1]\ttrain-logloss:0.44819\teval-logloss:0.47325\n",
            "[2]\ttrain-logloss:0.38859\teval-logloss:0.42444\n",
            "[3]\ttrain-logloss:0.34590\teval-logloss:0.39308\n",
            "[4]\ttrain-logloss:0.31374\teval-logloss:0.36986\n",
            "[5]\ttrain-logloss:0.28707\teval-logloss:0.35301\n",
            "[6]\ttrain-logloss:0.26881\teval-logloss:0.34220\n",
            "[7]\ttrain-logloss:0.25077\teval-logloss:0.33604\n",
            "[8]\ttrain-logloss:0.23792\teval-logloss:0.33084\n",
            "[9]\ttrain-logloss:0.22448\teval-logloss:0.32632\n",
            "[10]\ttrain-logloss:0.21605\teval-logloss:0.32081\n",
            "[11]\ttrain-logloss:0.20413\teval-logloss:0.31601\n",
            "[12]\ttrain-logloss:0.19312\teval-logloss:0.31348\n",
            "[13]\ttrain-logloss:0.18783\teval-logloss:0.31075\n",
            "[14]\ttrain-logloss:0.17895\teval-logloss:0.30842\n",
            "[15]\ttrain-logloss:0.17418\teval-logloss:0.30604\n",
            "[16]\ttrain-logloss:0.16805\teval-logloss:0.30530\n",
            "[17]\ttrain-logloss:0.15866\teval-logloss:0.30294\n",
            "[18]\ttrain-logloss:0.15225\teval-logloss:0.30235\n",
            "[19]\ttrain-logloss:0.14868\teval-logloss:0.30104\n",
            "[20]\ttrain-logloss:0.14564\teval-logloss:0.29903\n",
            "[21]\ttrain-logloss:0.14009\teval-logloss:0.29871\n",
            "[22]\ttrain-logloss:0.13413\teval-logloss:0.29757\n",
            "[23]\ttrain-logloss:0.13081\teval-logloss:0.29597\n",
            "[24]\ttrain-logloss:0.12853\teval-logloss:0.29592\n",
            "[25]\ttrain-logloss:0.12260\teval-logloss:0.29648\n",
            "[26]\ttrain-logloss:0.11949\teval-logloss:0.29598\n",
            "[27]\ttrain-logloss:0.11504\teval-logloss:0.29550\n",
            "[28]\ttrain-logloss:0.11024\teval-logloss:0.29516\n",
            "[29]\ttrain-logloss:0.10700\teval-logloss:0.29400\n",
            "[30]\ttrain-logloss:0.10422\teval-logloss:0.29320\n",
            "[31]\ttrain-logloss:0.10190\teval-logloss:0.29363\n",
            "[32]\ttrain-logloss:0.10000\teval-logloss:0.29290\n",
            "[33]\ttrain-logloss:0.09787\teval-logloss:0.29293\n",
            "[34]\ttrain-logloss:0.09628\teval-logloss:0.29159\n",
            "[35]\ttrain-logloss:0.09437\teval-logloss:0.29216\n",
            "[36]\ttrain-logloss:0.09141\teval-logloss:0.29318\n",
            "[37]\ttrain-logloss:0.09027\teval-logloss:0.29284\n",
            "[38]\ttrain-logloss:0.08633\teval-logloss:0.29151\n",
            "[39]\ttrain-logloss:0.08426\teval-logloss:0.29150\n",
            "[40]\ttrain-logloss:0.08162\teval-logloss:0.29198\n",
            "[41]\ttrain-logloss:0.08018\teval-logloss:0.29120\n",
            "[42]\ttrain-logloss:0.07822\teval-logloss:0.29125\n",
            "[43]\ttrain-logloss:0.07652\teval-logloss:0.29167\n",
            "[44]\ttrain-logloss:0.07455\teval-logloss:0.29149\n",
            "[45]\ttrain-logloss:0.07305\teval-logloss:0.29104\n",
            "[46]\ttrain-logloss:0.07058\teval-logloss:0.29226\n",
            "[47]\ttrain-logloss:0.06918\teval-logloss:0.29218\n",
            "[48]\ttrain-logloss:0.06812\teval-logloss:0.29212\n",
            "[49]\ttrain-logloss:0.06613\teval-logloss:0.29218\n",
            "[50]\ttrain-logloss:0.06443\teval-logloss:0.29257\n",
            "[51]\ttrain-logloss:0.06255\teval-logloss:0.29302\n",
            "[52]\ttrain-logloss:0.06153\teval-logloss:0.29212\n",
            "[53]\ttrain-logloss:0.05948\teval-logloss:0.29300\n",
            "[54]\ttrain-logloss:0.05751\teval-logloss:0.29214\n",
            "[55]\ttrain-logloss:0.05536\teval-logloss:0.29254\n",
            "[56]\ttrain-logloss:0.05395\teval-logloss:0.29218\n",
            "[57]\ttrain-logloss:0.05283\teval-logloss:0.29291\n",
            "[58]\ttrain-logloss:0.05210\teval-logloss:0.29293\n",
            "[59]\ttrain-logloss:0.05033\teval-logloss:0.29416\n",
            "[60]\ttrain-logloss:0.04862\teval-logloss:0.29297\n",
            "[61]\ttrain-logloss:0.04764\teval-logloss:0.29319\n",
            "[62]\ttrain-logloss:0.04641\teval-logloss:0.29325\n",
            "[63]\ttrain-logloss:0.04513\teval-logloss:0.29438\n",
            "[64]\ttrain-logloss:0.04392\teval-logloss:0.29421\n",
            "[65]\ttrain-logloss:0.04225\teval-logloss:0.29525\n",
            "[66]\ttrain-logloss:0.04184\teval-logloss:0.29544\n",
            "[67]\ttrain-logloss:0.04070\teval-logloss:0.29548\n",
            "[68]\ttrain-logloss:0.03935\teval-logloss:0.29627\n",
            "[69]\ttrain-logloss:0.03832\teval-logloss:0.29616\n",
            "[70]\ttrain-logloss:0.03737\teval-logloss:0.29634\n",
            "[71]\ttrain-logloss:0.03645\teval-logloss:0.29613\n",
            "[72]\ttrain-logloss:0.03583\teval-logloss:0.29631\n",
            "[73]\ttrain-logloss:0.03465\teval-logloss:0.29683\n",
            "[74]\ttrain-logloss:0.03410\teval-logloss:0.29780\n",
            "[75]\ttrain-logloss:0.03277\teval-logloss:0.29893\n",
            "[76]\ttrain-logloss:0.03177\teval-logloss:0.29998\n",
            "[77]\ttrain-logloss:0.03054\teval-logloss:0.30116\n",
            "[78]\ttrain-logloss:0.02942\teval-logloss:0.30128\n",
            "[79]\ttrain-logloss:0.02856\teval-logloss:0.30133\n",
            "[80]\ttrain-logloss:0.02792\teval-logloss:0.30166\n",
            "[81]\ttrain-logloss:0.02751\teval-logloss:0.30154\n",
            "[82]\ttrain-logloss:0.02722\teval-logloss:0.30229\n",
            "[83]\ttrain-logloss:0.02663\teval-logloss:0.30229\n",
            "[84]\ttrain-logloss:0.02584\teval-logloss:0.30357\n",
            "[85]\ttrain-logloss:0.02559\teval-logloss:0.30373\n",
            "[86]\ttrain-logloss:0.02521\teval-logloss:0.30485\n",
            "[87]\ttrain-logloss:0.02503\teval-logloss:0.30512\n",
            "[88]\ttrain-logloss:0.02442\teval-logloss:0.30517\n",
            "[89]\ttrain-logloss:0.02420\teval-logloss:0.30501\n",
            "[90]\ttrain-logloss:0.02344\teval-logloss:0.30586\n",
            "[91]\ttrain-logloss:0.02281\teval-logloss:0.30713\n",
            "[92]\ttrain-logloss:0.02222\teval-logloss:0.30817\n",
            "[93]\ttrain-logloss:0.02200\teval-logloss:0.30816\n",
            "[94]\ttrain-logloss:0.02141\teval-logloss:0.30851\n",
            "[95]\ttrain-logloss:0.02112\teval-logloss:0.30961\n",
            "[96]\ttrain-logloss:0.02068\teval-logloss:0.30969\n",
            "[97]\ttrain-logloss:0.02008\teval-logloss:0.31047\n",
            "[98]\ttrain-logloss:0.01959\teval-logloss:0.31097\n",
            "[99]\ttrain-logloss:0.01923\teval-logloss:0.31105\n",
            "[100]\ttrain-logloss:0.01875\teval-logloss:0.31131\n",
            "[101]\ttrain-logloss:0.01857\teval-logloss:0.31175\n",
            "[102]\ttrain-logloss:0.01832\teval-logloss:0.31236\n",
            "[103]\ttrain-logloss:0.01790\teval-logloss:0.31280\n",
            "[104]\ttrain-logloss:0.01731\teval-logloss:0.31332\n",
            "[105]\ttrain-logloss:0.01671\teval-logloss:0.31415\n",
            "[106]\ttrain-logloss:0.01646\teval-logloss:0.31461\n",
            "[107]\ttrain-logloss:0.01609\teval-logloss:0.31525\n",
            "[108]\ttrain-logloss:0.01568\teval-logloss:0.31621\n",
            "[109]\ttrain-logloss:0.01530\teval-logloss:0.31765\n",
            "[110]\ttrain-logloss:0.01476\teval-logloss:0.31929\n",
            "[111]\ttrain-logloss:0.01462\teval-logloss:0.31929\n",
            "[112]\ttrain-logloss:0.01442\teval-logloss:0.31974\n",
            "[113]\ttrain-logloss:0.01412\teval-logloss:0.31914\n",
            "[114]\ttrain-logloss:0.01378\teval-logloss:0.31965\n",
            "[115]\ttrain-logloss:0.01358\teval-logloss:0.31975\n",
            "[116]\ttrain-logloss:0.01348\teval-logloss:0.31970\n",
            "[117]\ttrain-logloss:0.01319\teval-logloss:0.32009\n",
            "[118]\ttrain-logloss:0.01307\teval-logloss:0.31956\n",
            "[119]\ttrain-logloss:0.01281\teval-logloss:0.32041\n",
            "[120]\ttrain-logloss:0.01259\teval-logloss:0.32049\n",
            "[121]\ttrain-logloss:0.01222\teval-logloss:0.32135\n",
            "[122]\ttrain-logloss:0.01198\teval-logloss:0.32168\n",
            "[123]\ttrain-logloss:0.01172\teval-logloss:0.32256\n",
            "[124]\ttrain-logloss:0.01145\teval-logloss:0.32314\n",
            "[125]\ttrain-logloss:0.01124\teval-logloss:0.32365\n",
            "[126]\ttrain-logloss:0.01099\teval-logloss:0.32428\n",
            "[127]\ttrain-logloss:0.01078\teval-logloss:0.32429\n",
            "[128]\ttrain-logloss:0.01053\teval-logloss:0.32495\n",
            "[129]\ttrain-logloss:0.01027\teval-logloss:0.32627\n",
            "[130]\ttrain-logloss:0.01015\teval-logloss:0.32685\n",
            "[131]\ttrain-logloss:0.00991\teval-logloss:0.32710\n",
            "[132]\ttrain-logloss:0.00982\teval-logloss:0.32717\n",
            "[133]\ttrain-logloss:0.00968\teval-logloss:0.32746\n",
            "[134]\ttrain-logloss:0.00952\teval-logloss:0.32765\n",
            "[135]\ttrain-logloss:0.00928\teval-logloss:0.32783\n",
            "[136]\ttrain-logloss:0.00911\teval-logloss:0.32881\n",
            "[137]\ttrain-logloss:0.00901\teval-logloss:0.32883\n",
            "[138]\ttrain-logloss:0.00894\teval-logloss:0.32887\n",
            "[139]\ttrain-logloss:0.00883\teval-logloss:0.32953\n",
            "[140]\ttrain-logloss:0.00864\teval-logloss:0.33048\n",
            "[141]\ttrain-logloss:0.00855\teval-logloss:0.33055\n",
            "[142]\ttrain-logloss:0.00833\teval-logloss:0.33154\n",
            "[143]\ttrain-logloss:0.00818\teval-logloss:0.33244\n",
            "[144]\ttrain-logloss:0.00802\teval-logloss:0.33272\n",
            "[145]\ttrain-logloss:0.00790\teval-logloss:0.33265\n",
            "[146]\ttrain-logloss:0.00784\teval-logloss:0.33365\n",
            "[147]\ttrain-logloss:0.00775\teval-logloss:0.33437\n",
            "[148]\ttrain-logloss:0.00759\teval-logloss:0.33457\n",
            "[149]\ttrain-logloss:0.00752\teval-logloss:0.33531\n",
            "[150]\ttrain-logloss:0.00740\teval-logloss:0.33562\n",
            "[151]\ttrain-logloss:0.00730\teval-logloss:0.33606\n",
            "[152]\ttrain-logloss:0.00721\teval-logloss:0.33624\n",
            "[153]\ttrain-logloss:0.00709\teval-logloss:0.33691\n",
            "[154]\ttrain-logloss:0.00698\teval-logloss:0.33733\n",
            "[155]\ttrain-logloss:0.00685\teval-logloss:0.33778\n",
            "[156]\ttrain-logloss:0.00678\teval-logloss:0.33805\n",
            "[157]\ttrain-logloss:0.00666\teval-logloss:0.33828\n",
            "[158]\ttrain-logloss:0.00655\teval-logloss:0.33837\n",
            "[159]\ttrain-logloss:0.00645\teval-logloss:0.33855\n",
            "[160]\ttrain-logloss:0.00635\teval-logloss:0.33921\n",
            "[161]\ttrain-logloss:0.00628\teval-logloss:0.33942\n",
            "[162]\ttrain-logloss:0.00620\teval-logloss:0.34008\n",
            "[163]\ttrain-logloss:0.00609\teval-logloss:0.34016\n",
            "[164]\ttrain-logloss:0.00599\teval-logloss:0.34091\n",
            "[165]\ttrain-logloss:0.00592\teval-logloss:0.34114\n",
            "[166]\ttrain-logloss:0.00588\teval-logloss:0.34129\n",
            "[167]\ttrain-logloss:0.00579\teval-logloss:0.34195\n",
            "[168]\ttrain-logloss:0.00570\teval-logloss:0.34275\n",
            "[169]\ttrain-logloss:0.00562\teval-logloss:0.34271\n",
            "[170]\ttrain-logloss:0.00557\teval-logloss:0.34275\n",
            "[171]\ttrain-logloss:0.00552\teval-logloss:0.34330\n",
            "[172]\ttrain-logloss:0.00540\teval-logloss:0.34366\n",
            "[173]\ttrain-logloss:0.00528\teval-logloss:0.34470\n",
            "[174]\ttrain-logloss:0.00520\teval-logloss:0.34538\n",
            "[175]\ttrain-logloss:0.00509\teval-logloss:0.34675\n",
            "[176]\ttrain-logloss:0.00505\teval-logloss:0.34719\n",
            "[177]\ttrain-logloss:0.00502\teval-logloss:0.34764\n",
            "[178]\ttrain-logloss:0.00493\teval-logloss:0.34811\n",
            "[179]\ttrain-logloss:0.00488\teval-logloss:0.34846\n",
            "[180]\ttrain-logloss:0.00481\teval-logloss:0.34832\n",
            "[181]\ttrain-logloss:0.00475\teval-logloss:0.34903\n",
            "[182]\ttrain-logloss:0.00467\teval-logloss:0.34979\n",
            "[183]\ttrain-logloss:0.00458\teval-logloss:0.35020\n",
            "[184]\ttrain-logloss:0.00453\teval-logloss:0.34995\n",
            "[185]\ttrain-logloss:0.00446\teval-logloss:0.35059\n",
            "[186]\ttrain-logloss:0.00440\teval-logloss:0.35145\n",
            "[187]\ttrain-logloss:0.00436\teval-logloss:0.35166\n",
            "[188]\ttrain-logloss:0.00430\teval-logloss:0.35251\n",
            "[189]\ttrain-logloss:0.00425\teval-logloss:0.35274\n",
            "[190]\ttrain-logloss:0.00418\teval-logloss:0.35281\n",
            "[191]\ttrain-logloss:0.00413\teval-logloss:0.35233\n",
            "[192]\ttrain-logloss:0.00408\teval-logloss:0.35246\n",
            "[193]\ttrain-logloss:0.00402\teval-logloss:0.35309\n",
            "[194]\ttrain-logloss:0.00395\teval-logloss:0.35374\n",
            "[195]\ttrain-logloss:0.00389\teval-logloss:0.35440\n",
            "[196]\ttrain-logloss:0.00383\teval-logloss:0.35522\n",
            "[197]\ttrain-logloss:0.00381\teval-logloss:0.35541\n",
            "[198]\ttrain-logloss:0.00376\teval-logloss:0.35576\n",
            "[199]\ttrain-logloss:0.00373\teval-logloss:0.35615\n",
            "[200]\ttrain-logloss:0.00366\teval-logloss:0.35696\n",
            "[201]\ttrain-logloss:0.00360\teval-logloss:0.35770\n",
            "[202]\ttrain-logloss:0.00356\teval-logloss:0.35742\n",
            "[203]\ttrain-logloss:0.00351\teval-logloss:0.35783\n",
            "[204]\ttrain-logloss:0.00347\teval-logloss:0.35857\n",
            "[205]\ttrain-logloss:0.00343\teval-logloss:0.35920\n",
            "[206]\ttrain-logloss:0.00341\teval-logloss:0.35966\n",
            "[207]\ttrain-logloss:0.00336\teval-logloss:0.35985\n",
            "[208]\ttrain-logloss:0.00332\teval-logloss:0.36019\n",
            "[209]\ttrain-logloss:0.00329\teval-logloss:0.36071\n",
            "[210]\ttrain-logloss:0.00324\teval-logloss:0.36084\n",
            "[211]\ttrain-logloss:0.00321\teval-logloss:0.36060\n",
            "[212]\ttrain-logloss:0.00317\teval-logloss:0.36140\n",
            "[213]\ttrain-logloss:0.00314\teval-logloss:0.36176\n",
            "[214]\ttrain-logloss:0.00311\teval-logloss:0.36191\n",
            "[215]\ttrain-logloss:0.00309\teval-logloss:0.36215\n",
            "[216]\ttrain-logloss:0.00307\teval-logloss:0.36247\n",
            "[217]\ttrain-logloss:0.00303\teval-logloss:0.36274\n",
            "[218]\ttrain-logloss:0.00301\teval-logloss:0.36293\n",
            "[219]\ttrain-logloss:0.00299\teval-logloss:0.36320\n",
            "[220]\ttrain-logloss:0.00296\teval-logloss:0.36326\n",
            "[221]\ttrain-logloss:0.00292\teval-logloss:0.36315\n",
            "[222]\ttrain-logloss:0.00290\teval-logloss:0.36331\n",
            "[223]\ttrain-logloss:0.00288\teval-logloss:0.36341\n",
            "[224]\ttrain-logloss:0.00284\teval-logloss:0.36387\n",
            "[225]\ttrain-logloss:0.00282\teval-logloss:0.36401\n",
            "[226]\ttrain-logloss:0.00279\teval-logloss:0.36471\n",
            "[227]\ttrain-logloss:0.00276\teval-logloss:0.36491\n",
            "[228]\ttrain-logloss:0.00274\teval-logloss:0.36493\n",
            "[229]\ttrain-logloss:0.00270\teval-logloss:0.36482\n",
            "[230]\ttrain-logloss:0.00267\teval-logloss:0.36513\n",
            "[231]\ttrain-logloss:0.00265\teval-logloss:0.36578\n",
            "[232]\ttrain-logloss:0.00262\teval-logloss:0.36657\n",
            "[233]\ttrain-logloss:0.00259\teval-logloss:0.36699\n",
            "[234]\ttrain-logloss:0.00257\teval-logloss:0.36694\n",
            "[235]\ttrain-logloss:0.00255\teval-logloss:0.36727\n",
            "[236]\ttrain-logloss:0.00252\teval-logloss:0.36743\n",
            "[237]\ttrain-logloss:0.00249\teval-logloss:0.36788\n",
            "[238]\ttrain-logloss:0.00246\teval-logloss:0.36760\n",
            "[239]\ttrain-logloss:0.00243\teval-logloss:0.36742\n",
            "[240]\ttrain-logloss:0.00241\teval-logloss:0.36748\n",
            "[241]\ttrain-logloss:0.00238\teval-logloss:0.36792\n",
            "[242]\ttrain-logloss:0.00236\teval-logloss:0.36816\n",
            "[243]\ttrain-logloss:0.00234\teval-logloss:0.36846\n",
            "[244]\ttrain-logloss:0.00232\teval-logloss:0.36870\n",
            "[245]\ttrain-logloss:0.00230\teval-logloss:0.36869\n",
            "[246]\ttrain-logloss:0.00228\teval-logloss:0.36928\n",
            "[247]\ttrain-logloss:0.00227\teval-logloss:0.36941\n",
            "[248]\ttrain-logloss:0.00225\teval-logloss:0.36989\n",
            "[249]\ttrain-logloss:0.00224\teval-logloss:0.36981\n",
            "[250]\ttrain-logloss:0.00222\teval-logloss:0.37034\n",
            "[251]\ttrain-logloss:0.00220\teval-logloss:0.37034\n",
            "[252]\ttrain-logloss:0.00218\teval-logloss:0.37107\n",
            "[253]\ttrain-logloss:0.00216\teval-logloss:0.37128\n",
            "[254]\ttrain-logloss:0.00214\teval-logloss:0.37177\n",
            "[255]\ttrain-logloss:0.00212\teval-logloss:0.37261\n",
            "[256]\ttrain-logloss:0.00210\teval-logloss:0.37284\n",
            "[257]\ttrain-logloss:0.00209\teval-logloss:0.37315\n",
            "[258]\ttrain-logloss:0.00207\teval-logloss:0.37367\n",
            "[259]\ttrain-logloss:0.00206\teval-logloss:0.37359\n",
            "[260]\ttrain-logloss:0.00205\teval-logloss:0.37365\n",
            "[261]\ttrain-logloss:0.00203\teval-logloss:0.37444\n",
            "[262]\ttrain-logloss:0.00202\teval-logloss:0.37449\n",
            "[263]\ttrain-logloss:0.00200\teval-logloss:0.37428\n",
            "[264]\ttrain-logloss:0.00199\teval-logloss:0.37448\n",
            "[265]\ttrain-logloss:0.00197\teval-logloss:0.37481\n",
            "[266]\ttrain-logloss:0.00196\teval-logloss:0.37472\n",
            "[267]\ttrain-logloss:0.00194\teval-logloss:0.37483\n",
            "[268]\ttrain-logloss:0.00193\teval-logloss:0.37483\n",
            "[269]\ttrain-logloss:0.00191\teval-logloss:0.37551\n",
            "[270]\ttrain-logloss:0.00190\teval-logloss:0.37554\n",
            "[271]\ttrain-logloss:0.00188\teval-logloss:0.37558\n",
            "[272]\ttrain-logloss:0.00187\teval-logloss:0.37550\n",
            "[273]\ttrain-logloss:0.00185\teval-logloss:0.37559\n",
            "[274]\ttrain-logloss:0.00184\teval-logloss:0.37573\n",
            "[275]\ttrain-logloss:0.00183\teval-logloss:0.37565\n",
            "[276]\ttrain-logloss:0.00182\teval-logloss:0.37594\n",
            "[277]\ttrain-logloss:0.00180\teval-logloss:0.37617\n",
            "[278]\ttrain-logloss:0.00179\teval-logloss:0.37643\n",
            "[279]\ttrain-logloss:0.00178\teval-logloss:0.37638\n",
            "[280]\ttrain-logloss:0.00177\teval-logloss:0.37680\n",
            "[281]\ttrain-logloss:0.00175\teval-logloss:0.37648\n",
            "[282]\ttrain-logloss:0.00174\teval-logloss:0.37721\n",
            "[283]\ttrain-logloss:0.00173\teval-logloss:0.37729\n",
            "[284]\ttrain-logloss:0.00171\teval-logloss:0.37758\n",
            "[285]\ttrain-logloss:0.00170\teval-logloss:0.37828\n",
            "[286]\ttrain-logloss:0.00169\teval-logloss:0.37843\n",
            "[287]\ttrain-logloss:0.00168\teval-logloss:0.37871\n",
            "[288]\ttrain-logloss:0.00167\teval-logloss:0.37885\n",
            "[289]\ttrain-logloss:0.00165\teval-logloss:0.37934\n",
            "[290]\ttrain-logloss:0.00164\teval-logloss:0.37932\n",
            "[291]\ttrain-logloss:0.00163\teval-logloss:0.37924\n",
            "[292]\ttrain-logloss:0.00162\teval-logloss:0.37967\n",
            "[293]\ttrain-logloss:0.00161\teval-logloss:0.37963\n",
            "[294]\ttrain-logloss:0.00160\teval-logloss:0.37991\n",
            "[295]\ttrain-logloss:0.00159\teval-logloss:0.38033\n",
            "[296]\ttrain-logloss:0.00158\teval-logloss:0.38099\n",
            "[297]\ttrain-logloss:0.00157\teval-logloss:0.38090\n",
            "[298]\ttrain-logloss:0.00155\teval-logloss:0.38082\n",
            "[299]\ttrain-logloss:0.00154\teval-logloss:0.38111\n",
            "[300]\ttrain-logloss:0.00153\teval-logloss:0.38120\n",
            "[301]\ttrain-logloss:0.00152\teval-logloss:0.38156\n",
            "[302]\ttrain-logloss:0.00152\teval-logloss:0.38188\n",
            "[303]\ttrain-logloss:0.00151\teval-logloss:0.38235\n",
            "[304]\ttrain-logloss:0.00149\teval-logloss:0.38256\n",
            "[305]\ttrain-logloss:0.00149\teval-logloss:0.38301\n",
            "[306]\ttrain-logloss:0.00148\teval-logloss:0.38332\n",
            "[307]\ttrain-logloss:0.00147\teval-logloss:0.38399\n",
            "[308]\ttrain-logloss:0.00146\teval-logloss:0.38411\n",
            "[309]\ttrain-logloss:0.00145\teval-logloss:0.38419\n",
            "[310]\ttrain-logloss:0.00144\teval-logloss:0.38452\n",
            "[311]\ttrain-logloss:0.00143\teval-logloss:0.38452\n",
            "[312]\ttrain-logloss:0.00142\teval-logloss:0.38462\n",
            "[313]\ttrain-logloss:0.00141\teval-logloss:0.38485\n",
            "[314]\ttrain-logloss:0.00140\teval-logloss:0.38505\n",
            "[315]\ttrain-logloss:0.00139\teval-logloss:0.38536\n",
            "[316]\ttrain-logloss:0.00139\teval-logloss:0.38529\n",
            "[317]\ttrain-logloss:0.00138\teval-logloss:0.38613\n",
            "[318]\ttrain-logloss:0.00137\teval-logloss:0.38622\n",
            "[319]\ttrain-logloss:0.00136\teval-logloss:0.38661\n",
            "[320]\ttrain-logloss:0.00135\teval-logloss:0.38725\n",
            "[321]\ttrain-logloss:0.00135\teval-logloss:0.38718\n",
            "[322]\ttrain-logloss:0.00134\teval-logloss:0.38722\n",
            "[323]\ttrain-logloss:0.00133\teval-logloss:0.38745\n",
            "[324]\ttrain-logloss:0.00133\teval-logloss:0.38758\n",
            "[325]\ttrain-logloss:0.00132\teval-logloss:0.38801\n",
            "[326]\ttrain-logloss:0.00131\teval-logloss:0.38804\n",
            "[327]\ttrain-logloss:0.00131\teval-logloss:0.38820\n",
            "[328]\ttrain-logloss:0.00130\teval-logloss:0.38862\n",
            "[329]\ttrain-logloss:0.00129\teval-logloss:0.38874\n",
            "[330]\ttrain-logloss:0.00129\teval-logloss:0.38894\n",
            "[331]\ttrain-logloss:0.00128\teval-logloss:0.38951\n",
            "[332]\ttrain-logloss:0.00127\teval-logloss:0.38943\n",
            "[333]\ttrain-logloss:0.00127\teval-logloss:0.38959\n",
            "[334]\ttrain-logloss:0.00126\teval-logloss:0.38947\n",
            "[335]\ttrain-logloss:0.00126\teval-logloss:0.38955\n",
            "[336]\ttrain-logloss:0.00125\teval-logloss:0.38953\n",
            "[337]\ttrain-logloss:0.00124\teval-logloss:0.38969\n",
            "[338]\ttrain-logloss:0.00124\teval-logloss:0.39015\n",
            "[339]\ttrain-logloss:0.00123\teval-logloss:0.39037\n",
            "[340]\ttrain-logloss:0.00122\teval-logloss:0.39050\n",
            "[341]\ttrain-logloss:0.00122\teval-logloss:0.39117\n",
            "[342]\ttrain-logloss:0.00121\teval-logloss:0.39115\n",
            "[343]\ttrain-logloss:0.00121\teval-logloss:0.39134\n",
            "[344]\ttrain-logloss:0.00120\teval-logloss:0.39163\n",
            "[345]\ttrain-logloss:0.00119\teval-logloss:0.39164\n",
            "[346]\ttrain-logloss:0.00119\teval-logloss:0.39225\n",
            "[347]\ttrain-logloss:0.00118\teval-logloss:0.39239\n",
            "[348]\ttrain-logloss:0.00117\teval-logloss:0.39272\n",
            "[349]\ttrain-logloss:0.00117\teval-logloss:0.39296\n",
            "[350]\ttrain-logloss:0.00116\teval-logloss:0.39311\n",
            "[351]\ttrain-logloss:0.00116\teval-logloss:0.39312\n",
            "[352]\ttrain-logloss:0.00115\teval-logloss:0.39328\n",
            "[353]\ttrain-logloss:0.00115\teval-logloss:0.39335\n",
            "[354]\ttrain-logloss:0.00114\teval-logloss:0.39355\n",
            "[355]\ttrain-logloss:0.00114\teval-logloss:0.39371\n",
            "[356]\ttrain-logloss:0.00113\teval-logloss:0.39369\n",
            "[357]\ttrain-logloss:0.00113\teval-logloss:0.39388\n",
            "[358]\ttrain-logloss:0.00112\teval-logloss:0.39412\n",
            "[359]\ttrain-logloss:0.00112\teval-logloss:0.39429\n",
            "[360]\ttrain-logloss:0.00111\teval-logloss:0.39445\n",
            "[361]\ttrain-logloss:0.00111\teval-logloss:0.39459\n",
            "[362]\ttrain-logloss:0.00110\teval-logloss:0.39521\n",
            "[363]\ttrain-logloss:0.00110\teval-logloss:0.39537\n",
            "[364]\ttrain-logloss:0.00109\teval-logloss:0.39555\n",
            "[365]\ttrain-logloss:0.00109\teval-logloss:0.39544\n",
            "[366]\ttrain-logloss:0.00108\teval-logloss:0.39569\n",
            "[367]\ttrain-logloss:0.00108\teval-logloss:0.39595\n",
            "[368]\ttrain-logloss:0.00107\teval-logloss:0.39623\n",
            "[369]\ttrain-logloss:0.00107\teval-logloss:0.39628\n",
            "[370]\ttrain-logloss:0.00106\teval-logloss:0.39635\n",
            "[371]\ttrain-logloss:0.00106\teval-logloss:0.39640\n",
            "[372]\ttrain-logloss:0.00106\teval-logloss:0.39622\n",
            "[373]\ttrain-logloss:0.00105\teval-logloss:0.39615\n",
            "[374]\ttrain-logloss:0.00105\teval-logloss:0.39614\n",
            "[375]\ttrain-logloss:0.00104\teval-logloss:0.39649\n",
            "[376]\ttrain-logloss:0.00104\teval-logloss:0.39683\n",
            "[377]\ttrain-logloss:0.00103\teval-logloss:0.39728\n",
            "[378]\ttrain-logloss:0.00103\teval-logloss:0.39715\n",
            "[379]\ttrain-logloss:0.00103\teval-logloss:0.39724\n",
            "[380]\ttrain-logloss:0.00102\teval-logloss:0.39734\n",
            "[381]\ttrain-logloss:0.00102\teval-logloss:0.39740\n",
            "[382]\ttrain-logloss:0.00101\teval-logloss:0.39755\n",
            "[383]\ttrain-logloss:0.00101\teval-logloss:0.39800\n",
            "[384]\ttrain-logloss:0.00101\teval-logloss:0.39826\n",
            "[385]\ttrain-logloss:0.00100\teval-logloss:0.39822\n",
            "[386]\ttrain-logloss:0.00100\teval-logloss:0.39839\n",
            "[387]\ttrain-logloss:0.00099\teval-logloss:0.39844\n",
            "[388]\ttrain-logloss:0.00099\teval-logloss:0.39853\n",
            "[389]\ttrain-logloss:0.00099\teval-logloss:0.39895\n",
            "[390]\ttrain-logloss:0.00098\teval-logloss:0.39901\n",
            "[391]\ttrain-logloss:0.00098\teval-logloss:0.39940\n",
            "[392]\ttrain-logloss:0.00098\teval-logloss:0.39944\n",
            "[393]\ttrain-logloss:0.00097\teval-logloss:0.39929\n",
            "[394]\ttrain-logloss:0.00097\teval-logloss:0.39940\n",
            "[395]\ttrain-logloss:0.00096\teval-logloss:0.39946\n",
            "[396]\ttrain-logloss:0.00096\teval-logloss:0.39968\n",
            "[397]\ttrain-logloss:0.00096\teval-logloss:0.39981\n",
            "[398]\ttrain-logloss:0.00095\teval-logloss:0.40001\n",
            "[399]\ttrain-logloss:0.00095\teval-logloss:0.39990\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>eval-logloss</td><td></td></tr><tr><td>f1</td><td></td></tr><tr><td>precision</td><td></td></tr><tr><td>recall</td><td></td></tr><tr><td>train-logloss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.89259</td></tr><tr><td>epoch</td><td>399</td></tr><tr><td>f1</td><td>0.93266</td></tr><tr><td>precision</td><td>0.90441</td></tr><tr><td>recall</td><td>0.96273</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">gossipcop-sbert-mpnet-v2-biggraph128-xgbE400-fold-0</strong>: <a href=\"https://wandb.ai/saloniteam/nofolds/runs/ps1yufcd\" target=\"_blank\">https://wandb.ai/saloniteam/nofolds/runs/ps1yufcd</a><br/>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221018_133332-ps1yufcd/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNEc6tfHpccu"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}